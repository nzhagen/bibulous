@Preamble{
"
%\def\Olog{\tilde{O}}
%\def\NP{\ensuremath{{\cal N \cal P}}}
\newcommand{\willappear}[1]{To appear\typeout{ #1 APPEARED YET?}}
\newcommand{\submitted}[2]{Submitted for publication.\typeout{ #1 ACCEPTED TO #2 YET?}}
"
}
@string{sicomp = {SIAM Journal on Computing}}
@string{iui = {International Conference on Intelligent User Interfaces}}
@string{student = {\asteriskit{\labelwidth}} # " " }
@string{iptps = {International Workshop on Peer-to-Peer Systems}}
@string{podc = {ACM Symposium on Principles of Distributed Computing}}
@STRING{SJC = "SIAM J. Comput."}
@string{mp = {Mathematical Programming}}
@string{siamdm = {{SIAM} Journal on Discrete Mathematics}}
@string{JALG = {Journal of Algorithms}}
@string{jpdc ={Journal of Parallel and Distributed Computing}}
@string{jacm = {Journal of the ACM}}
@string{cacm = {Communications of the ACM}}
@string{ALGO = {Algorithmica}}
@string{sirev = {SIAM Review}}
@string{OR = {Operations Research}}
@string{IPL = {Information Processing Letters}}
@string{COMB = {Combinatorica}}
@string{DM = {Discrete Mathematics}}
@string{JCSS = {Journal of Computer and System Sciences}}
@string{TCS = {Theoretical Computer Science}}
@string{LNCS = {Lecture notes in Computer Science}}
@string{prelim = {A preliminary version appeared in }}
@string{journal = {Journal version appears in } }
@string{special = {Special issue of selected papers from }}
@string{esa = {European Symposium on Algorithms}}
@string{sigir =  {Annual International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval}}
@string{focs =  {Annual Symposium on the Foundations of Computer Science}}
@string{stoc =  {{ACM} Symposium on Theory of Computing}}
@string{proc =  {Proceedings of the}}
@string{soda =  {Annual {ACM}-{SIAM} Symposium on Discrete Algorithms}}
@string{spaa = {Annual {ACM}-{SIAM} Symposium on Parallel Algorithms and Architectures}}
@string{swat = {Scandinavian Workshop on Algorithmic Theory}}
@string{wads =  {Workshop on Algorithms and Data Structures}}
@string{mor = {Mathematics of Operation Research}}
@string{esa94 = proc # { 1994 } # esa}
@string{focs79 = proc # { {$20^{th}$} } # focs}
@string{FOCS82 = proc # { {$23^{rd}$} } # focs}
@string{FOCS83 = proc # { {$24^{th}$} } # focs}
@string{FOCS84 = proc # { {$25^{th}$} } # focs}
@string{FOCS85 = proc # { {$26^{th}$} } # focs}
@string{FOCS86 = proc # { {$27^{th}$} } # focs}
@string{FOCS87 = proc # { {$28^{th}$} } # focs}
@string{FOCS88 = proc # { {$29^{th}$} } # focs}
@string{FOCS89 = proc # { {$30^{th}$} } # focs}
@string{FOCS90 = proc # { {$31^{st}$} } # focs}
@string{FOCS91 = proc # { {$32^{nd}$} } # focs}
@string{FOCS92 = proc # { {$33^{rd}$} } # focs}
@string{FOCS93 = proc # { {$34^{th}$} } # focs}
@string{FOCS94 = proc # { {$35^{th}$} } # focs}
@string{FOCS95 = proc # { {$36^{th}$} } # focs}
@string{FOCS96 = proc # { {$37^{th}$} } # focs}
@string{FOCS97 = proc # { {$30^{th}$} } # focs}
@string{FOCS98 = proc # { {$31^{st}$} } # focs}
@string{FOCS99 = proc # { {$32^{nd}$} } # focs}
@string{FOCS00 = proc # { {$33^{rd}$} } # focs}
@string{FOCS01 = proc # { {$34^{th}$} } # focs}
@string{FOCS02 = proc # { {$35^{th}$} } # focs}
@string{FOCS03 = proc # { {$36^{th}$} } # focs}
@string{FOCS04 = proc # { {$37^{th}$} } # focs}
@string{FOCS09 = proc # { {$45^{th}$} } # focs}
@string{SODA92 = proc # { {$3^{rd}$} } # soda}
@string{SODA93 = proc # { {$4^{th}$} } # soda}
@string{SODA94 = proc # { {$5^{th}$} } # soda}
@string{SODA95 = proc # { {$6^{th}$} } # soda}
@string{SODA96 = proc # { {$7^{th}$} } # soda}
@string{SODA97 = proc # { {$8^{th}$} } # soda}
@string{SODA98 = proc # { {$9^{th}$} } # soda}
@string{SODA99 = proc # { {$10^{th}$} } # soda}
@string{SODA00 = proc # { {$11^{th}$} } # soda}
@string{SODA01 = proc # { {$12^{th}$} } # soda}
@string{SODA04 = proc # { {$15^{th}$} } # soda}
@string{SODA05 = proc # { {$16^{th}$} } # soda}
@string{SODA06 = proc # { {$17^{th}$} } # soda}
@string{SODA07 = proc # { {$18^{th}$} } # soda}
@string{SODA08 = proc # { {$19^{th}$} } # soda}
@string{SODA10 = proc # { {$21^{st}$} } # soda}
@string{SIGIR92 = proc # { {$15^{th}$} } # sigir}
@string{SIGIR93 = proc # { {$16^{th}$} } # sigir}
@string{STOC80 = proc # { {$12^{th}$} } # stoc}
@string{STOC86 = proc # { {$18^{th}$} } # stoc}
@string{STOC87 = proc # { {$19^{th}$} } # stoc}
@string{STOC88 = proc # { {$20^{th}$} } # stoc}
@string{STOC89 = proc # { {$21^{st}$} } # stoc}
@string{STOC90 = proc # { {$22^{nd}$} } # stoc}
@string{STOC91 = proc # { {$23^{rd}$} } # stoc}
@string{STOC92 = proc # { {$24^{th}$} } # stoc}
@string{STOC93 = proc # { {$25^{th}$} } # stoc}
@string{STOC94 = proc # { {$26^{th}$} } # stoc}
@string{STOC95 = proc # { {$27^{th}$} } # stoc}
@string{STOC96 = proc # { {$28^{th}$} } # stoc}
@string{STOC97 = proc # { {$29^{th}$} } # stoc}
@string{STOC98 = proc # { {$29^{th}$} } # stoc}
@string{STOC99 = proc # { {$30^{th}$} } # stoc}
@string{STOC00 = proc # { {$31^{st}$} } # stoc}
@string{STOC01 = proc # { {$32^{nd}$} } # stoc}
@string{STOC02 = proc # { {$33^{rd}$} } # stoc}
@string{STOC09 = proc # { {$40^{th}$} } # stoc}
@string{SPAA92 = proc # { {$4^{th}$} } # spaa}
@string{SPAA94 = proc # { {$6^{th}$} } # spaa}
@string{SWAT90 = proc # { $2^{nd}$ } # swat}
@string{WADS91 =  proc # { $2^{nd}$ } # wads}
@string{SIGPLAN89 = proc # { SIGPLAN 89 Conference on Programming Language Design and Implementation}}
@string{icalpa = {Automata, Languages and Programming.}}
@string{icalpb = {International Colloquium Proceedings}}
@string{icalp90 = icalpa # { {$17^{th}$} } # icalpb}
@string{icalp91 = icalpa # { {$18^{th}$} } # icalpb}
@string{icalp92 = icalpa # { {$19^{th}$} } # icalpb}
@string{icalp93 = icalpa # { {$20^{th}$} } # icalpb}
@string{icalp94 = icalpa # { {$21^{st}$} } # icalpb}
@string{icalp95 = icalpa # { {$22^{nd}$} } # icalpb}
@string{PODS91 = proc # { 10th {ACM} Symposium on Principles of Database Systems}}
@string{istcs95 = proc # {Israeli Symposium on Theoretical Computer Science}}
@string{ieeep = {IEEE Computer Society Press}}
@string{acmp = {ACM Press}}
@string{mitp = {{MIT} Press}}
@string{sv = {Springer-Verlag}}
@string{hbase="http://theory.lcs.mit.edu/~karger/Papers"}
@string{hayweb="http://haystack.lcs.mit.edu/papers/"}
@string{and = { and }}
@string{aleliunas={R. Aleliunas}}
@string{applegate = {David Appelgate}}
@string{awerbuch = {Baruch Awerbuch}}
@string{babai = "L. Babai"}
@string{barnes = {Greg Barnes}}
@string{benczur = {Andr{\'a}s A. Bencz{\'u}r}}
@string{bixby = {Robert Bixby}}
@string{bollobas = {B{\'e}la Bollob{\'a}s}}
@string{cole = {Richard Cole}}
@string{cook = {William Cook}}
@string{chvatal = {Va\v{s}ek Chv\'a{a}tal}}
@string{dwork = {Cynthia Dwork}}
@string{erdos = {P{\`a}l Erd{\"o}s}}
@string{feige = {Uri Feige}}
@string{frank = {Andras Frank}}
@string{gabow = {Harold N. Gabow}}
@string{grotschel = {Martin Gr{\"o}tschel}}
@string{ibaraki = {Toshihide Ibaraki}}
@string{jerrum = {Mark Jerrum}}
@string{johnson = {Donald B. Johnson}}
@string{karger = {David R. Karger}}
@string{lovasz = {L{\`a}szl{\'o} Lov{\'a}sz}}
@string{metaxas = {Panagiotis Metaxas}}
@string{karp = {Richard M. Karp}}
@string{linial = "Natan Linial"}
@string{lipton = {Richard J. Lipton}}
@string{leeuwen = {van Leeuwen, Jan}}
@string{nagamochi = {Hiroshi Nagamochi}}
@string{nisan = "Noam Nisan"}
@string{nishimura = {Kazuhiro Nishimura}}
@string{rackoff = {C. Rackoff}}
@string{renyi = {A. R{\'e}nyi}}
@string{reischuk = {Rudiger Reischuk}}
@string{ruzzo = {Walter L. Ruzzo}}
@string{szegedy = "Mario Szegedy"}
@string{stoer = {Methchild Stoer}}
@string{tardos =  {{\'E}va Tardos}}
@string{tarjan = {Robert E. Tarjan}}
@string{vishkin = {Uzi Vishkin}}
@string{vvazirani = {Vijay Vazirani}}
@string{valiant = {Leslie Valiant}}
@string{wagner = {F. Wagner}}
@STRING{MIT = "Massachusetts Institute of Technology"}
@STRING{MITLCS = MIT # " Laboratory for Computer Science"}
@STRING{MIT-ADDR = "Cambridge, Massachusetts"}

@inproceedings{Danis:ManyEyes,
 author = {Danis, Catalina M. and Viegas, Fernanda B. and Wattenberg, Martin and Kriss, Jesse},
 title = {Your place or mine?: visualization as a community component},
 booktitle = {Proceedings of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
 series = {CHI '08},
 year = {2008},
 isbn = {978-1-60558-011-1},
 location = {Florence, Italy},
 pages = {275--284},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1357054.1357102},
 doi = {10.1145/1357054.1357102},
 acmid = {1357102},
 publisher = {ACM},
 hideaddress = {New York, NY, USA},
 keywords = {communication, distributed community, social data analysis, visualization},
}

@Article{Rosson84,
  author = {Mary Beth Rosson},
  title = {Effects of experience on learning, using, and evaluating a
                  text editor},
  journal = {Human Factors},
  year = {1984},
  pages = {463--475},
}

@inproceedings{Mackay91,
 author = {Wendy E. Mackay},
 title = {Triggers and barriers to customizing software},
 booktitle = {CHI '91: Proceedings of the SIGCHI conference on Human
                  factors in computing systems},
 year = {1991},
 isbn = {0-89791-383-3},
 pages = {153--160},
 location = {New Orleans, Louisiana, United States},
 doi = {http://doi.acm.org/10.1145/108844.108867},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@article{McKenzie:UserGeneratedContent,
author = {McKenzie, Pamela and Burkell, Jacquelyn and Wong, Lola and Whippey,
                  Caroline and Trosow, Samuel and McNally, Michael},
title = {User-generated online content 1: overview, current state and
                  context},
journal = {First Monday [Online]},
url = {http://firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/view/3912/3266},
volume = 17,
number = 6,
month = jun,
year = 2012}

@article{Heer:D3,
  title = {D3: Data-Driven Documents},
  author = {Michael Bostock AND Vadim Ogievetsky AND Jeffrey Heer},
  journal = {IEEE Trans. Visualization \& Comp. Graphics
                  (Proc. InfoVis)},
  year = {2011},
  url = {http://vis.stanford.edu/papers/d3}
}

@InProceedings{Adler:NetworkCodingCapacity,
  author = 	 {Micah Adler and Nick Harvey and Kamal Jain and
                  Robert Kleinberg and April Rasala Lehman},
  title = 	 {On the Capacity of Information Networks},
  crossref =	 {SODA06}
}
}

@Book{Overmars:Geometry,
  author =	 {Mark de Berg and Otfried Schwarzkopf and Mark van
                  Kreveld and Mark Overmars},
  title = 	 {Computational Geometry: Algorithms and Applications},
  publisher = 	 {Springer-Verlag},
  year = 	 2000
}

@inproceedings{Findlater04,
 author = {Leah Findlater and Joanna McGrenere},
 title = {A comparison of static, adaptive, and adaptable menus},
 booktitle = {CHI '04: Proceedings of the SIGCHI conference on Human
                  factors in computing systems},
 year = {2004},
 isbn = {1-58113-702-8},
 pages = {89--96},
 location = {Vienna, Austria},
 doi = {http://doi.acm.org/10.1145/985692.985704},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@article{MapReduceRant1,
  author = {David. J. DeWitt and Michael Stonebraker},
  title = {MapReduce: A major step backwards},
  journal = {The Database Column},
  year = 2008,
  month = jan,
  note = {http://www.databasecolumn.com/2008/01/mapreduce-a-major-step-back.html}
  }

@incollection{Edwards:LostInHyperspace,
 author = {Edwards, Deborah M. and Hardman, Lynda},
 title = {Lost in hyperspace: cognitive mapping and navigation in a
                  hypertext environment},
 booktitle = {Hypertext: theory into practice},
 editor = {McAleese, Ray},
 year = {1999},
 isbn = {1-871516-28-5},
 pages = {90--105},
 numpages = {16},
 url = {http://dl.acm.org/citation.cfm?id=320628.320639},
 acmid = {320639},
 publisher = {Intellect Books},
 address = {Exeter, UK, UK},
}

@article{MapReduceRant2,
  author = {David. J. DeWitt and Michael Stonebraker},
  title = {MapReduce II},
  journal = {The Database Column},
  year = 2008,
  month = jan,
  note = {http://www.databasecolumn.com/2008/01/mapreduce-continued.html}
  }


@InProceedings{Shmoys:StochasticOptimization,
  author = 	 {David B. Shmoys and Chaitana Swamy},
  title = 	 {Stochastic Optimization is (Almost) as Easy as
                  Deterministic Optimization},
  crossref =	 {FOCS04},
  pages =	 {228--237}
}

@techreport{Hickson:WebStorage,
  author = 	 {Ian Hickson},
  institution =  {World Wide Web Consortium},
  title = 	 {Web Storage},
  month = 	 apr,
  year = 	 2009,
  note = 	 {\texttt{http://www.w3.org/TR/webstorage/}},
}

@article{Terry:ActiveTioga,
 author = {Terry, Douglas B. and Baker, Donald G.},
 title = {Active tioga documents: an exploration of two paradigms},
 journal = {Electronic Publishing---Origination, Dissemination, and Design},
 volume = {3},
 number = {2},
 year = {1990},
 issn = {0894-3982},
 pages = {105--122},
 publisher = {John Wiley and Sons Ltd.},
 address = {Chichester, UK},
}

@article{Bier:EmbeddedButtons,
 author = {Bier, Eric A.},
 title = {EmbeddedButtons: supporting buttons in documents},
 journal = {ACM Trans. Inf. Syst.},
 volume = {10},
 number = {4},
 year = {1992},
 issn = {1046-8188},
 pages = {381--407},
 doi = {http://doi.acm.org/10.1145/146486.146547},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{Brandt:OpportunisticProgramming,
 author = {Brandt, Joel and Guo, Philip J. and Lewenstein, Joel and
                  Dontcheva, Mira and Klemmer, Scott R.},
 title = {Two studies of opportunistic programming: interleaving web
                  foraging, learning, and writing code},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in
                  Computing Systems},
 series = {CHI '09},
 year = {2009},
 isbn = {978-1-60558-246-7},
 location = {Boston, MA, USA},
 pages = {1589--1598},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1518701.1518944},
 doi = {10.1145/1518701.1518944},
 acmid = {1518944},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {copy-and-paste, opportunistic programming, prototyping},
}

@article{Karger:VizStandards,
author = {David R. Karger},
title = {Standards Opportunities around Data-bearing Web Pages},
journal = {Philosophical Transactions of the Royal Society A},
cat:multiple = {CHI;Semantic Web},
year = 2013,
month = mar,
volume = 371,
number = 1987,
pages = {},
doi = {http://doi.acm.org/10.1098/rsta.2012.0381},
pdf = {Papers/standards.pdf},
}

@article{Karger:Disks,
 author = {Thouis Jones and David R. Karger},
 title = {Linear-Time Poisson-Disk Patterns},
 journal = {Journal of Graphics, GPU, and Game Tools},
 volume = 15,
 number = 3,
 pages = {177--182},
 year = 2011,
 month = oct}

@inproceedings{Karger:HCIR-standards,
 author = {David R. Karger},
 title = {Standards Opportunities around Data-Bearing Web Pages},
 booktitle = {HCIR 2012: the Sixth International Symposium on
                  Human-Computer Interaction and Information
                  Retrieval},
 cat:multiple = {CHI;Semantic Web},
 year = 2012,
 month = dec
}

@inproceedings{Karger:Gossip,
 author = {Haeupler, Bernhard and Karger, David},
 cat:multiple={Theory},
 title = {Faster information dissemination in dynamic networks via
                  network coding},
 booktitle = {Proceedings of the 30th annual ACM SIGACT-SIGOPS
                  symposium on Principles of distributed computing},
 series = {PODC '11},
 venue={PODC},
 year = {2011},
month=jun,
 isbn = {978-1-4503-0719-2},
 location = {San Jose, California, USA},
 pages = {381--390},
 numpages = {10},
 pdf = {http://arxiv.org/abs/1104.2527},
 doi = {http://doi.acm.org/10.1145/1993806.1993885},
 acmid = {1993885},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dynamic networks, gossip, multicast, network coding},
}

@inproceedings{Karger:Twitinfo,
 author = {Marcus, Adam and Bernstein, Michael S. and Badar, Osama and
                  Karger, David R. and Madden, Samuel and Miller,
                  Robert C.},
 venue={CHI},
 title = {Twitinfo: aggregating and visualizing microblogs for event
                  exploration},
 booktitle = {Proceedings of the 2011 annual conference on Human
                  factors in computing systems},
 series = {CHI '11},
 year = {2011},
 month=may,
 cat:multiple = {CHI;Systems;Information Retrieval},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {227--236},
 numpages = {10},
 doi = {http://doi.acm.org/10.1145/1978942.1978975},
pdf={http://people.csail.mit.edu/marcua/papers/twitinfo-chi2011.pdf},
url={http://twitinfo.csail.mit.edu/},
 acmid = {1978975},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {twitter visualization streaming aggregate sentiment},
}

@article{Karger:HumanJoin,
 author = {Marcus, Adam and Wu, Eugene and Karger, David and Madden,
                  Samuel and Miller, Robert},
 title = {Human-powered sorts and joins},
 journal = {Proc. VLDB Endow.},
 issue_date = {September 2011},
 volume = {5},
 issue = {1},
 month = sep,
 year = {2011},
 issn = {2150-8097},
 pages = {13--24},
 numpages = {12},
 url = {http://dl.acm.org/citation.cfm?id=2047485.2047487},
 acmid = {2047487},
cat:multiple={CHI;Databases;Machine Learning;Systems},
pdf={http://people.csail.mit.edu/marcua/papers/qurk-vldb2012.pdf},
 publisher = {VLDB Endowment},
}

@inproceedings{Karger:HumanJoins-conf,
author={Adam Marcus and Eugene Wu and David Karger and Samuel Madden
                  and Robert Miller},
title={Human Powered Sorts and Joins},
booktitle = {Proceedings of the 38th International Conference on Very
                  Large Databases},
month = aug,
year = 2012
}


@inproceedings{Karger:Spreadsheets,
 author = {Bakke, Eirik and Karger, David and Miller, Rob},
 title = {A spreadsheet-based user interface for managing plural
                  relationships in structured data},
 booktitle = {Proceedings of the 2011 annual conference on Human
                  factors in computing systems},
 cat:multiple = {CHI;Systems;Information Retrieval},
 series = {CHI '11},
 venue={CHI},
 year = {2011},
 month=may,
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2541--2550},
 numpages = {10},
 doi = {http://doi.acm.org/10.1145/1978942.1979313},
 pdf = {http://www.mit.edu/~ebakke/research/related_worksheets_chi2011.pdf},
 acmid = {1979313},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {databases, foreign key relationships, hierarchical views,
                  one-to-many relationships, spreadsheets},
}

@inproceedings{Karger:Listit-CHI2011,
 author = {Van Kleek, Max G. and Styke, Wolfe and schraefel, m. c. and
                  Karger, David},
 cat:multiple = {CHI;Systems;Information Retrieval},
 title = {Finders/keepers: a longitudinal study of people managing
                  information scraps in a micro-note tool},
 booktitle = {Proceedings of the 2011 annual conference on Human
                  factors in computing systems},
 series = {CHI '11},
 venue={CHI},
 year = {2011},
 month=may,
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {2907--2916},
 numpages = {10},
 doi = {http://doi.acm.org/10.1145/1978942.1979374},
 pdf={http://people.csail.mit.edu/emax/papers/chi2011-finders-keepers.pdf},
 acmid = {1979374},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {information scraps, longitudinal study, note taking,
                  personal information management, personal
                  organization},
}

@inproceedings{Karger:Qurk,
author = {Adam Marcus and Eugene We and David R. Karger and Sammuel
                  Madden and Robert C. Miller},
title={Crowdsourced Databases: Query Processing with People},
year=2011,
month=jan,
booktitle={Conference on Innovation in Database Research (CIDR) 2011},
venue={CIDR},
cat:multiple={CHI;Systems;Information Retrieval},
pdf={http://people.csail.mit.edu/marcua/papers/qurk-cidr2011.pdf}
}

@inproceedings{Karger:Adrenaline,
 author = {Bernstein, Michael S. and Brandt, Joel and Miller, Robert
                  C. and Karger, David R.},
title = {Crowds in Two Seconds: Enabling Realtime Crowd-Powered Interfaces},
venue = {UIST},
cat:multiple={CHI;Systems;Crowdsourcing},
 booktitle = {Proceedings of the 24th annual ACM symposium on User
                  interface software and technology},
 series = {UIST '11},
 year = {2011},
 month = nov,
 isbn = {978-1-4503-0716-1},
 location = {Santa Barbara, California, USA},
 pages = {33--42},
 numpages = {10},
 doi = {http://doi.acm.org/10.1145/2047196.2047201},
 acmid = {2047201},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {crowdsourcing, human computation},
}

@inproceedings{Karger:ScalingOverlay,
 author = {Sontag, David and Zhang, Yang and Phanishayee, Amar and Andersen, David G. and Karger, David},
 title = {Scaling all-pairs overlay routing},
 booktitle = {CoNEXT '09: Proceedings of the 5th international conference on Emerging networking experiments and technologies},
 year = {2009},
 month=dec,
 abstract={This paper presents and experimentally evaluates a new
                  algorithm for efficient one-hop link-state routing
                  in full-mesh networks. Prior techniques for this
                  setting scale poorly, as each node incurs quadratic
                  ($n^2$) communication overhead to broadcast its link
                  state to all other nodes. In contrast, in our
                  algorithm each node exchanges routing state with
                  only a small subset of overlay nodes determined by
                  using a quorum system. Using a two round protocol,
                  each node can find an optimal one-hop path to any
                  other node using only $n^{1.5}$ per-node
                  communication. Our algorithm can also be used to
                  find the optimal shortest path of arbitrary length
                  using only $n^{1.5}$ logn per-node communication. The
                  algorithm is designed to be resilient to both node
                  and link failures.

We apply this algorithm to a Resilient Overlay Network (RON) system,
                  and evaluate the results using a large-scale,
                  globally distributed set of Internet hosts. The
                  reduced communication overhead from using our
                  improved full-mesh algorithm allows the creation of
                  all-pairs routing overlays that scale to hundreds of
                  nodes, without reducing the system's ability to
                  rapidly find optimal routes.},
 isbn = {978-1-60558-636-6},
 cat:multiple={Applications of Theory;P2P},
 pages = {145--156},
 location = {Rome, Italy},
 doi = {http://doi.acm.org/10.1145/1658939.1658956},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{Karger:Canadian,
  author    = {Evdokia Nikolova and
               David R. Karger},
  title     = {Route Planning under Uncertainty: The Canadian
                  Traveller
               Problem},
  booktitle = {Twenty-Third AAAI Conference on Artificial Intelligence},
  venue = {AAAI},
  cat = {Theory},
  year      = {2008},
  month = jul,
  pages     = {969-974},
  crossref  = {DBLP:conf/aaai/2008},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{DBLP:conf/aaai/2008,
  editor    = {Dieter Fox and
               Carla P. Gomes},
  title     = {Proceedings of the Twenty-Third AAAI Conference on
                  Artificial
               Intelligence, AAAI 2008, Chicago, Illinois, USA, July
                  13-17,
               2008},
  booktitle = {AAAI},
  publisher = {AAAI Press},
  year      = {2008},
  isbn      = {978-1-57735-368-3},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@Article{Karger:Mallows-JAIR,
  author = 	 {Harr Chen and S.R.K. Branavan and Regina Barzilay and David R. Karger},
  title = 	 {Content Modelling Using Latent Permutations},
  journal = 	 {Journal of Artificial Intelligence Research},
  year = 	 2009,
  month=sep,
  volume = 	 36,
  cat:multiple = {Machine Learning;Information Retrieval},
  doi = {http://dx.doi.org/10.1613/jair.2830},
  pdf = {http://www.jair.org/media/2830/live-2830-4684-jair.pdf},
  abstract={We present a novel Bayesian topic model for learning
                  discourse-level document structure. Our model
                  leverages insights from discourse theory to
                  constrain latent topic assignments in a way that
                  reflects the underlying organization of document
                  topics. We propose a global model in which both
                  topic selection and ordering are biased to be
                  similar across a collection of related documents. We
                  show that this space of orderings can be effectively
                  represented using a distribution over permutations
                  called the Generalized Mallows Model. We apply our
                  method to three complementary discourse-level tasks:
                  cross-document alignment, document segmentation, and
                  information ordering. Our experiments show that
                  incorporating our permutation-based model in these
                  applications yields substantial improvements in
                  performance over previously proposed methods.},
  pages = 	 {129--163}}

@inproceddings{Karger:DataModelEUP,
author={David R. Karger and David Huynh},
title={Adopting a Common Data Model for End User Web Programming
                  Tools},
booktitle={CHI2009 Workshop on End User Programming for the Web},
year=2009,
month=apr
}

@inproceedings{Karger:DIDO,
 author = {Karger, David R. and Ostler, Scott and Lee, Ryan},
 title = {The web page as a WYSIWYG end-user customizable
                  database-backed information management application},
 booktitle = {UIST '09: Proceedings of the 22nd annual ACM symposium
                  on User interface software and technology},
 year = {2009},
 month = oct,
 isbn = {978-1-60558-745-5},
 pages = {257--260},
 location = {Victoria, BC, Canada},
 doi = {http://doi.acm.org/10.1145/1622176.1622223},
 publisher = {ACM},
 pdf = {Papers/dido.pdf},
 venue = {UIST},
 url = {http://projects.csail.mit.edu/exhibit/Dido/},
 cat:multiple = {CHI;Haystack;Semantic Web;Systems},
 hideaddress = {New York, NY, USA},
 abstract={Dido is an application (and application development environment) in a web page.  It is a single web page containing rich structured data, an AJAXy interactive visualizer/editor for that data, and a ``metaeditor'' for WYSIWYG editing of the visualizer/editor.  Historically, users have been limited to the data schemas, visualizations, and interactions offered by a small number of heavyweight applications.  In contrast, Dido encourages and enables the end user to edit (not code) in his or her web browser a distinct ephemeral interaction ``wrapper'' for each data collection that is specifically suited to its intended use.  Dido's \emph{active document} metaphor has been explored before but we show how, given today's web infrastructure, it can be deployed in a small self-contained HTML document without touching a web client or server.}
 }


@inproceedings{Haeupler:LLL,
author = {Bernhard Haeupler and Karthekeyan Chandrasekaran and Navin Goyal},
title={Deterministic Algorithms for the Lovasz Local Lemma},
crossref={SODA10}
}

@Article{Karger:InteractomeFlow,
  author = 	 {Esther Yeger-Lotem and Laura Riva and L.J. Su and A.D. Gitler and A.G. Cashikar and O.D. King and P.K. Auluck and M.L. Geddie and J.S. Valastyan and David R. Karger and Susan Lindquist and Ernest Fraenkel},
  title = 	 {Bridging High-Throughput Genetic and Transcriptional Data Reveals Cellular Responses to Alpha-Synuclein Toxicity},
  journal = 	 {Nature Genetics},
  cat:multiple = {Theory;Applications of Theory},
  year = 	 2009,
  url = {http://www.ncbi.nlm.nih.gov/pubmed/19234470},
  volume = 	 41,
  number = 	 3,
  pages = 	 {316-23},
  month = 	 mar}

@inproceedings{Voida:Homebrew,
 author = {Voida, Amy and Harmon, Ellie and Al-Ani, Ban},
 title = {Homebrew databases: complexities of everyday information management in nonprofit organizations},
 booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
 series = {CHI '11},
 year = {2011},
 isbn = {978-1-4503-0228-9},
 location = {Vancouver, BC, Canada},
 pages = {915--924},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1978942.1979078},
 doi = {10.1145/1978942.1979078},
 acmid = {1979078},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {NPO, homebrew databases, information management, nonprofit, volunteer coordination, volunteer management.},
}

@article{Flajolet:Counting,
  author    = {Philippe Flajolet},
  title     = {Approximate Counting: A Detailed Analysis},
  journal   = {BIT},
  volume    = {25},
  number    = {1},
  year      = {1985},
  pages     = {113-134},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@InProceedings{Karger:OptimalDistanceOracle,
  author = 	 {Aaron Bernstein and David Karger},
  title = 	 {A Nearly Optimal Oracle for Avoiding Failed Vertices and Edges},
  crossref =  {STOC09},
  venue = {STOC},
  cat={Theory},
  pdf={Papers/optimalDistanceOracle.pdf},
  pages = 	 {101--110},
  abstract ={We present an improved oracle for the distance
                  sensitivity
problem. The goal is to preprocess a directed graph
$G = (V,E)$ with non-negative edge weights to answer queries
of the form: what is the length of the shortest path from $x$
to $y$ that does not go through some failed vertex or edge
$f$. The previous best algorithm produces an oracle of size $O(n^2)$ that
                  has an $O(1)$ query time, and an $O(n^2\sqrt(m))$ construction
time. It was a randomized Monte Carlo algorithm
that worked with high probability. Our oracle also has a
constant query time and an $O(n^2)$ space requirement, but it
has an improved construction time of $O(mn)$, and it is deterministic.
note that $O(1)$ query, $O(n^2)$ space, and $O(mn)$
construction time is also the best known bound (up to logarithmic
factors) for the simpler problem of finding all pairs
shortest paths in a weighted, directed graph. Thus, barring
improved solutions to the all pairs shortest path problem,
our oracle is optimal up to logarithmic factors.
}
}

@InProceedings{Karger:Mallows,
  author = 	 {Harr Chen and S.R.K. Branavan and Regina Barzilay and David R. Karger},
  title = 	 {Global Models of Document Structure Using Latent Permutations},
  booktitle = {North American Chapter of the Association for
                  Computational Linguistics - Human Language
                  Technologies (NAACL HLT) conference},
  venue = {NAACL},
  year = 	 2009,
  cat:multiple = {Machine Learning;Information Retrieval},
  pdf={http://people.csail.mit.edu/regina/my_papers/perm.pdf},
  address = 	 {Boulder, CO, USA},
  month = 	 may}

@InProceedings{Karger:Listit,
  author = 	 {Van Kleek, Max and Michael Bernstein and Greg
                  Vargas and Katrina Panovich and David Karger and mc schraefel},
  title = 	 {note to Self: Examining Personal Information-Keeping in a Lightweight note-Taking Tool},
  conference = {CHI},
  booktitle =	 {Proceedings of the ACM CHI Conference on Human Factors in Computing Systems},
  year = 	 2009,
  month=apr,
  doi = {http://doi.acm.org/10.1145/1518701.1518924},
  address = 	 {Boston, MA, USA},
  pages={1477-1480},
  cat:multiple = {CHI;Information Retrieval},
  venue = {CHI},
  note={Best note nominee},
  organization = {ACM},
  pdf={http://people.csail.mit.edu/msbernst/papers/note1546-vankleek.pdf},
  abstract={This paper describes a longitudinal field experiment in
                  personal note-taking that examines how people
                  capture and use information in short textual
                  notes. Study participants used our tool, a simple
                  browser-based textual note-taking utility, to
                  capture personal information over the course of ten
                  days. We examined the information they kept in notes
                  using the tool, how this information was expressed,
                  and aspects of note creation, editing, deletion, and
                  search. We found that notes were recorded extremely
                  quickly and tersely, combined information of
                  multiple types, and were rarely revised or
                  deleted. The results of the study demonstrate the
                  need for a tool such as ours to support the rapid
                  capture and retrieval of short notes-to-self, and
                  afford insights into how users' actual note-keeping
                  tendencies could be used to better support their
                  needs in future PIM tools.}
}



@InProceedings{Karger:Inky,
  author = 	 {Miller, Rob and Victoria Chou and Michael Bernstein
                  and Greg Little and Van Kleek, Max and David Karger and mc schraefel},
  title = 	 {Inky: A Sloppy Command Line for the Web with Rich Visual Feedback},
  cat:multiple = {CHI;Information Retrieval},
  venue={UIST},
  booktitle = {21st Symposium on User Interface Software Technology (UIST)},
  pages = 	 {131--140},
  year = 	 2008,
  address = 	 {Monterey, CA},
  month = 	 oct}

@misc{Karger:AtomSmasherPoster,
  author = 	 {Van Kleek, Max and Paul Andre and Mikko Perttunen and David Karger and Rob Miller and mc schraefel},
  title = 	 {AtomsMasher: Personal Reactive Automation for the Web},
  cat:multiple = {CHI;Information Retrieval},
  booktitle = {21st Symposium on User Interface Software Technology (UIST)},
  year = 	 2008,
  pub-type =     "Poster",
  venue={UIST},
  address = 	 {Monterey, CA},
  month = 	 oct,
  pub-type=      {Poster},
  note={Poster.}
}


@Article{Karger:Scraps,
  author = 	 {Michael Bernstein and Van Kleek, Max and David R. Karger and mc schraefel},
  title = 	 {Information Scraps: How and Why Information Eludes our Personal Information Management Tools},
  journal = 	 {ACM Transactions on Information Systems},
  year = 	 2008,
  volume = 	 26,
  number = 	 4,
  cat:multiple = {CHI;Information Retrieval;Haystack},
  note = 	 {special issue on PIM},
 issn = {1046-8188},
 pages = {1--46},
 doi = {http://doi.acm.org/10.1145/1402256.1402263},
 publisher = {ACM},
 address = {New York, NY, USA},
 abstract={In this article we investigate information
                  scraps---personal information where content has
                  been scribbled on Post-it notes, scrawled on the
                  corners of sheets of paper, stuck in our pockets,
                  sent in email messages to ourselves, and stashed in
                  miscellaneous digital text files. Information scraps
                  encode information ranging from ideas and sketches
                  to notes, reminders, shipment tracking numbers,
                  driving directions, and even poetry. Although
                  information scraps are ubiquitous, we have much
                  still to learn about these loose forms of
                  information practice. Why do we keep information
                  scraps outside of our traditional PIM
                  applications? What role do information scraps
                  play in our overall information practice? How
                  might PIM applications be better designed to
                  accommodate and support information scraps'
                  creation, manipulation and retrieval?

We pursued these questions by studying the information scrap practices
                  of 27 knowledge workers at five organizations. Our
                  observations shed light on information scraps'
                  content, form, media, and location. From this data,
                  we elaborate on the typical information scrap
                  lifecycle, and identify common roles that
                  information scraps play: temporary storage,
                  archiving, work-in-progress, reminding, and
                  management of unusual data. These roles suggest a
                  set of unmet design needs in current PIM tools:
                  lightweight entry, unconstrained content, flexible
                  use and adaptability, visibility, and mobility.}
}



@InProceedings{Karger:FixedPrecisionBinPacking,
  author = 	 {David R. Karger and Jacob Scott},
  title = 	 {Efficient Algorithms for Fixed-Precision Instances of Bin Packing and Euclidean TSP },
  booktitle = {11th International Workshop on Approximation Algorithms
                  for Combinatorial Optimization Problems
                  (RANDOM/APPROX)},
  cat:multiple = {Theory},
  pages = 	 104,
  year = 	 2008,
  month = 	 aug}

@InProceedings{Karger:SchedulingUncertainty,
  author = 	 {Christopher Y. Crutchfield and Zoran Dzunic and
                  Jeremy T. Fineman and David R. Karger and Jacob H. Scott},
  title = 	 {Improved Approximations for Multiprocessor Scheduling Under Uncertainty},
  booktitle = {Proceedings of the Twentieth ACM Symposium on Parallelism in Algorithms and Architectures (SPAA)},
  year = 	 2008,
  address = 	 {Munich, Germany},
  cat = {Theory},
  venue = {SPAA},
  month = 	 jun,
  organization = {ACM}}

@InCollection{Karger:PimBook,
  author = 	 {David R. Karger},
  title = 	 {It's All the Same to Me: Data Unification in Personal Information Management},
  booktitle = 	 {Personal Information Management},
  pages = 	 {127-152},
  publisher =    {University of Washington Press},
  year = 	 2007,
  cat:multiple = {Information Retrieval;Semantic Web},
  editor = 	 {William Jones and Jaime Teevan},
  abstract =     {Information fragmentation is a pervasive problem in
                  personal information management. Even a seemingly
                  simple decision, such as whether to say "yes" to a
                  dinner invitation, often depends upon information
                  from several sources---a calendar, a paper flyer,
                  web sites, a previous email conversation, etc. This
                  information is fragmented by the very tools that
                  have been designed to help us manage
                  it. Applications often store their data in their own
                  particular locations and representations,
                  inaccessible to other applications. Consider the
                  information Alex maintains about Brooke. He must
                  keep Brooke's address in his address book, his
                  picture in a photo album, his home page in his web
                  bookmarks, a birthday invitation he is editing with
                  her in his file system, and an appointment with her
                  in his calendar.  This fragmentation causes numerous
                  problems. There is no one "directory" Alex can use
                  to find all the information about Brooke; nor any
                  way to "link" pieces of information about Brooke to
                  each other. Instead, Alex must launch multiple
                  applications and perform numerous repetitive
                  searches for relevant information, to say nothing of
                  deciding which applications to look in. He may
                  change data in one place (a new married name in the
                  address book) and fail to change it elsewhere,
                  leading to inconsistency that makes it even harder
                  to find information (which name does Alex use to
                  search the photo album?).  While the computer has
                  fragmented information, it can also be used to put
                  the pieces together again. This chapter surveys some
                  of the ways in which our personal information might
                  be better unified.},
  pdf =          {Papers/pimchapter.pdf},
  address = 	 {Seattle, WA},
  chapter = 	 8
}

@inproceedings{Karger:TieStrength,
 author = {Panovich, Katrina and Miller, Rob and Karger, David},
 title = {Tie strength in question \& answer on social network
                  sites},
 booktitle = {Proceedings of the ACM 2012 conference on Computer
                  Supported Cooperative Work},
 series = {CSCW '12},
 cat:multiple = {CHI;Information Retrieval},
 venue = {CSCW},
 year = {2012},
 isbn = {978-1-4503-1086-4},
 location = {Seattle, Washington, USA},
 pages = {1057--1066},
 numpages = {10},
 doi = {10.1145/2145204.2145361},
 acmid = {2145361},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {q\&\#38;a, social network q\&\#38;a., social networks,
                  social search},
}

@article{Karger:TwitinfoSigmod,
 author = {Marcus, Adam and Bernstein, Michael S. and Badar, Osama and
                  Karger, David R. and Madden, Samuel and Miller,
                  Robert C.},
 title = {Processing and visualizing the data in tweets},
 journal = {SIGMOD Record},
 issue_date = {December 2011},
 cat:multiple = {CHI;Systems;Information Retrieval},
 volume = {40},
 number = {4},
 month = jan,
 year = {2012},
 issn = {0163-5808},
 pages = {21--27},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/2094114.2094120},
 doi = {10.1145/2094114.2094120},
 acmid = {2094120},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{Karger:TurkBudgetMatrix,
  author = {David R. Karger and Sewoong Oh and Devavrat Shah},
  title = {Budget-Optimal Crowdsourcing using Low-rank Matrix
                  Approximations},
  booktitle = {$49^th$ Annual Conference on Communication, Control,
                  and Computing (Allerton)},
  pages = {284-291},
  cat:multiple = {Applications of Theory;Coding;Machine
                  Learning;Theory;Crowdsourcing},
  venue = {Allerton},
  year = 2011,
  month = sep,
  pdf = {https://netfiles.uiuc.edu/swoh/www/paper_crowdsourcing_allerton.pdf}
}

@inproceedings{Karger:CrowdQueuing,
  author    = {Michael S. Bernstein and
               David R. Karger and
               Robert C. Miller and
               Joel Brandt},
  title     = {Analytic Methods for Optimizing Realtime
                  Crowdsourcing},
  booktitle = {Collective Intelligence},
  cat:multiple = {Applications of Theory;Theory;Crowdsourcing},
  year      = {2012},
  month     = apr,
  pdf       = {http://arxiv.org/pdf/1204.2995v1},
  url       = {http://arxiv.org/abs/1204.2995}
}

@inproceedings{Karger:TurkBudget,
  author = {David R. Karger and Sewoong Oh and Devavrat Shah},
  title = {Iterative Learning for Reliable Crowd-sourcing Systems},
  booktitle = {$25^{th}$ Annual Conference on Neural
                  Information Processing Systems (NIPS)},
  venue = {NIPS},
  cat:multiple = {Applications of Theory;Coding;Machine Learning;Theory;Crowdsourcing},
  month = dec,
  year = {2011}
}

@InCollection{Karger:DesktopBook,
  author = 	 {David R. Karger},
  title = 	 {Haystack: Per-User Information Environments},
  booktitle = 	 {Beyond the Desktop Metaphor: Designing Integrated Digital Work Environments},
  pages = 	 {49-100},
  publisher = {The MIT Press},
  year = 	 2007,
  cat:multiple = {Haystack;Systems;Information Retrieval;Semantic Web},
  editor = 	 {Victor Kaptelinin and Mary Czerwinski},
  abstract= {Haystack is a system that aims to maximize every individual user's
control over the way he or she records, views, organizes, and searches for
information.  In this paper we discuss the elements of the system: a
flexible semantic-net data model that can stretch to accomodate
whatever information, relationships, properties, and categories a user
considers important, and a user interface framework that can
effecively display the personalized information space in ways that
make sense to and can be customized by the end user.},
  pdf =          {Papers/desktopchapter.pdf},
  chapter = 	 7,
  address = 	 {Cambridge, MA}}


@misc{Karger:Doing,
  author= {Michael S. Bernstein and Van Kleek, Max and m. c. schraefel
                  and David R. Karger},
  title = {Management of personal information scraps},
  booktitle={CHI Extended Abstracts},
  year = 2007,
  pages ={2285-2290},
  month = may,
  cat = {Information Retrieval},
  cat = {CHI},
  venue = {CHI},
  pdf = {http://people.csail.mit.edu/emax/papers/infoscraps_WIP_chi2007.pdf},
  note = {Poster.},
  pub-type={Poster},
abstract = {We introduce research on information scraps. short, self-contained personal notes that fall outside of traditional filing schemes. We report on a preliminary study of information scraps. nature and outline plans for the next phase of our user study. Based on ongoing study results, we describe our designs and prototypes for information scrap capture and access tools.}
}

@InProceedings{Karger:Detours,
  author = 	 {Aaron Bernstein and David Karger},
  title = 	 {Improved Distance Sensitivity Oracles via Random Sampling},
  crossref =  {SODA08},
  cat={Theory},
  abstract={We present improved oracles for the distance sensitivity
                  problem. The goal is to preprocess a graph $G = (V,E)$
                  with non-negative edge weights to answer queries of
                  the form: what is the length of the shortest path
                  from x to y that does not go through some failed
                  vertex or edge f. There are two state of the art
                  algorithms for this problem. The first produces an
                  oracle of size $O(n^2)$ that has an O(1) query time,
                  and an $O(mn^2)$ construction time. The second oracle
                  has size $O(n^{2.5})$, but the construction time is only
                  mn1.5). We present two new oracles that
                  substantially improve upon both of these
                  results. Both oracles are constructed with
                  randomized, Monte Carlo algorithms. For directed
                  graphs with non-negative edge weights, we present an
                  oracle of size $O(n^2)$, which has an $O(1)$ query
                  time, and an $O(n^2m)$ construction time. For
                  unweighted graphs, we achieve a more general
                  construction time of $O(n^{3/2) \cdot APSP + mn)$, where
                  APSP is the time it takes to compute all pairs
                  shortest paths in an aribtrary subgraph of $G$.},
  pdf={Papers/detour.pdf},
  pages = {34-43}
}
}
@misc{Karger:UnsupervisedRecords,
  author = {Yuan Kui Shen and David R. Karger},
  title ={ {U-REST}: an unsupervised record extraction system},
  crossref = {www07},
  pages = {1347-1348},
  cat:multiple = {Machine Learning;Information Retrieval},
  pdf = {https://www2007.cpsc.ucalgary.ca/posters/poster1005.pdf},
pub-type={Poster},
  note = {Poster.},
abstract = {We demonstrate a system that extracts record sets from record-list web pages with no direct human supervision. Our system, U-REST, reframes the problem of unsupervised record extraction as a two-phase machine learning problem with a clustering phase, where structurally similar regions are discovered, and a record cluster detection phase, where discovered grouping of regions are ranked by their likelihood of being records. This framework simplifies the record extraction task, and allows for independent analysis of the algorithms and the underlying features. In our work, we survey a large set of features under this simplified framework. We conclude with an preliminary comparison of U-REST against similar systems and show improvements in the extraction accuracy.}
}

@article{Karger:Optical,
 author = {David Karger and Muriel M\'{e}dard},
 title= {Toward Using the Network as a Switch},
 journal = {IEEE Journal on Selected Areas in Communications: Optical
Communications and Networking Series},
 volume = 23,
 number = 8,
 year = 2005,
  cat:multiple = {Theory;Applications of Theory;Cuts and Flows},
 month = aug,
 pages = {1533--1541},
abstract = {A common problem in optical networking is that the large quantity of raw bandwidth available in such networks is often difficult to access. We show that time-division multiplexing (TDM) can be used to operate bus and ring architectures in a manner akin to a switch. Doing so substantially reduces the amount of hardware [particularly, add-drop multiplexers (ADMs)] needed to utilize fully the available bandwidth in a range of optical networks. We show that a significant fraction (and in some cases all) of the bandwidth available to the system can be utilized even if each node in the system has only a single ADM. Our approach is probabilistic in nature, using generalizations of the Birkhoff-von Neumann statistical multiplexing approaches that have been successful in switching theory. Our techniques rely on decompositions of fractional matchings (for architectures without erasures) and fractional interval graph colorings (for architectures with erasures) into integral matchings and colorings.}
 }

@InProceedings{deshpande-barzilay-karger:2007:main,
  author    = {Deshpande, Pawan  and  Barzilay, Regina  and  Karger, David},
  title     = {Randomized Decoding for Selection-and-Ordering Problems},
  booktitle = {Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference},
  month     = apr,
  year      = {2007},
  address   = {Rochester, New York},
  publisher = {Association for Computational Linguistics},
  pages     = {444--451},
  cat = {Applications of Theory},
  venue = {NAACL},
  pdf       = {ordering.pdf},
abstract = {The task of selecting and ordering information appears in multiple contexts in text
generation and summarization. For instance, methods for title generation construct
a headline by selecting and ordering words from the input text. In this paper,
we investigate decoding methods that simultaneously optimize selection and ordering
preferences. We formalize decoding as a task of finding an acyclic path in a directed weighted graph. Since the problem is NP-hard, finding an exact solution is challenging. We describe a novel decoding method based on a randomized color-coding algorithm. We prove bounds on the number of color-coding iterations necessary to guarantee any desired likelihood of finding the correct solution. Our experiments show that the randomized decoder is an appealing alternative to a range of decoding algorithms for selection-and-ordering problems, including beam search and Integer Linear Programming.}

}

@misc{Karger:Relo,
 author = {Vineet Sinha and Robert C. Miller and David Karger},
 title = {Incremental exploratory visualization of relationships in large codebases for program comprehension},
 booktitle = {OOPSLA'05 Eclipse Technology eXchange (ETX) Workshop},
 crossref = {oopsla05companion},
 pages = {116--117},
 cat = {CHI},
 doi = {http://doi.acm.org/10.1145/1094855.1094891},
 pdf = {http://relo.csail.mit.edu/documentation/relo-etx05.pdf},
abstract = { As software systems grow in size and use more third-party libraries and frameworks, the need for developers to understand unfamiliar large codebases is rapidly increasing. In this poster, we present a tool, Relo that supports users' understanding by allowing interactive exploration of code. As the developer explores relationships found in the code, Relo builds and automatically manages a visualization mirroring the developer's mental model, allowing them to group viewed artifacts or use the viewed items to ask the system for further exploration suggestions.}
}

@inproceedings{Karger:FightFire,
   author =       "Michael Walfish and Hari Balakrishnan and
         David Karger and Scott Shenker",
   title =        {{DoS:} Fighting Fire with Fire},
   cat     =      {Systems},
   pdf = {http://nms.csail.mit.edu/papers/fightfire-hotnets-2005.pdf},
   crossref = {hotnets05},
abstract = {We consider DoS attacks on servers in which attackers' requests are indistinguishable from legitimate requests. Most current defenses against this class of attack rely on legitimate users in aggregate having more of some resource (CPU cycles, memory cycles, human attention, etc.) than attackers. A server so defended asks prospective clients to prove their legitimacy by spending some of this resource. We adopt this general approach but use bandwidth as the constrained resource. Specifically, we argue that when a server is attacked, it should: (1) prevent overloading by limiting the incoming rate of requests (and dropping all others) and (2) encourage its legitimate clients to fight back with aggressive retransmission. This approach forces all clients to spend bandwidth to receive service, and the legitimate clients, with their greater aggregate bandwidth, will receive the bulk of the service.}
}

@inproceedings{Karger:Phooey,
 author = {Van Kleek, Max and Michael Bernstein and David R. Karger and
                  mc schraefel},
 venue = "UIST",
  cat:multiple = {Information Retrieval;Semantic Web;CHI;Haystack},
 title = {{GUI} --- Phooey!: The Case for Text Input},
 booktitle = {UIST '07: Proceedings of the 20th annual ACM symposium
                  on User interface software and technology},
 year = {2007},
 month = oct,
 isbn = {978-1-59593-679-2},
 pages = {193--202},
 location = {Newport, Rhode Island, USA},
 doi = {http://doi.acm.org/10.1145/1294211.1294247},
 pdf = {http://people.csail.mit.edu/msbernst/papers/p337-vankleek.pdf},
 video = {http://people.csail.mit.edu/msbernst/videos/uist07-jourknow.mov},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@inproceedings{Heer:Profiler,
 author = {Kandel, Sean and Parikh, Ravi and Paepcke, Andreas and
                  Hellerstein, Joseph M. and Heer, Jeffrey},
 title = {Profiler: integrated statistical analysis and visualization
                  for data quality assessment},
 booktitle = {Proceedings of the International Working Conference on
                  Advanced Visual Interfaces},
 series = {AVI '12},
 year = {2012},
 month = may,
 isbn = {978-1-4503-1287-5},
 location = {Capri Island, Italy},
 pages = {547--554},
 numpages = {8},
 url = {http://vis.stanford.edu/papers/profiler},
 doi = {10.1145/2254556.2254659},
 acmid = {2254659},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {anomaly detection, data analysis, data quality,
                  visualization},
}


@inproceedings{Nusser:FastEmail,
 author = {Nusser, Stefan and Cerruti, Julian and Wilcox, Eric and Cousins, Steve and Schoudt, Jerald and Sancho, Sergio},
 title = {Enabling efficient orienteering behavior in webmail clients},
 booktitle = {Proceedings of the 20th annual ACM symposium on User interface software and technology},
 series = {UIST '07},
 year = {2007},
 isbn = {978-1-59593-679-0},
 location = {Newport, Rhode Island, USA},
 pages = {139--148},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1294211.1294235},
 doi = {10.1145/1294211.1294235},
 acmid = {1294235},
 publisher = {ACM},
 hideaddress = {New York, NY, USA},
 keywords = {ajax, dojo, email, personal information management, systems design, webmail},
}

@inproceedings{Karger:Pathetic,
  author = {David R. Karger and m. c. schraefel},
  title = {The Pathetic Fallacy of RDF},
  booktitle ={ SWUI 2006 - 3rd International Semantic Web User
                  Interaction Workshop},
  venue = {SWUI},
  cat:multiple = {CHI;Information Retrieval;Semantic Web},
  month = nov,
  year = 2006,
  location = {Athens, Georgia, USA},
  note ={collocated with ISWC 2006},
  url =  {http://swui.semanticweb.org/swui06/papers/Karger/Pathetic_Fallacy.html}
}

@inproceedings{Karger:VCGOverpayment,
   author = {Evdokia Nikolova and David R. Karger},
   title = {On the Expected VCG Overpayment in Large Networks},
   booktitle = {45th IEEE Conference on Decision and Control},
   cat = {Theory},
   pdf = {http://people.csail.mit.edu/enikolova/papers/cdc-6pages.pdf},
   year = {2006},
   month = dec,
   pages = {2831--2836},
   doi = {http://dx.doi.org/10.1109/CDC.2006.377149},
   venue = {DC}
   }

@InProceedings{Karger:UncertainShortestPaths,
  author = 	 {Evdokia Nikolova and Matthew Brand and and David Karger},
  title = 	 {Optimal Route Planning under Uncertainty},
  booktitle =	 {Proceedings of 2006 International Conference on
                  Automated Planning and Scheduling (ICAPS 2006)},
  year =	 2006,
  month = jun,
  venue = {ICAPS},
  pdf =          {ICAPS0602NikolovaE.pdf},
  cat =          {Theory},
abstract = {We present new complexity results and efficient algorithms for optimal route planning in the presence of uncertainty. We employ a decision theoretic framework for defining the optimal route: for a given source S and destination T in the graph, we seek an ST-path of lowest expected cost where the edge travel times are random variables and the cost is a nonlinear function of total travel time. Although this is a natural model for route-planning on real-world road networks, results are sparse due to the analytic difficulty of finding closed form expressions for the expected cost, as well as the computational/combinatorial difficulty of efficiently finding an optimal path which minimizes the expected cost. We identify a family of appropriate cost models and travel time distributions that are closed under convolution and physically valid. We obtain hardness results for routing problems with a given start time and cost functions with a global minimum, in a variety of deterministic and stochastic settings. In general the global cost is not separable into edge costs, precluding classic shortest-path approaches. However, using partial minimization techniques, we exhibit an efficient solution via dynamic programming with low polynomial complexity.}
}

@misc{Apple:Hypercard,
  author = {Apple Computer},
  title={Hypercard Software \& User's Manual},
  year = {1987--1998}}




@Article{English:Interleaf,
  author = 	 {Paul M. English and Raman Tenneti},
  title = 	 {Interleaf Active Documents},
  journal = 	 {Electronic Publishing},
  year = 	 1994,
  volume = 	 7,
  number = 	 2,
  pages = 	 {75--87},
  month = 	 jun}

@InProceedings{Karger:Walsh,
  author = 	 {A. Chan and Jon Feldman and Raghu Madyastha and
                  Piotr Indyk and David Karger},
  title = 	 {Local Decoding of Walsh Codes to Reduce CDMA Despreading Computation},
  booktitle =	 {Sotware Defined Radio Technical Conference},
  year =	 2005,
  address =	 {Orange County, CA},
  month =	 nov,
venue = {SDR},
  cat =          {Coding},
  pdf = {http://www.vanu.com/wp-content/resources/publications/2.1-01\%20Chan_SDR05.pdf},
  cat:multiple =	{Applications of Theory;Machine Learning},
abstract = {In traditional hardware implementations of the CDMA
standard IS-95 [1], signals received at the base station are
despread at a rate of 1.2288 Megachips/sec prior to Walsh
decoding. However, in a software implementation where low
computational complexity is critical, despreading at such a
high rate imposes a strain on computational resources. In
this paper, we take advantage of the flexibility afforded by
software implementations and develop three classes of
Walsh decoding algorithms that do not require full
despreading of incoming signals at the base station. Two
proposed classes of algorithms exploit the fact that Walsh
codes are locally decodable codes, which have the surprising
property that any bit of the message can be recovered (with
some probability) by examining only a small number of
symbols of the codeword. We also describe a third class of
algorithms based on code puncturing. All these algorithms
enable trading off computation for performance or, from
another perspective, they enable the system to dynamically
adapt the computational requirements of the despreader and
subsequent Walsh decoder to changing channel conditions
such that a target bit-error rate (BER) is maintained. These
algorithms are applicable to other CDMA-based systems
that use Walsh codes for orthogonal modulation, and the
third class is also applicable to CDMA-based systems such
as UMTS (3G WCDMA) that use codes for channelization
}
}

@InProceedings{Karger:OverCite,
  author = 	 {Jeremy Stribling and Isaac G. Councill and Jinyang Li and M. Frans Kaashoek and David R. Karger and  Robert Morris and Scott Shenker},
  title = 	 {OverCite: A Cooperative Digital Research Library},
  crossref =	 {iptps05},
  doi = {http://dx.doi.org/10.1007/11558989_7},
  pdf = {http://pdos.csail.mit.edu/papers/overcite:iptps05/paper.pdf},
  location = {Ithaca, NY},
  pages =	 {69--79},
  cat:multiple =	{Systems;P2P},
abstract = {CiteSeer is a well-known online resource for the computer science research community, allowing users to search and browse a large archive of research papers. Unfortunately, its current centralized incarnation is costly to run. Although members of the community would presumably be willing to donate hardware and bandwidth at their own sites to assist CiteSeer, the current architecture does not facilitate such distribution of resources. OverCite is a design for a new architecture for a distributed and cooperative research library based on a distributed hash table (DHT). The new architecture harnesses donated resources at many sites to provide document search and retrieval service to researchers worldwide. A preliminary evaluation of an initial OverCite prototype shows that it can service more queries per second than a centralized system, and that it increases total storage capacity by a factor of n/4 in a system of n nodes. OverCite can exploit these additional resources by supporting new features such as document alerts, and by scaling to larger data sets.}
}

@InProceedings{Karger:Arpeggio,
  author = 	 {Austin T. Clements and Dan R. K. Ports and David R. Karger},
  title = 	 {Arpeggio: Metadata Searching and Content Sharing with Chord},
  crossref =	 {iptps05},
  doi = {http://dx.doi.org/10.1007/11558989_6},
  pdf = {http://project-iris.net/irisbib/papers/arpeggio:iptps05/paper.pdf},
  pages =	 {58--68},
  cat:multiple =	{Systems;P2P},
abstract = {Arpeggio is a peer-to-peer file-sharing network based on
the Chord lookup primitive. Queries for data whose metadata
matches a certain criterion are performed efficiently
by using a distributed keyword-set index, augmented with
index-side filtering. We introduce index gateways, a technique
for minimizing index maintenance overhead. Because
file data is large, Arpeggio employs subrings to track
live source peers without the cost of inserting the data itself
into the network. Finally, we introduce postfetching, a
technique that uses information in the index to improve the
availability of rare files. The result is a system that provides
efficient query operations with the scalability and reliability
advantages of full decentralization, and a content
distribution system tuned to the requirements and capabilities
of a peer-to-peer network.}

}

@article{dht:cacm03,
  title = {Looking up data in P2P systems},
  author = {Hari Balakrishnan and M. Frans Kaashoek and David Karger and Robert
Morris and Ion Stoica},
  journal = cacm,
  year = {2003},
  month = feb,
  pdf = {http://project-iris.net/irisbib/papers/dht:cacm03/paper.pdf},
  cat:multiple =	{Systems;P2P},
abstract = {The main challenge in P2P computing is to design and implement a robust and scalable distributed system composed of inexpensive, individually unreliable computers in unrelated administrative domains.},
abstract = {The main challenge in P2P computing is to design and implement a robust and scalable distributed system composed of inexpensive, individually unreliable computers in unrelated administrative domains. The participants in a typical P2P system might include computers at homes, schools, and businesses, and can grow to several million concurrent participants.}

}

@inproceedings{Karger:SubjectiveCostRouting,
   author = {Joan Feigenbaum and David R. Karger and Vahab S. Mirrokni and Rahul Sami},
   title = {Subjective Cost Policy Routing},
   booktitle = {Internet and Network Economics: First International Workshop, WINE 2005},
   year = {2005},
   month = dec,
   pages = {174--183},
   venue={WINE},
   doi = {http://dx.doi.org/10.1007/11600930_18},
   cat:multiple =	{Theory; Mechanism Design},
abstract = {We study a model of path-vector routing in which nodes' routing policies are based on subjective cost assessments of alternative routes. The routes are constrained by the requirement that all routes to a given destination must be confluent. We show that it is NP-hard to determine whether there is a set of stable routes. We also show that it is NP-hard to find a set of confluent routes that minimizes the total subjective cost; it is hard even to approximate the minimum cost closely. These hardness results hold even for very restricted classes of subjective costs.

We then consider a model in which the subjective costs are based on the relative importance nodes place on a small number of objective cost measures. We show that a small number of confluent routing trees is sufficient for each node to have a route that nearly minimizes its subjective cost. We show that this scheme is trivially strategy proof and that it can be computed easily with a distributed algorithm. Furthermore, we prove a lower bound on the number of trees required to contain a (1+epsilon (Porson))-approximately optimal route for each node and show that our scheme is nearly optimal in this respect. }
}


@article{Karger:SubjectiveCostRouting-Journal,
   author = {Joan Feigenbaum and David R. Karger and Vahab S. Mirrokni and Rahul Sami},
   title = {Subjective Cost Policy Routing},
   journal = {Theoretical Computer Science},
   volume = 378,
   number =2,
   month = jun,
   pages = {175-189},
   year = {2007},
   pages = {174--183},
   doi = {http://dx.doi.org/10.1007/11600930_18},
   pdf = {http://cs-www.cs.yale.edu/homes/jf/FKMS.pdf},
   ps = {http://www.umich.edu/~rsami/papers/wine.ps},
   cat:multiple =	{Theory; Mechanism Design},
   abstract = {We study a model of interdomain routing in which autonomous systems' (ASes') routing policies are based on {\em subjective} cost assessments of alternative routes. The routes are constrained by the requirement that all routes to a given destination must be confluent. We show that it is NP-hard to determine whether there is a set of stable routes. We also show that it is NP-hard to find a set of confluent routes that minimizes the total subjective cost; it is hard even to approximate minimum cost closely. These hardness results hold even for very restricted classes of subjective costs. We then consider a model in which the subjective costs are based on the relative importance ASes place on a small number of objective cost measures. We show that a small number of confluent routing trees is sufficient for each AS to have a route that nearly minimizes its subjective cost; these routing trees can be computed easily with a distributed algorithm. Furthermore, we prove that this bound is almost tight.}
}



@inproceedings{Karger:FirstPathAuction,
 author = {Nicole Immorlica and David Karger and Evdokia Nikolova and
                  Rahul Sami},
 title = {First-price path auctions},
 booktitle = {EC '05: Proceedings of the 6th ACM conference on
                  Electronic commerce},
venue={EC},
  month = jun,
 year = {2005},
 isbn = {1-59593-049-3},
 pages = {203--212},
 location = {Vancouver, BC, Canada},
 doi = {http://doi.acm.org/10.1145/1064009.1064031},
 publisher = {ACM Press},
 address = {New York, NY, USA},
   cat:multiple =	{Theory; Mechanism Design},
 ps = {http://www.umich.edu/~rsami/papers/PAdraft.ps},
 abstract = {We study first-price auction mechanisms for auctioning flow between given nodes in a graph. We assume edges are independent agents with fixed capacities and costs, and their objective is to maximize their profit. We characterize all {\it strong $\epsilon$-Nash equilibria} of a first-price auction for this problem, and show that the total payment is never significantly more than, and often less than, the well known dominant strategy Vickrey-Clark-Groves (VCG) mechanism. We then present a randomized version of the first-price auction, for which the equilibrium condition can be relaxed to $\epsilon$-Nash equilibrium. We next consider a model in which the amount of demand is uncertain, but its probability distribution is known to the edges. For this model, we show that a simple {\em ex ante} first-price auction may not have any $\epsilon$-Nash equilibria. We then present a modified auction mechanism with $2$-parameter bids, and show that it has an $\epsilon$-Nash equilibrium.}
 }


@InProceedings{Hogue:Wrapper,
  author = 	 {Andrew Hogue and David Karger},
  title = 	 {Wrapper Induction for End-User Semantic Content Development},
  booktitle =	 {Interaction and Design for the Semantic Web Workshop
                  at the $13^{th}$ annual World Wide Web Conference},
  cat:multiple =	{Haystack;Information Retrieval;Semantic Web;Machine Learning},
  year =	 2004,
  month = may,
  address =	 {New York, NY},
venue={WWW},
abstract = {The transition from existingWorld WideWeb content to the
Semantic Web relies on the labeling and classification of existing
information before it is useful to end-users and their
agents. This paper presents a wrapper induction system
designed to allow end-users to create, modify, and utilize semantic
patterns on unlabeled World Wide Web documents.
These patterns allow users to overlay documents with RDF
classes and properties, and then to interact with this labeled
content within a larger Semantic Web application, such as
Haystack.}
}

@InProceedings{Hogue:Thresher,
  author = 	 {Andrew Hogue and David Karger},
  title = 	 {Thresher: Automating the Unwrapping of Semantic
                  Content from the World Wide Web},
  pages =        {86--95},
  month = may,
  cat:multiple =	{Haystack;Information Retrieval;Semantic Web;Machine Learning},
  pdf = {http://haystack.lcs.mit.edu/papers/www2005-thresher.pdf},
  crossref = {www05},
abstract = {We describe Thresher, a system that lets non-technical users
teach their browsers how to extract semantic web content
from HTML documents on the World Wide Web. Users
specify examples of semantic content by highlighting them
in a web browser and describing their meaning. We then use
the tree edit distance between the DOM subtrees of these examples
to create a general pattern, or wrapper, for the content,
and allow the user to bind RDF classes and predicates
to the nodes of these wrappers. By overlaying matches to
these patterns on standard documents inside the Haystack
semantic web browser, we enable a rich semantic interaction
with existing web pages, \unwrapping" semantic data
buried in the pages' HTML. By allowing end-users to create,
modify, and utilize their own patterns, we hope to speed
adoption and use of the Semantic Web and its applications.}

}

@article{Karger:Tox1,
   author = {Edward W. Boyer and Kai Shih and David R. Karger and L. Quang
                  and P. Case},
   title = {Internet Surveillance of Pro-drug Websites. I.
                  Incidence of Club Drug Reporting Over a One-year
                  Period.},
   journal = {Journal of Toxicology: Clinical Toxicology},
   year = {2001},
   volume = {39},
   pages = {536},
   note={(abstract)},
   cat = {Information Retrieval}
}

@article{Karger:Tox2,
   author = {Edward W. Boyer and Kai Shih and David R. Karger and L. Quang
                  and P. Case},
   title = {Internet Surveillance of Pro-drug Websites. II.
                  Identification of Emerging Drug Use Trends.},
   journal = {Journal of Toxicology: Clinical Toxicology},
   year = {2001},
   volume = {39},
   pages = {537},
   note={(abstract)},
   cat = {Information Retrieval}
}

@article{Karger:Tox3,
   author = {Edward W. Boyer and Kai Shih and David R. Karger and L. Quang
                  and P. Case},
   title = {Internet Surveillance of Pro-drug Websites. III.
                  Identification of Emerging Drugs of Abuse.},
   journal = {Journal of Toxicology: Clinical Toxicology},
   year = {2001},
   volume = {39},
   pages = {537},
   note={(abstract)},
   cat = {Information Retrieval}
}

@InCollection{Karger:RandomizationHandbook,
  author = 	 {David R. Karger},
  title = 	 {Random Sampling in Graph Optimization Problems: A Survey},
  booktitle = 	 {Handbook on Randomization},
  publisher = {Kluwer Academic Press},
  year = 	 2001,
  ps = {Papers/random.ps},
  psgz={Papers/random.ps.gz},
  basefilename={random},
  editor = 	 {S. Rajasekaran and P. Pardalos and J.H. Reif and
                  J. Rolim},
  cat = {Theory},
abstract = {Randomization has become a pervasive technique in combinatorial optimization. We survey our thesis and subsequent work, which uses four common randomization techniques to attack numerous optimization problems on undirected graphs. 1 Introduction Randomization has become a pervasive technique in combinatorial optimization. Randomization has been used to develop algorithms that are faster, simpler, and/or better-performing than previous deterministic algorithms.}
}

@inproceedings{Spielman:Compression-quadratic,
 author = {Spielman, Daniel A. and Srivastava, Nikhil},
 title = {Graph sparsification by effective resistances},
 crossref={STOC08},
 pages = {563--568},
 }

@inproceedings{Batson:Compression-sparse,
  author    = {Joshua D. Batson and
               Daniel A. Spielman and
               Nikhil Srivastava},
  title     = {Twice-ramanujan sparsifiers},
  pages     = {255-262},
  doi        = {http://doi.acm.org/10.1145/1536414.1536451},
  crossref  = {STOC09},
  bibsource = {DBLP, http://dblp.uni-trier.de}}


@InProceedings{Karger:Koorde-IPTPS,
  author = 	 {M. Frans Kaashoek and David R. Karger},
  title = 	 {Koorde: A Simple Degree-Optimal Distributed Hash Table},
  crossref =	 {iptps03},
  link = {http://www.springerlink.com/index/UNMQCQY0YXPU32XP},
  ps = {http://iptps03.cs.berkeley.edu/finalpapers/koorde.ps},
abstract={Koorde is a new distributed hash table (DHT) based on
Chord and the de Bruijn graphs.
While inheriting the simplicity of Chord, Koorde meets various lower
bounds, such as $O(\log n)$ hops per lookup request with only 2
neighbors per node (where $n$ is the number of nodes in the DHT), and
$O(\log n/\log\log n)$ hops per lookup request with $O(\log n)$
neighbors per node.},
   cat:multiple =	{Theory;Systems; P2P; Applications of Theory},
abstract = {Koorde is a new distributed hash table (DHT) based on Chord [15] and the de Bruijn graphs [2]. While inheriting the simplicity of Chord, Koorde meets various lower bounds, such as O(log n) hops per lookup request with only 2 neighbors per node (where n is the number of nodes in the DHT), and O(log n/ log log n) hops per lookup request with O(log n) neighbors per node.}
}

@inproceedings{twine:pervasive02,
  title = {INS/Twine: A Scalable Peer-to-Peer Architecture for Intentional
Resource Discovery},
  author = {Magdalena Balazinska and Hari Balakrishnan and David Karger},
  booktitle = {Proceedings of the International Conference on Pervasive
Computing (Pervasive 2002)},
  venue = {Pervasive},
  year = {2002},
  month = aug,
  address = {Zurich, Switzerland},
  pdf = {http://project-iris.net/irisbib/papers/twine:pervasive02/paper.pdf},
  cat:multiple =	{Systems; P2P},
abstract = {The decreasing cost of computing technology is speeding the deployment of abundant ubiquitous computation and communication.}
}

@incollection{Karger:ABCO,
	author = {Michel X. Goemans and David R. Karger and Jon
Kleinberg},
	title = {Randomized Algorithms},
	booktitle = {Annotated Bibliographies in Combinatorial Optimization},
	editor = {Mauro Dell'Amico and Francesco Maffioli and
	   Silvano Martello},
	isbn = {0-471-96574-X},
	month = aug,
	publisher = {John Wiley \& Sons},
        cat = {Theory},
	year = 1997}

@inproceedings{Karger:Approxcut,
	author = karger,
	title = {Using Randomized Sparsification to Approximate
Minimum Cuts},
	crossref = {SODA94},
	pages = {424--432},
        ps={Papers/approxcut.ps},
        psgz={Papers/approxcut.ps.gz},
        cat:multiple =	{Theory; Cuts and Flows},
        abstract =  {We develop new parallel and dynamic algorithms for approximating
minimum cuts in weighted, undirected graphs.  Our approach is to
combine new algorithms for sparse unweighted graphs with a reduction
for dense weighted graphs called {\em randomized sparsification}.
Randomized sparsification yields a sparse unweighted graph that
closely approximates the minimum cut structure of the original graph.
In~\cite{Karger:Skeleton}, this techniques was used in sequential
algorithms for approximating the minimum cut.  In this paper we devise
parallel and dynamic approximation algorithms.  We show that a cut
within a multiplicative factor of $\alpha$ of the minimum can be found
in $\RNC$ using $m+n^{2/\alpha}$ processors.  Using similar
techniques, we give a {\em dynamic approximation algorithm} for a
graph undergoing a series of edge insertions and deletions.  At a cost
of $\Olog(n/\epsilon^2)$ time per insertion or deletion, the
algorithm will maintain a cut with value at most $(1+\epsilon)$ times
the minimum.

We also consider a functional inverse of randomized sparsification,
and use it to develop a different dynamic algorithm that approximates
the value of the minimum cut more quickly than the previous algorithm,
but does not actually exhibit a cut of small value.  An
$O(\sqrt{1+2/\epsilon})$-approximation to the minimum cut value is
maintained at a cost of $\Olog(n^{\epsilon+1/2})$ time per insertion
or deletion.  If only insertions are allowed, the approximation can be
maintained at a cost of $\Olog(n^{\epsilon})$ time per insertion.}
}


@InProceedings{Karger:SemApps,
  author = 	 {Dennis Quan and David Huynh and David R. Karger},
  title = 	 {Haystack: A Platform for authoring End-User Semantic
                  Web Applications},
  pages =        {738--753},
  link = {http://www.springerlink.com/index/H74TVQB63J2DF9W8},
  studentwork = student,
  crossref =	 {iswc03},
  url={http://haystack.csail.mit.edu/papers/iswc2003-haystack},
	confurl = "http://iswc2003.semanticweb.org/",
pdf = "http://haystack.lcs.mit.edu/papers/iswc2003-haystack.pdf",
	pdfkb = "153",
  cat:multiple =	{Information Retrieval;Haystack; Semantic Web},
abstract={The Semantic Web promises to open innumerable opportunities
                  for automation and information retrieval by
                  standardizing the protocols for metadata
                  exchange. However, just as the success of the World
                  Wide Web can be attributed to the ease of use and
                  ubiquity of Web browsers, we believe that the
                  unfolding of the Semantic Web vision depends on
                  users getting powerful but easy-to-use tools for
                  managing their information. But unlike HTML, which
                  can be easily edited in any text editor, RDF is more
                  complicated to author and does not have an obvious
                  presentation mechanism. Previous work has
                  concentrated on the ideas of generic RDF graph
                  visualization and RDF Schema-based form
                  generation. In this paper, we present a
                  comprehensive platform for constructing end user
                  applications that create, manipulate, and visualize
                  arbitrary RDF-encoded information, adding another
                  layer to the abstraction cake. We discuss a
                  programming environment specifically designed for
                  manipulating RDF and introduce user interface
                  concepts on top that allow the developer to quickly
                  assemble applications that are based on RDF data
                  models. Also, because user interface specifications
                  and program logic are themselves describable in RDF,
                  applications built upon our framework enjoy
                  properties such as network updatability,
                  extensibility, and end user customizability---all
                  desirable characteristics in the spirit of the
                  Semantic Web. }
}

@InProceedings{Karger:SemBrowser,
  author = 	 {Dennis Quan and David R. Karger},
  title = 	 {How to Make a Semantic Web Browser},
  crossref = {www04},
  pages =        {255--265},
  pdf={http://www2004.org/proceedings/docs/1p255.pdf},
  cat:multiple =	{Information Retrieval;Haystack; Semantic Web},
  abstract={Two important architectural choices underlie the success
                  of the Web: numerous, independently operated servers
                  speak a common protocol, and a single type of
                  client-the Web browser-provides point-and-click
                  access to the content and services on these
                  decentralized servers. However, because HTML marries
                  content and presentation into a single
                  representation, end users are often stuck with
                  inappropriate choices made by the Web site designer
                  of how to work with and view the content. RDF
                  metadata on the Semantic Web does not have this
                  limitation: users can gain direct access to the
                  underlying information and control how it is
                  presented for themselves. This principle forms the
                  basis for our Semantic Web browser-an end user
                  application that automatically locates metadata and
                  assembles point-and-click interfaces from a
                  combination of relevant information, ontological
                  specifications, and presentation knowledge, all
                  described in RDF and retrieved dynamically from the
                  Semantic Web. With such a tool, naive users can
                  begin to discover, explore, and utilize Semantic Web
                  data and services. Because data and services are
                  accessed directly through a standalone client and
                  not through a central point of access (e.g., a
                  portal), new content and services can be consumed as
                  soon as they become available. In this way we take
                  advantage of an important sociological force that
                  encourages the production of new Semantic Web
                  content by remaining faithful to the decentralized
                  nature of the Web. }
}

@InProceedings{Karger:TreeLearning,
  author = 	 {Kai Shih and David R. Karger},
  title = 	 {Using URLs and Table Layout for Web Classification Tasks},
  pdf={http://www2004.org/proceedings/docs/1p193.pdf},
  crossref={www04},
  cat:multiple =	{Information Retrieval;CHI; Machine Learning},
abstract={  We propose new features and algorithms for automating Web-page
  classification tasks such
  as content recommendation and ad blocking.  We show that the
  automated classification of Web pages can be much improved if,
  instead of looking at their textual content, we consider each links's
  URL and the visual placement of those links on a referring page.
  These features are unusual: rather than being scalar measurements
  like word counts they are \emph{tree structured}---describing the
  position of the item in a tree.  We develop a model and algorithm
  for machine learning using such tree-structured features.  We apply
  our methods in automated tools for recognizing and blocking Web
  advertisements and for recommending ``interesting'' news stories to
  a reader.  Experiments show that our algorithms are both faster and
  more accurate than those based on the text content of Web documents.}
}

@InProceedings{Karger:Neighbor,
  author = 	 {David R. Karger and Matthias Ruhl},
  title = 	 {Finding Nearest Neighbors in Growth Restricted Metrics},
  crossref =	 {STOC02},
  pages = {741--750},
  studentwork = student,
  ps = {Papers/neighbor.ps},
  psgz = {Papers/neighbor.ps.gz},
  cat:multiple =	{Theory;P2P},
abstract={  Most research on nearest neighbor algorithms in the literature has
  been focused on the Euclidian case. In many practical search
  problems however, the underlying metric cannot be well approximated
  by an Euclidian space, and applying general purpose algorithms
  result in poor performance by not making use of the special
  properties of the subspace that the points lie in. In this paper, we
  develop an efficient dynamic data structure for nearest neighbor
  queries in growth-constrained metrics.  These metrics satisfy the
  property that for any point $q$ the number of points within a radius
  $2r$ around $q$ is at most a constant times the number of points
  within radius $r$. Spaces of this kind occur in networking
  applications, such as the Internet or Peer-to-peer networks, and
  vector quantization applications, where feature vectors fall into
  low-dimensional manifolds within high-dimensional vector spaces.}
}

@Article{Karger:Chord,
  author = 	 {Ion Stoica and Robert Morris and David Liben-Nowell
                  and David R. Karger and M. Frans Kaashoek and Frank
                  Dabek and Hari Balakrishnan},
  title = 	 {Chord: A Scalable Peer-to-Peer Lookup Protocol for
                  Internet Applications},
  journal = 	 {IEEE Transactions on Networking},
  year = 	 2003,
  month = feb,
  volume = 11,
  studentwork = student,
  cat:multiple =	{Theory; Applications of Theory; P2P; Systems},
  pdf={http://www.pdos.csail.mit.edu/papers/ton:chord/paper-ton.pdf},
abstract={A fundamental problem that confronts peer-to-peer applications is the
efficient location of the node that stores a desired data item. This paper
presents Chord, a distributed lookup protocol that addresses this problem.
Chord provides support for just one operation: given a key, it maps the
key onto a node. Data location can be easily implemented on top of Chord
by associating a key with each data item, and storing the key/data pair at
the node to which the key maps. Chord adapts efficiently as nodes join
and leave the system, and can answer queries even if the system is continuously
changing. Results from theoretical analysis and simulations show
that Chord is scalable: communication cost and the state maintained by
each node scale logarithmically with the number of Chord nodes.
}
}

@InProceedings{Arora:FastSparseCut,
  author = 	 {Sanjeev Arora and Elad Hazan and Satyen Kale},
  title = 	 {An {$O(\sqrt{\log n})$} Approximation to Sparsest Cut
                  in {$\Olog(n^2)$} Time},
  crossref =  {FOCS09},
  pages = 	 {238--247}}

@inproceedings{Karger:PlanarTSP,
	author = {Sanjeev Arora and Michelangelo Grigni and David
Karger and Philip Klein and Andrzej Woloszyn},
	title = {A Polynomial-Time Approximation Scheme for Weighted
Planar Graph TSP},
	crossref = {SODA98},
        cat = {Theory},
        psgz = {Papers/qtsp.ps.gz},
abstract={Given a planar graph on $n$ nodes with costs (weights) on
                  its edges, define the distance between nodes $i$ and
                  $j$ as the length of the shortest path between $i$
                  and~$j$.  Consider this as an instance of {\em
                  metric\/} TSP.  For any $\eps>0$, our algorithm
                  finds a salesman tour of total cost at most
                  $(1+\eps)$ times optimal in time $n^{O(1/\eps^2)}$.

We also present a quasi-polynomial time algorithm for the Steiner
version of this problem.},
	pages = {33--41}}

@inproceedings{Karger:Nb,
  author    = {Sacha Zyto and
               David R. Karger and
               Mark S. Ackerman and
               Sanjoy Mahajan},
  title     = {Successful classroom deployment of a social document
                  annotation system},
  booktitle = {CHI Conference on Human Factors in Computing Systems},
  year      = {2012},
  month     = may,
  venue     = {CHI},
  cat:multiple = {CHI;Education},
  pages     = {1883-1892},
  pdf       = {http://people.csail.mit.edu/karger/Papers/nb.pdf},
  doi       = {http://dx.doi.org/10.1145/2207676.2208326},
  url       = {http://nb.mit.edu/},
  ee        = {http://doi.acm.org/10.1145/2207676.2208326}
}

@inproceedings{Karger:DynamicCut,
        author = {Mikkel Thorup and  David R. Karger},
        title = {Dynamic Graph Algorithms with Applications},
        booktitle = {Seventh Scandinavian Workshop on Algorithm Theory},
venue={SWAT},
        year = {2000},
        month = jul,
        cat:multiple = {Theory;Cuts and Flows},
abstract = { First we review amortized fully-dynamic polylogarithmic algorithms for connectivity, minimum spanning trees (MST), 2-edge- and biconnectivity. Second we discuss how they yield improved static algorithms: connectivity for constructing a tree from homeomorphic subtrees, 2-edge connectivity for finding unique matchings in graphs, and MST for packing spanning trees in graphs.

The application of MST for spanning tree packing is new and when boot-strapped, it yields a fully-dynamic polylogarithmic algorithm for approximating general edge connectivity within a factor {2+o(1)}.

Finally, on the more practical side, we will discuss how output sensitive algorithms for dynamic shortest paths have been applied successfully to speed up local search algorithms for improving routing on the internet, roughly doubling the capacity.}
}

@article{Karger:Optima,
       author = karger,
       title = {Random Sampling in Graph Optimization Problems: A
                  Survey},
       journal = {Optima},
       year = {1998},
       volume = {58},
       pages = {1--11},
       cat:multiple =	{Theory; Cuts and Flows},
       pdf = {http://www.ise.ufl.edu/~optima/optima58.pdf},
abstract={Randomization has become a pervasive technique in combinatorial
optimization.  We survey our thesis and subsequent work, which uses
four common randomization techniques to attack numerous optimization
problems on undirected graphs.
}
}
@InProceedings{Karger:TSPBranchPrediction,
  author = 	 {Cliff Young and David S. Johnson and David R. Karger
                  and Michael D. Smith},
  booktitle = 	 {ACM SIGPLAN Conference on Programming Language
                  Design and Implementation},
venue={PLDI},
  title = 	 {Near-Optimal Interprocedural Branch Alignment},
  year =	 1997,
  month=jun,
  pages =	 {183--193},
  organization = {ACM},
  address =	 {Las Vegas, NV},
  cat:multiple =	{Systems; Applications of Theory},
abstract={Branch alignment reorders the basic blocks of a program to minimize
pipeline penalties due to controltransfer instructions. Prior work in
branch alignment has produced useful heuristic methods. We compute
lower bounds on the runtime costs frompipeline penalties and present
an intraprocedural branch alignment algorithm that approaches the
bound. We compare the control penalties and running times of our
algorithm to an older, greedy approach and observe that both the
greedy method and ourmethod are close to the lower bound on control
penalties, suggesting that greedy is good enough. Surprisingly, in
actual execution our method produces programs that run noticeably
faster than the greedy method. We also report results from training
andtesting on different data sets, validating that our results can be
achieved in real-world usage. Training and testing on different data
sets slightly reduced the benefits from both branch alignment
algorithms, but not enough to change the ranking of algorithms, and
not enough to completely erase the benefits from branch alignment
}
}

@InProceedings{Karger:Augmentation-Conf,
  author = 	 benczur # and # karger,
  title = 	 {Augmenting Undirected Edge Connectivity in {$\Olog(n^2)$} Time},
  crossref =  {SODA98},
  pages = 	 {500--509},
  brag = journal # JALG # { 37},
  cat:multiple =	{Theory; Cuts and Flows},
  ps = {http://people.csail.mit.edu/karger/Papers/pldi96-final.ps},
  studentwork = student,
abstract = {We give improved randomized algorithms for the undirected
edge splitting and connectivity augmentation problems. Our
algorithms are an approximately $O()$ factor faster than
the best known deterministic ones. Our runtimes of $O()$
are near-optimal in the sense that even for sparse input
graphs the optimum output graph may require $\Omega()$ edges.}
}

@article{Karger:Augmentation,
  author = 	 benczur # and # karger,
  title = 	 {Augmenting Undirected Edge Connectivity in
                  {$\Olog(n^2)$} Time},
  journal = JALG,
  year = {2000},
  volume = {37},
  pages = {2--36},
  ps = {http://people.csail.mit.edu/karger/Papers/augment-journal.ps},
  cat:multiple =	{Theory; Cuts and Flows},
  brag = special # SODA98,
  studentwork = student,
abstract = {We give improved randomized (Monte Carlo) algorithms for undirected edge splitting and edge connectivity augmentation problems. Our algorithms run in time ~ O(n^2) on n-vertex graphs, making them an ~\Omega(m/n) factor faster than the best known deterministic ones on m-edge graphs.}
}
@inproceedings{Karger:Grid,
  author = {Jinyang Li and John Janotti and Douglas S. J. {De Couto}
 and David R. Karger and Robert Morris},
  title = {A Scalable Location Service for Geographic Ad-Hoc Routing},
  year  = {2000},
  booktitle = {Proceedings of  the $6^{th}$ {ACM} International Conference on
                  Mobile Computing and Networking ({MobiCom} 2000)},
venue={Mobicom},
  month = aug,
  address = {Boston, MA},
  pages = {120--130},
  studentwork = student,
  cat:multiple =	{Systems;P2P;Applications of Theory},
  ps = {http://pdos.lcs.mit.edu/grid/grid:mobicomm00/paper.ps},
  pdf = {http://pdos.lcs.mit.edu/grid/grid:mobicomm00/paper.pdf},
  ppt = {http://pdos.lcs.mit.edu/grid/mobicom_presentation.ppt},
  confurl = {http://portal.acm.org/toc.cfm?id=345910&dl=GUIDE&dl=ACM&type=proceeding&idx=SERIES395&part=Proceedings&WantType=Proceedings},
abstract = { GLS is a new distributed location service which tracks mobile node locations. GLS combined with geographic forwarding allows the construction of ad hoc mobile networks that scale to a larger number of nodes than possible with previous work. GLS is decentralized and runs on the mobile nodes themselves, requiring no fixed infrastructure. Each mobile node periodically updates a small set of other nodes (its location servers) with its current location. A node sends its position updates to its location servers without knowing their actual identities, assisted by a predefined ordering of node identifiers and a predefined geographic hierarchy. Queries for a mobile node's location also use the predefined identifier ordering and spatial hierarchy to find a location server for that node. Experiments using the ns simulator for up to 600 mobile nodes show that the storage and bandwidth requirements of GLS grow slowly with the size of the network. Furthermore, GLS tolerates node failures well: each failure has only a limited effect and query performance degrades gracefully as nodes fail and restart. The query performance of GLS is also relatively insensitive to node speeds. Simple geographic forwarding combined with GLS compares favorably with Dynamic Source Routing (DSR): in larger networks (over 200 nodes) our approach delivers more packets, but consumes fewer network resources.  }
}
@inproceedings{Karger:Coloring-Conf,
        author = {David R. Karger and Rajeev Motwani and Madhu Sudan},
        title = {Approximate Graph Coloring by Semidefinite
		  Programming},
        crossref = {FOCS94},
	note = journal # jacm # " 45(2)",
        cat = {Theory},
        pages = {2--13},
	abstract = {We consider the problem of coloring k-colorable graphs with the fewest possible colors. We present a randomized polynomial time algorithm that colors a 3-colorable graph on n vertices with min{O(&Dgr;1/3 log1/2 &Dgr; log n), O(n1/4 log1/2 n)} colors where &Dgr; is the maximum degree of any vertex. Besides giving the best known approximation ratio in terms of n, this marks the first nontrivial approximation result as a function of the maximum degree &Dgr;. This result can be generalized to k-colorable graphs to obtain a coloring using min{O(&Dgr;1-2/k log1/2 &Dgr; log n), O(n1-3/(k+1) log1/2 n)} colors. Our results are inspired by the recent work of Goemans and Williamson who used an algorithm for semidefinite optimization problems, which generalize linear programs, to obtain improved approximations for the MAX CUT and MAX 2-SAT problems. An intriguing outcome of our work is a duality relationship established between the value of the optimum solution to our semidefinite program and the Lovsz &thgr;-function. We show lower bounds on the gap between the optimum solution of our semidefinite program and the actual chromatic number; by duality this also demonstrates interesting new facts about the &thgr;-function.}}

@inproceedings{Karger:Chord-FS,
        title = {Wide-area cooperative storage with CFS},
        author = {Frank Dabek and M. Frans Kaashoek and David Karger
                  and Robert Morris and Ion Stoica},
        booktitle = {Proceedings of the {ACM} 2001 Symposium on
                  Operating System Principles},
venue={SOSP},
        year = {2001},
        month = oct,
  cat:multiple =	{Theory;Systems;P2P;Applications of Theory},
        pdf ={http://www.cs.ucsd.edu/sosp01/papers/morris.pdf},
        confurl = {http://portal.acm.org/toc.cfm?id=502034&idx=SERIES372&type=proceeding&coll=ACM&dl=ACM&part=series&WantType=Proceedings},
        studentwork = student,
        location = {Banff, Canada},
abstract = {The Cooperative File System (CFS) is a new peer-to-peer read-only storage system that provides provable guarantees for the efficiency, robustness, and load-balance of file storage and retrieval. CFS does this with a completely decentralized architecture that can scale to large systems. CFS servers provide a distributed hash table (DHash) for block storage. CFS clients interpret DHash blocks as a file system. DHash distributes and caches blocks at a fine granularity to achieve load balance, uses replication for robustness, and decreases latency with server selection. DHash finds blocks using the Chord location protocol, which operates in time logarithmic in the number of servers.CFS is implemented using the SFS file system toolkit and runs on Linux, OpenBSD, and FreeBSD. Experience on a globally deployed prototype shows that CFS delivers data to clients as fast as FTP. Controlled tests show that CFS is scalable: with 4,096 servers, looking up a block of data involves contacting only seven servers. The tests also demonstrate nearly perfect robustness and unimpaired performance even when as many as half the servers fail.}}

@inproceedings{Karger:Chord-hotos,
            title = {Building Peer-to-Peer Systems With Chord, a Distributed Lookup
          Service},
            author = {Frank Dabek and Emma Brunskill and
                        M. Frans Kaashoek and David Karger and Robert Morris and Ion Stoica and Hari Balakrishnan},
            booktitle = {Proceedings of the 8th {W}orkshop on {H}ot {T}opics in
          {O}perating {S}ystems ({HotOS-VIII})},
venue={HotOS},
            organization = {IEEE Computer Society},
            year = {2001},
            month = may,
  cat:multiple =	{Theory;Systems;P2P;Applications of Theory},
            address = {Schloss Elmau, Germany},
            ps = {http://www.pdos.lcs.mit.edu/papers/chord:hotos01/hotos8.ps},
  studentwork = student,
abstract = {We argue that the core problem facing peer-to-peer systems
is locating documents in a decentralized network and
propose Chord, a distributed lookup primitive. Chord provides
an efficient method of locating documents while placing
few constraints on the applications that use it. As proof
that Chord's functionality is useful in the development of
peer-to-peer applications, we outline the implementation
of a peer-to-peer file sharing system based on Chord.}
          }

@inproceedings{Karger:Chord-sigcomm01,
         title = {Chord: A Scalable Peer-to-peer Lookup Service for Internet
       Applications},
         author = {Ion Stoica and Robert Morris and David Karger and M. Frans Kaashoek
       and Hari Balakrishnan},
         booktitle = {Proceedings of the {ACM} {SIGCOMM} '01 Conference},
venue={SIGCOMM},
         year = {2001},
         month = aug,
         address = {San Diego, California},
  cat:multiple =	{Theory;Systems;P2P;Applications of Theory},
        ps = {http://pdos.lcs.mit.edu/papers/chord:sigcomm01/chord_sigcomm.ps},
         confurl = {http://portal.acm.org/toc.cfm?id=383059&dl=ACM&dl=ACM&type=proceeding&idx=SERIES419&part=Proceedings&WantType=Proceedings},
         pages = {149--160},
  studentwork = student,
abstract = {A fundamental problem that confronts peer-to-peer applications is
to efficiently locate the node that stores a particular data item. This
paper presents Chord, a distributed lookup protocol that addresses
this problem. Chord provides support for just one operation: given
a key, it maps the key onto a node. Data location can be easily
implemented on top of Chord by associating a key with each data
item, and storing the key/data item pair at the node to which the
key maps. Chord adapts efficiently as nodes join and leave the
system, and can answer queries even if the system is continuously
changing. Results from theoretical analysis, simulations, and experiments
show that Chord is scalable, with communication cost
and the state maintained by each node scaling logarithmically with
the number of Chord nodes.}
       }

@article{Karger:Coloring,
        note={see Karger:Coloring-Journal}
}

@article{Karger:Coloring-Journal,
        author = {David R. Karger and Rajeev Motwani and Madhu Sudan},
        title = {Approximate Graph Coloring by Semidefinite
		  Programming},
        journal = jacm,
        year = 1998,
        month = mar,
        volume = {45},
        number = {2},
        pages = {246--265},
        cat = {Theory},
        ps = {http://people.csail.mit.edu/karger/Papers/color.ps},
        note = prelim # FOCS94,
abstract = {We consider the problem of coloring k-colorable graphs with the fewest possible colors. We present a randomized polynomial time algorithm that colors a 3-colorable graph on n vertices with min{O(&Dgr;1/3 log1/2 &Dgr; log n), O(n1/4 log1/2 n)} colors where &Dgr; is the maximum degree of any vertex. Besides giving the best known approximation ratio in terms of n, this marks the first nontrivial approximation result as a function of the maximum degree &Dgr;. This result can be generalized to k-colorable graphs to obtain a coloring using min{O(&Dgr;1-2/k log1/2 &Dgr; log n), O(n1-3/(k+1) log1/2 n)} colors. Our results are inspired by the recent work of Goemans and Williamson who used an algorithm for semidefinite optimization problems, which generalize linear programs, to obtain improved approximations for the MAX CUT and MAX 2-SAT problems. An intriguing outcome of our work is a duality relationship established between the value of the optimum solution to our semidefinite program and the Lovsz &thgr;-function. We show lower bounds on the gap between the optimum solution of our semidefinite program and the actual chromatic number; by duality this also demonstrates interesting new facts about the &thgr;-function.}}

@article{Karger:Coloring2,
  author = 	 "Avrim Blum and David R. Karger",
  title = 	 "Improved approximation for graph coloring",
  journal = IPL,
  volume = 61,
  number = 1,
  month = jan,
  pages = {49--53},
        cat = {Theory},
  ps = {http://people.csail.mit.edu/karger/Papers/n314color.ps},
  year =	 "1997",
abstract = {We show how the results of Karger, Motwani, and Sudan and Blum can be
combined in a natural manner to yield an $O(n^{3/14})$ coloring of any n
node 3-colorable
graph. This improves on the previous best bound of $O(n^{1/4})$ colors.}
}

@article{Karger:Contraction,
	author = {David R. Karger and Clifford Stein},
	title = {A New Approach to the Minimum Cut Problem},
	journal = jacm,
volume = 43,
number = 4,
month = jul,
pages = {601--640},
        cat:multiple = {Theory;Cuts and Flows},
	note = {Preliminary portions appeared in SODA 1992
		  and STOC 1993},
        ps = {http://people.csail.mit.edu/karger/Papers/contract.ps},
        doi = {http://doi.acm.org/10.1145/234533.234534},
	year = 1996,
	abstract = { This paper present a new approach to finding minimum cuts in undirected graphs. The fundamental principle is simple: the edges in a graph's minimum cut form an extremely small fraction of the graph's edges. Using this idea, we give a randomized, strongly polynomial algorithm that finds the minimum cut in an arbitrarily weighted undirected graph with high probability. The algorithm runs in $O(n^2\log^3n)$ time, a significant improvement over the previous $\Olog(mn)$ time bounds based on maximum flows. It is simple and intuitive and uses no complex data structures. Our algorithm can be parallelized to run in RNC with n2 processors; this gives the first proof that the minimum cut problem can be solved in RNC. The algorithm does more than find a single minimum cut; it finds all of them.With minor modifications, our algorithm solves two other problems of interest. Our algorithm finds all cuts with value within a multiplicative factor of &agr; of the minimum cut's in expected $\Olog(n^{2\alpha})$ time, or in RNC with $n^{2\alpha}$ processors. The problem of finding a minimum multiway cut of graph into r pieces is solved in expected $\Olog(n^{2(r-1)})$ time, or in RNC with $n^{2(r-1)}$ processors. The ``trace'' the algorithm's execution on these two problems forms a new compact data structure for representing all small cuts and all multiway cuts in a graph. This data structure can be efficiently transformed into the more standard cactus representation for minimum cuts.
}
}

@inproceedings{Karger:Connectivity-Conf,
	author = {David R. Karger and Noam Nisan and Michal Parnas},
	title = {Fast Connected Components Algorithms for the {EREW}
{PRAM}},
	crossref = {SPAA92},
        cat = {Theory},
        brag = journal # sicomp # { 28(3)},
        ps = {http://people.csail.mit.edu/karger/Papers/conn-components.ps},
	pages = {562-572},
abstract = { We present fast and efficient parallel algorithms for finding the connected components of an undirected graph. These algorithms run on the exclusive-read, exclusive-write (EREW) PRAM. On a graph with n vertices and m edges, our randomized algorithm runs in O(log n) time using $(m+n^{1+\epsilon})/\log n$ EREW processors (for any fixed $\epsilon>0$). A variant uses (m+n)/log n processors and runs in O(log n log log n) time. A deterministic version of the algorithm runs in $O(\log^{1.5}n)$ time using m+n EREW processors.}
}

@article{Karger:Connectivity,
        cat = {Theory},
	author = {David R. Karger and Noam Nisan and Michal Parnas},
	title = {Fast Connected Components Algorithms for the {EREW}
{PRAM}},
	journal=sicomp,
        year =1999,
        volume = 28,
        number = 3,
        pages = {1021--1034},
        ps = {http://www.mta.ac.il/~michalp/Papers/connectivity.ps},
        note = prelim # SPAA92}

@inproceedings{Karger:Dense-Conf,
	author = {Sanjeev Arora and David R. Karger and Marek
Karpinski},
	title = {Polynomial Time Approximation Schemes for Dense
Instances of {$\NP$}-Hard Problems},
        pages = {284--293},
        cat = {Theory},
        note = journal # JCSS,
        ps = {http://people.csail.mit.edu/karger/Papers/dense.ps},
	crossref = {STOC95}}

@article{Karger:Dense,
	author = {Sanjeev Arora and David R. Karger and Marek
Karpinski},
	title = {Polynomial Time Approximation Schemes for Dense
Instances of {$\NP$}-Hard Problems},
        journal = JCSS,
        volume = 58,
        pages = {193--210},
        year = 1999,
        cat = {Theory},
        brag = special # STOC95
}
@inproceedings{Karger:DetCut-Conf,
	author = {David R. Karger and Rajeev Motwani},
	title = {Derandomization Through Approximation: An {${\cal
NC}$} Algorithm for Minimum Cuts},
	crossref = {STOC93},
        note = journal # sicomp # { 26(1)},
        cat:multiple =	{Theory;Cuts and Flows},
        ps = {http://people.csail.mit.edu/karger/Papers/detcut.ps},
	pages = {497--506},
	abstract = {We show that the minimum cut and multi-cut problems
in weighted undirected graphs can be solved in
JVC. We do so by giving three separate and independently
interesting results. The first is an m2/n processor
JVC algorithm for a (2 + c)-approximation to the
minimum cut. The second is a randomized reduction of
the minimum cut problem to the problem of obtaining a
(2+ e)-approximation to the minimum cut. This reduction
involves a natural combinatorial Safe Sets Problem
that can be solved easily in %?JVC. Our third result is
a derandomization of this 7?JVC solution that requires
a novel combination of two widely used tools: pairwise
independence and random walks on expanders. We believe
that the safe sets approach will prove useful in
other derandomization problems.}
	}

@article{Karger:DetCut,
	author = {David R. Karger and Rajeev Motwani},
	title = {Derandomization Through Approximation: An {${\cal
NC}$} Algorithm for Minimum Cuts},
	journal = sicomp,
	year = 1997,
month = jan,
volume = 26,
number =1,
pages = {255--272},
        cat:multiple =	{Theory;Cuts and Flows},
        ps = {http://epubs.siam.org/sam-bin/dbq/article/27308},
	note = prelim # STOC93,
	abstract = {We show that the minimum cut and multi-cut problems
in weighted undirected graphs can be solved in
JVC. We do so by giving three separate and independently
interesting results. The first is an m2/n processor
JVC algorithm for a (2 + c)-approximation to the
minimum cut. The second is a randomized reduction of
the minimum cut problem to the problem of obtaining a
(2+ e)-approximation to the minimum cut. This reduction
involves a natural combinatorial Safe Sets Problem
that can be solved easily in %?JVC. Our third result is
a derandomization of this 7?JVC solution that requires
a novel combination of two widely used tools: pairwise
independence and random walks on expanders. We believe
that the safe sets approach will prove useful in
other derandomization problems.}
	}

@inproceedings{Karger:Hamilton-Conf,
	author = {David R. Karger and G. D. S. Ramkumar and Rajeev
Motwani},
	title = {On Approximating the Longest Path in a Graph},
	booktitle = {WADS93: Algorithms and Data Structures : Third
Workshop},
venue={WADS},
	year = 1993,
        month = aug,
	series = LNCS,
	editor = {Frank Dehne},
	number = 709,
	publisher = sv,
        cat = {Theory},
        note = journal # ALGO # { 18(1)},
        pages = {421--430},
abstract = {We consider the problem of approximating the longest path in undirected graphs. In an attempt to pin down the best achievable performance ratio of an approximation algorithm for this problem, we present both positive and negative results. First, a simple greedy algorithm is shown to find long paths in dense graphs. We then consider the problem of finding paths in graphs that are guaranteed to have extremely long paths. We devise an algorithm that finds paths of a logarithmic length in Hamiltonian graphs. This algorithm works for a much larger class of graphs (weakly Hamiltonian), where the result is the best possible. Since the hard case appears to be that of sparse graphs, we also consider sparse random graphs. Here we show that a relatively long path can be obtained, thereby partially answering an open problem of Broderet al.
To explain the difficulty of obtaining better approximations, we also prove hardness results. We show that, for any e<1, the problem of finding a path of lengthn-n e in ann-vertex Hamiltonian graph isNP-hard. We then show that no polynomial-time algorithm can find a constant factor approximation to the longest-path problem unlessP=NP. We conjecture that the result can be strengthened to say that, for some constant d>0, finding an approximation of ration d is alsoNP-hard. As evidence toward this conjecture, we show that if any polynomial-time algorithm can approximate the longest path to a ratio of $$2^{O(\log ^{1 - \varepsilon } n)} $$ , for any e>0, thenNP has a quasi-polynomial deterministic time simulation. The hardness results apply even to the special case where the input consists of bounded degree graphs.}
}

@Article{Karger:Hamilton,
  author = 	 {David R. Karger and G. D. S. Ramkumar and Rajeev
Motwani},
  title = 	 {On Approximating the Longest Path in a Graph},
  journal = 	 {Algorithmica},
  year = 	 1997,
  volume =	 18,
  number =	 1,
  month =	 may,
        cat = {Theory},
  pages =	 {82--98},
  ps = {http://people.csail.mit.edu/karger/Papers/hamilton.ps},
  note =	 prelim # {the 1993 Workshop on Algorithms and Data Structures},
abstract = {We consider the problem of approximating the longest path in undirected graphs. In an attempt to pin down the best achievable performance ratio of an approximation algorithm for this problem, we present both positive and negative results. First, a simple greedy algorithm is shown to find long paths in dense graphs. We then consider the problem of finding paths in graphs that are guaranteed to have extremely long paths. We devise an algorithm that finds paths of a logarithmic length in Hamiltonian graphs. This algorithm works for a much larger class of graphs (weakly Hamiltonian), where the result is the best possible. Since the hard case appears to be that of sparse graphs, we also consider sparse random graphs. Here we show that a relatively long path can be obtained, thereby partially answering an open problem of Broderet al.
To explain the difficulty of obtaining better approximations, we also prove hardness results. We show that, for any e<1, the problem of finding a path of lengthn-n e in ann-vertex Hamiltonian graph isNP-hard. We then show that no polynomial-time algorithm can find a constant factor approximation to the longest-path problem unlessP=NP. We conjecture that the result can be strengthened to say that, for some constant d>0, finding an approximation of ration d is alsoNP-hard. As evidence toward this conjecture, we show that if any polynomial-time algorithm can approximate the longest path to a ratio of $$2^{O(\log ^{1 - \varepsilon } n)} $$ , for any e>0, thenNP has a quasi-polynomial deterministic time simulation. The hardness results apply even to the special case where the input consists of bounded degree graphs.}
}

@inproceedings{Karger:FastCut,
	author = {David R. Karger and Clifford Stein},
	title = {An {$\Olog(n^2)$} Algorithm for Minimum Cuts},
	crossref = {STOC93},
        cat:multiple =	{Theory;Cuts and Flows},
        ps={http://people.csail.mit.edu/karger/Papers/fastcut.ps},
        note = journal # jacm # { 43(4)},
	pages = {757-765},
abstract = { This paper present a new approach to finding minimum cuts
                  in undirected graphs. The fundamental principle is
                  simple: the edges in a graph's minimum cut form an
                  extremely small fraction of the graph's edges. Using
                  this idea, we give a randomized, strongly polynomial
                  algorithm that finds the minimum cut in an
                  arbitrarily weighted undirected graph with high
                  probability. The algorithm runs in O(n2log3n) time,
                  a significant improvement over the previous ${\tilde
                  O}(mn)$ time bounds based on maximum flows. It is
                  simple and intuitive and uses no complex data
                  structures. Our algorithm can be parallelized to run
                  in RNC with n2 processors; this gives the first
                  proof that the minimum cut problem can be solved in
                  RNC. The algorithm does more than find a single
                  minimum cut; it finds all of them.With minor
                  modifications, our algorithm solves two other
                  problems of interest. Our algorithm finds all cuts
                  with value within a multiplicative factor of &agr;
                  of the minimum cut's in expected ${\tilde O}(n^2)$
                  time, or in RNC with n2&agr; processors. The problem
                  of finding a minimum multiway cut of graph into r
                  pieces is solved in expected ${\tilde
                  O}(n^{2(r-1)})$ time, or in RNC with n2(r-1)
                  processors. The ``trace'' of the algorithm's
                  execution on these two problems forms a new compact
                  data structure for representing all small cuts and
                  all multiway cuts in a graph. This data structure
                  can be efficiently transformed into the more
                  standard cactus representing for minimum cuts.  }
}

@Inproceedings{Karger:Diminish,
  author = 	 {David R. Karger},
  title = 	 {Using Random Sampling to Find Maximum Flows
in Uncapacitated Undirected Graphs},
  crossref = {STOC97},
        cat:multiple =	{Theory;Cuts and Flows},
 ps = {http://people.csail.mit.edu/karger/Papers/flow.ps},
 pages = {240--249},
abstract = {We present new algorithms, based on random sampling, that
find maximum flows in undirected incapacitated graphs. Our
algorithms dominate augmenting paths over all parameter values
(number of vertices and edges and flow value). They also
dominate blocking flows over a large range of parameter values.
Furthermore, they achieve time bounds on graphs with
parallel (equivalently, capacitated) edges that previously could
only be achieved on graphs without them.
The key contribution of this paper is to demonstrate that
such an improvement is possible. This shows that augmenting
paths and blocking flows are non-optimal, and reopens the
question of how fast we can find a maximum flow. We improve
known time bounds by only a small (but polynomial) factor,
and the complicated nature of our algorithms suggests they will
not be practical.
A new idea of our algorithm is to find flow by diminishing
cuts instead of augmenting paths. Rather than finding a way to
push flow from the source to the sink, we identify and delete
edges that are not needed in a maximum flow. When no more
edges can be deleted, we know that every remaining edge must
be saturated to give a maximum flow.
}
}

@InProceedings{Karger:Sifter,
  author = {David F. Huynh and Robert C. Miller and David R. Karger},
  title = {Enabling Web Browsers to Augment Web Sites' Filtering and Sorting Functionalities},
  venue = "UIST",
  booktitle = 	 {Proceedings of the ACM Symposium on User Interface Software and Technology (UIST)},
  pages = {125--134},
  month = may,
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
  pdf = {http://people.csail.mit.edu/dfhuynh/research/papers/uist2006-augmenting-web-sites.pdf},
  pdfkb = "1400",
  year =	 2006,
  abstract = "Existing augmentations of web pages are mostly small cosmetic changes (e.g., removing ads) and minor addition of third-party content (e.g., product prices from competing sites). None leverages the structured data presented in web pages. This paper describes Sifter, a web browser extension that can augment a web site with advanced filtering and sorting functionality. These added features work inside the site's own pages, preserving the site's presentational style, as if the site itself has implemented the features. Sifter contains an algorithm that scrapes structured data out of web pages while usually requiring no user intervention. We tested Sifter on real web sites and real users and found that people could use Sifter to perform sophisticated queries and high-level analyses on sizable data collections on the Web. We propose that web sites can be similarly augmented with other sophisticated data-centric functionality, giving users new benefits over the existing Web."
}

@inproceedings{Karger:Relo,
   author = {Vineet Sinha and David R. Karger and Robert C. Miller},
   title ={Relo: Helping Users Manage Context during Interactive
                  Exploratory Visualization of Large Codebases},
   booktitle ={VL/HCC: Visual Languages and Human Centered Computing},
   cat:multiple =	{Information Retrieval;CHI},
   venue={VLHCC},
   month = sep,
   location = {Brighton, UK},
   year ={2006},
   pages = {187-194},
   pdf = {http://relo.csail.mit.edu/documentation/relo-vlhcc06.pdf},
	abstract = {As software systems grow in size and use more third-party libraries and frameworks, the need for developers to understand unfamiliar large codebases is rapidly increasing. In this paper, we present a tool, Relo, that supports developers' understanding by allowing interactive exploration of code. As the developer explores relationships found in the code, Relo builds and automatically manages the context in a visualization, thereby helping build the developer's mental representation of the code. Developers can group viewed artifacts or use the viewed items to ask Relo for further exploration suggestions, with Relo providing features to limit the growth of the diagram. To ensure developers don't get overwhelmed, Relo has been built with a user-centered approach, and preliminary evaluations with developers exploring new code have shown them to find the tool intuitive and helpful.}
}

@inproceedings{Karger:Exhibit,
	title = "Exhibit: Lightweight Structured Data Publishing",
        booktitle = {WWW 2007},
        pages = {737--746},
	year = "2007",
        month = may,
	venue = "WWW",
 location = {Banff, Alberta, Canada},
 doi = {10.1145/1242572.1242672},
	pdf = "http://people.csail.mit.edu/dfhuynh/research/papers/www2007-exhibit.pdf",
	pdfkb = "2460",
	author = "David Huynh and Robert Miller and David R. Karger",
	abstract = "It is no surprise that Semantic Web researchers and enthusiasts are excited to publish and accumulate semi-structured data on the Web. Beyond our community, however, we see many authors with structured data who want to publish it in rich browsing interfaces. These small-time authors are similar to early enthusiasts of the Web, simply excited by the opportunity to use a new medium to share information that they care about. For these users, we propose Exhibit, a lightweight structured data publishing framework that duplicates many of the desirable properties that contributed to the original growth of the Web. We argue that appealing to this segment of the Web population?addressing their publishing needs at very low cost?lets us leverage their labor to put structure on content that otherwise would be published in hand-authored HTML, and thus very hard to harvest automatically.",
	projectSite = "http://simile.mit.edu/exhibit/",
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
	project = "Exhibit",
	origin = "http://people.csail.mit.edu/dfhuynh/publications.html#Exhibit%3A%20Lightweight%20Structured%20Data%20Publishing"
}


@Article{ManyEyes,
  author = 	 {Fernanda B. Viegas and Martin Wattenberg and Frank
                  van Ham and Jesse Kriss and Matthew M. McKeon},
  title = 	 {ManyEyes: a Site for Visualization at Internet Scale},
  journal = 	 {IEEE Trans. Vis. Comput. Graph.},
  year = 	 2007,
  volume = 	 13,
  number = 	 6,
  pages = 	 {1121-1128}}

@inproceedings{Karger:Potluck,
	title = "Potluck: Data Mash-Up Tool for Casual Users",
	year = "2007",
        month=nov,
        crossref = {iswc07},
	work-done-at = "MIT CSAIL",
	pdf = "http://people.csail.mit.edu/dfhuynh/research/papers/iswc2007-potluck.pdf",
	author = "David Huynh and Robert Miller and David R. Karger",
	abstract = "<p>As more and more reusable structured data appears on the Web, casual users will want to take into their own hands the task of mashing up data rather than wait for mash-up sites to be built that address exactly their individually unique needs. In this paper, we present Potluck, a Web user interface that lets casual users?those without programming skills and data modeling expertise?mash up data themselves.</p><p>Potluck is novel in its use of drag and drop for merging fields, its integration and extension of the faceted browsing paradigm for focusing on subsets of data to align, and its application of simultaneous editing for cleaning up data syntactically. Potluck also lets the user construct rich visualizations of data in-place as the user aligns and cleans up the data. This iterative process of integrating the data while constructing useful visualizations is desirable when the user is unfamiliar with the data at the beginning?a common case?and wishes to get immediate value out of the data without having to spend the overhead of completely and perfectly integrating the data first.</p><p>A user study on Potluck indicated that it was usable and learnable, and elicited excitement from programmers who, even with their programming skills, previously had great difficulties performing data integration.</p>",
	pdfkb = "1677",
	projectSite = "http://simile.mit.edu/potluck/",
	project = "Potluck",
	screencastURL = "http://people.csail.mit.edu/dfhuynh/research/media/iswc2007/potluck-screencast.mov",
	screencastKB = "67274",
	note = "to appear",
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
}



@InProceedings{Karger:Haystack-swfat03,
  author = 	 {Dennis Quan and David Huynh and David R. Karger},
  title = 	 {RDF authoring Environments for End Users},
  booktitle =	 {International Workshop on Semantic Web Foundations
                  and Application Technologies (SWFAT)},
  year =	 2003,
  studentwork = student,
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
	venue = "SWFAT",
  month = mar,
  confurl = {http://www-kasm.nii.ac.jp/SWFAT/proceedings.html},
	pdf = "http://haystack.csail.mit.edu/papers/swfat2003.pdf",
	pdfkb = "494",
	abstract = {The Semantic Web promises to open innumerable opportunities for
automation and information retrieval by standardizing the protocols for
metadata exchange. However, just as the success of the World Wide Web can
be attributed to the ease of use and ubiquity of Web browsers, we believe that
the unfolding of the Semantic Web vision depends on users getting powerful
but easy-to-use tools for managing their information. But unlike HTML, which
can be easily edited in any text editor, RDF is more complicated to author and
does not have an obvious presentation mechanism. Previous work has
concentrated on the ideas of generic RDF graph visualization and RDF Schemabased
form generation. In this paper, we present a comprehensive platform for
constructing end user applications that create, manipulate, and visualize
arbitrary RDF-encoded information, adding another layer to the abstraction
cake. We discuss a programming environment specifically designed for
manipulating RDF and introduce user interface concepts on top that allow the
developer to quickly assemble applications that are based on RDF data models.
Also, because user interface specifications and program logic are themselves
describable in RDF, applications built upon our framework enjoy properties
such as network updatability, extensibility, and end user customizability---all
desirable characteristics in the spirit of the Semantic Web.}
}



@InProceedings{Karger:Workspace,
	title = "End-User Application Development for the Semantic Web",
  booktitle =	 {Semantic Desktop 2005 Workshop,
International Semantic Web Conference (ISWC)},
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
	confurl = "http://iswc2005.semanticweb.org/",
	pdf = "http://haystack.lcs.mit.edu/papers/SemDesk-Final.pdf",
	author = "Karun Bakshi and David Karger",
	venue = "ISWC",
	year = "2005",
        month = oct,
	pdfkb = "1465",
	event = "Semantic Desktop Workshop",
	abstract = {Although a lot of information has become readily
                  accessible and necessary for daily work, the current
                  infrastructure for managing information is
                  ill-suited for information-oriented activities:
                  information and functionality are scattered across
                  applications and websites, making it difficult to
                  aggregate and reuse just the right set of content
                  and operations required for unique user tasks. We
                  discuss a collection of tools built into the
                  Haystack platform that address many of the
                  shortcomings of current applications, and allow
                  composing reusable fragments of information and
                  associated operations and views from the Semantic
                  Web into a task workspace tailored to the user and
                  the task. Users can change the workspace to
                  immediately meet changing requirements to easily
                  include, remove or reuse information in multiple
                  tasks simultaneously. The time that a user invests
                  for the initial setup and occasional updates to the
                  workspace is amortized over the numerous times he or
                  she returns to the task, and all relevant
                  information resources are co-located and ready to
                  use.}
}

@InProceedings{Haystack:Messaging,
	title = "A Unified Abstraction for Messaging on the Semantic Web",
        booktitle = {Developers' day,  $12^{th}$ International World
                  Wide Web Conference},
	conf = "http://www.www2003.org/",
	pdfurl = "http://haystack.lcs.mit.edu/papers/www2003-messaging.pdf",
	author = "Dennis Quan and Karun Bakshi and David R. Karger",
	venue = "WWW",
	year = "2003",
        month = may,
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
  pages =	 231,
  crossref={www03},
	pdfkb = "307",
	event = "Developer's Day",
	abstract = {Since its inception, the Internet has been a hotbed of several successful
communications channels, starting off with e-mail, Internet
Relay Chat and Usenet newsgroups and more recently adding
Web annotation, instant messaging, and news feeds. However,
these channels were developed fairly independently, and in many
cases their respective functionalities have grown to overlap significantly.
For instance, users of these systems have separate identifiers
for e-mail, chat, and instant messaging, and clients for these
systems all have their own implementations of threaded message
views. We believe these problems stem from a lack of a common
user interface and data model. In this paper we use basic concepts
from the Semantic Web and RDF to unify and model these seemingly
disparate messaging paradigms. We also demonstrate a generalized
user interface for messaging that uses the data model we
have developed. From this process we realize a number of synergies
that result from the reduction of overlap and the finer-grained
control users are given over message composition, transmission,
storage and retrieval.}
}


@InProceedings{Karger:MultipleCategorization,
  author = 	 {Dennis Quan and Karun Bakshi and David Huynh and
                  David R. Karger},
  title = 	 {User Interfaces for Supporting Multiple Categorization.},
  pages =        {228--235},
  cat:multiple =	{Information Retrieval;Semantic Web;CHI},
  crossref =	 {interact03},
	confurl = "http://www.interact2003.org/",
  studentwork = student,
	pdf = "http://haystack.lcs.mit.edu/papers/interact2003-multicat.pdf",
	pdfkb = "175",
  pdf = hayweb # {interact2003-multicat.pdf},
abstract = {As the amount of information stored on and accessed by computer has increased over the past twenty
years, the tools available for organizing and retrieving such information have become outdated. The folder paradigm
has dominated existing user interfaces as the primary mechanism for organizing information for day-to-day
use. This paradigm encourages many-to-one placement of documents into strictly hierarchical containers. In this
paper we examine an alternative organization and navigation mechanism that promotes membership in multiple
overlapping categories (as opposed to storage containment). In particular, we explore the user interface consequences
of multiple categorization support being made conveniently available from within Web browsers. We
have carried out user studies providing evidence that compared to the folder paradigm, multiple categorization
not only improves organization and retrieval times but also matches more closely with the way users naturally
think about organizing their information.}
}



@InProceedings{Karger:Haystack-Semweb02,
  author = 	 {David Huynh and David Karger and Dennis Quan},
  title = 	 {Haystack: A Platform for Creating, Organizing, and
                  Visualizing Information Using {RDF}},
  studentwork = student,
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
	pdf = "http://haystack.csail.mit.edu/papers/sww02.pdf",
	pdfkb = "310",
  crossref =	 {semweb02},
abstract = {The Resource Definition Framework (RDF) is designed to support
agent communication on the Web, but it is also suitable as a
framework for modeling and storing personal information.
Haystack is a personalized information repository that employs
RDF in this manner. This flexible semistructured data model is
appealing for several reasons. First, RDF supports ontologies
created by the user and tailored to the user's needs. At the same
time, system ontologies can be specified and evolved to support a
variety of high-level functionalities such as flexible organization
schemes, semantic querying, and collaboration. In addition, we
show that RDF can be used to engineer a component architecture
that gives rise to a semantically rich and uniform user interface.
We demonstrate that by aggregating various types of users' data
together in a homogeneous representation, we create opportunities
for agents to make more informed deductions in automating tasks
for users. Finally, we discuss the implementation of an RDF
information store and a programming language specifically suited
for manipulating RDF.}
}



@misc{Karger:Haystack-IUI03-Poster,
  author = 	 {David Huynh and David R. Karger and Dennis Quan},
  title = 	 {Haystack: A Platform for Creating, Organizing, and
                  Visualizing Semistructured Information},
  crossref={iui03},
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
  studentwork  = student,
pub-type={Demo},
  note={Demo},
	pdf = "http://haystack.lcs.mit.edu/papers/iui2003-demo.pdf",
	pdfkb = "97",
}

@misc{Karger:Stickynotes-Poster,
  author = 	 {David R. Karger and Boris Katz and Jimmy Lin and
                  Dennis Quan},
  title = 	 {Sticky notes for the Semantic Web},
  crossref={iui03},
  pages = "254--256",
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
	pdf = "http://haystack.lcs.mit.edu/papers/iui2003-annotation.pdf",
  studentwork  = student,
  pub-type={Poster},
note={Poster.},
  url = "citeseer.ist.psu.edu/563406.html",
abstract = {Computer-based annotation is increasing in popularity as a mechanism for revising documents and sharing comments over the Internet. One reason behind this surge is that viewpoints, summaries, and notes written by others are often helpful to readers. In particular, these types of annotations can help users locate or recall relevant documents. We believe that this model can be applied to the problem of retrieval on the Semantic Web. In this paper, we propose a generalized annotation environment that supports richer forms of description such as natural language. We discuss how RDF can be used to model annotations and the connections between annotations and the documents they describe. Furthermore, we explore the idea of a question answering interface that allows retrieval based both on the text of the annotations and the annotations associated metadata. Finally, we speculate on how these features could be pervasively integrated into an information management environment, making Semantic Web annotation a first class player in terms of document management and retrieval}
}

@inproceedings{Adar99,
  note={see Karger:Haystack-CIKM}
}

@inproceedings{Karger:Haystack-CIKM,
  author = {Eytan Adar and David R. Karger and Lynn Andrea Stein},
  title = {Haystack: Per-User Information Environments},
  booktitle = {Proceedings of the 8th International Conference on
                  Information and Knowledge Management},
  year = {1999},
  month = nov,
  venue={CIKM},
  confurl = {http://portal.acm.org/toc.cfm?id=319950&dl=ACM&type=proceeding&idx=SERIES772&part=Proceedings&WantType=Proceedings},
  ps = {Papers/cikm99.ps},
  psgz = {Papers/cikm99.p.gzs},
  pdf = {Papers/cikm99.ps.pdf},
  pages =  {413--422},
  cat:multiple =	{Information Retrieval;Semantic Web;CHI;Haystack},
abstract = { Traditional Information Retrieval (IR) systems are designed to provide uniform access to centralized corpora by large numbers of people. The Haystack project emphasizes the relationship between a particular individual and his corpus. An individual's own haystack priviliges information with which that user interacts, gathers data about those interactions, and uses this metadata to further personalize the retrieval process. This paper describes the prototype Haystack system.},
  studentwork  = student
}


@InProceedings{Karger:Lincut-Conf,
  author = 	 karger,
  title = 	 "Minimum Cuts in Near-Linear Time",
  crossref =	 "STOC96",
  note = journal # jacm # { 47(1)},
  ps={http://people.csail.mit.edu/karger/Papers/lincut.ps},
pages = {56--63},
cat:multiple =	{Theory;Cuts and Flows},
abstract = { We significantly improve known time bounds for solving the minimum cut problem on undirected graphs. We use a "semiduality" between minimum cuts and maximum spanning tree packings combined with our previously developed random sampling techniques. We give a randomized (Monte Carlo) algorithm that finds a minimum cut in an m-edge, n-vertex graph with high probability in O(m log3 n) time. We also give a simpler randomized algorithm that finds all minimum cuts with high probability in O(m log3 n) time. This variant has an optimal RNC parallelization. Both variants improve on the previous best time bound of O(n2 log3 n). Other applications of the tree-packing approach are new, nearly tight bounds on the number of near-minimum cuts a graph may have and a new data structure for representing them in a space-efficient manner.
}
}

@article{Karger:Lincut,
  author = 	 karger,
  title = 	 "Minimum Cuts in Near-Linear Time",
  journal = jacm,
  volume = 47,
  number = 1,
  month = jan,
  year = {2000},
  pages = {46--76},
ps={http://people.csail.mit.edu/karger/Papers/lincut-journal.ps},
cat:multiple =	{Theory;Cuts and Flows},
  note = prelim # STOC96,
abstract = { We significantly improve known time bounds for solving the minimum cut problem on undirected graphs. We use a "semiduality" between minimum cuts and maximum spanning tree packings combined with our previously developed random sampling techniques. We give a randomized (Monte Carlo) algorithm that finds a minimum cut in an m-edge, n-vertex graph with high probability in O(m log3 n) time. We also give a simpler randomized algorithm that finds all minimum cuts with high probability in O(m log3 n) time. This variant has an optimal RNC parallelization. Both variants improve on the previous best time bound of O(n2 log3 n). Other applications of the tree-packing approach are new, nearly tight bounds on the number of near-minimum cuts a graph may have and a new data structure for representing them in a space-efficient manner.
}
}

@inproceedings{Karger:ImpConn-Conf,
  author = {Raj D. Iyer and David R. Karger and Hariharan Rahul and
                  Mikkel Thorup},
  title = {An Experimental Study of Polylogarithmic Fully-Dynamic
                  Connectivity Algorithms},
  booktitle = {Proceedings of ALENEX00: Workshop on Algorithm
                  Engineering and Experimentation},
  month = jan,
  year = {2000},
venue={ALENEX},
  brag = {ALENEX00 special issue of the Journal of
                  Experimental Algorithmics},
  ps = {http://people.csail.mit.edu/karger/Papers/impconn.ps},
  cat = {Theory},
  studentwork = student,
abstract = {We present an experimental study of different variants of the amortized O(log2 n)-time fully-dynamic connectivity algorithm of Holm, de Lichtenberg, and Thorup (STOC'98). The experiments build upon experiments provided by Alberts, Cattaneo, and Italiano (SODA'96) on the randomized amortized O(log3 n) fully-dynamic connectivity algorithm of Henzinger and King (STOC'95). Our experiments shed light upon similarities and differences between the two algorithms. We also present a slightly modified version of the Henzinger-King algorithm that runs in O(log2 n) time, which resulted from our experiments.}
  }

}
@article{Karger:ImpConn,
  author = {Raj D. Iyer and David R. Karger and Hariharan Rahul and
                  Mikkel Thorup},
  title = {An Experimental Study of Polylogarithmic Fully-Dynamic
                  Connectivity Algorithms},
  journal = {ACM Journal of Experimental Algorithmics},
  vol=6,
  year = {2001},
  cat = {Theory},
  brag = {Special issue of papers selected from ALENEX 2000},
  studentwork = student,
abstract = {We present an experimental study of different variants of the amortized O(log2 n)-time fully-dynamic connectivity algorithm of Holm, de Lichtenberg, and Thorup (STOC'98). The experiments build upon experiments provided by Alberts, Cattaneo, and Italiano (SODA'96) on the randomized amortized O(log3 n) fully-dynamic connectivity algorithm of Henzinger and King (STOC'95). Our experiments shed light upon similarities and differences between the two algorithms. We also present a slightly modified version of the Henzinger-King algorithm that runs in O(log2 n) time, which resulted from our experiments.}
}

@inproceedings{Karger:ImpCut,
  author = 	 "Chandra C. Chekuri and Andrew V. Goldberg and
                  David R. Karger and Matthew S. Levine and Cliff Stein",
  title = 	 "Experimental Study of Minimum Cut Algorithms",
pages = {324--333},
crossref = {SODA97},
cat:multiple =	{Theory;Cuts and Flows},
abstract = {Recently, several new algorithms have been developed
for the minimum cut problem. These algorithms
are very different from the earlier ones
and from each other and substantially improve the
worst-case time bounds for the problem. In this
paper, we conduct experimental evaluation the relative
performance of these algorithms. In the process,
we develop heuristics and data structures that
substantially improve the practical performance of
the algorithms. We also develop problem families
for testing minimum cut algorithms. Our work
leads to a better understanding of the practical
performance of minimum cut algorithms and produces
very efficient codes for the problem.},
  studentwork = {\asteriskit{\labelwidth}  } # " "
}



@InProceedings{Karger:ImpRel,
  author = 	 {David R. Karger and Ray P. Tai},
  title = 	 "Implementing a Fully Polynomial Time Approximation
                  Scheme for All Terminal Network Reliability",
  crossref =  {SODA97},
pages = {334--343},
ps = {Papers/imprel.ps},
psgz={Papers/imprel.ps.gz},
cat:multiple =	{Theory;Cuts and Flows},
abstract = {The classic all-terminal network reliability problem
posits a graph, each of whose edges fails (disappears)
independently with some given probability. The goal is
to determine the probability that the network becomes
disconnected due to edge failures. The practical applications
of this question to communication networks are
obvious, and the problem has therefore been the subject
of a great deal of study. Since it is tjp-complete,
and thus believed hard to solve exactly, a great deal of
research has been devoted to estimating the failure probability.
A comprehensive survey can be found in [Co187].
The first author recently presented an algorithm for
approximating the probability of network disconnection
under random edge failures. In this paper, we report
on our experience implementing this algorithm. Our
implementation shows that the algorithm is practical
on networks of moderate size, and indeed works better
than the theoretical bounds predict. Part of this
improvement arises from heuristic modifications to the
theoretical algorithm, while another part suggests that
the theoretical running time analysis of the algorithm
might not be tight.
Based on our observation of the implementation,
we were able to devise analytic explanations of at least
some of the improved performance. As one example,
we formally prove the accuracy of a simple heuristic
approximation for the reliability. We also discuss other
questions raised by the implementation which might be
susceptible to analysis.},
  studentwork = student
}

@InProceedings{Karger:ImpWeb-Conf,
  author =       "David Karger and Alex Sherman and Andy Berkheimer and
                 Bill Bogstad and Rizwan Dhanidina and Ken Iwamoto and
                 Brian Kim and Luke Matkins and Yoav Yerushalmi",
  title =        "Web Caching with Consistent Hashing",
  url = {http://www8.org/w8-papers/2a-webserver/caching/paper2.html},
  booktitle =    "Proceedings of the Eighth World-Wide Web Conference",
  year =         "1999",
  month = may,
venue={WWW},
  cat:multiple =	{Systems;Theory; Applications of Theory},
  keywords =     "load balancing",
  studentwork = {\asteriskit{\labelwidth} } # " ",
  comments =     "A key performance measure for the World Wide Web is
                 the speed with which content is served to users. As
                 traffic on the Web increases, users are faced with
                 increasing delays and failures in data delivery. Web
                 caching is one of the key strategies that has been
                 explored to improve performance. An important issue in
                 many caching systems is how to decide what is cached
                 where at any given time. Solutions have included
                 multicast queries and directory schemes. In this paper,
                 we offer a new Web caching strategy based on consistent
                 hashing. Consistent hashing provides an alternative to
                 multicast and directory schemes, and has several other
                 advantages in load balancing and fault tolerance. Its
                 performance was analyzed theoretically in previous
                 work: in this paper we describe the implementation of a
                 consistent-hashing-based system and experiments that
                 support our thesis that it can provide performance
                 improvements.",
}

@Article{Karger:ImpWeb-Journal,
  author =       "David Karger and Alex Sherman and Andy Berkheimer and
                 Bill Bogstad and Rizwan Dhanidina and Ken Iwamoto and
                 Brian Kim and Luke Matkins and Yoav Yerushalmi",
  title =        "{Web} caching with consistent hashing",
  journal =      "Computer Networks",
  volume =       "31",
  number =       "11--16",
  studentwork = {\asteriskit{\labelwidth} } # " ",
  pages =        "1203--1213",
  day =          "17",
  month =        may,
  year =         "1999",
  cat:multiple = {Systems;Theory;Applications of Theory},
  coden =        "????",
  cat:multiple =	{Systems;Theory; Applications of Theory},
  ISSN =         "1389-1286",
  address =      {Amsterdam, Netherlands},
  bibdate =      "Fri Sep 24 19:43:29 MDT 1999",
  url =          "http://www.elsevier.com/cas/tree/store/comnet/sub/1999/31/11-16/2181.pdf",
abstract = {A key performance measure for the World Wide Web is the speed with which content is served to users. As traffic on the Web increases, users are faced with increasing delays and failures in data delivery. Web caching is one of the key strategies that has been explored to improve performance.

An important issue in many caching systems is how to decide what is cached where at any given time. Solutions have included multicast queries and directory schemes.

In this paper, we offer a new web caching strategy based on consistent hashing. Consistent hashing provides an alternative to multicast and directory schemes, and has several other advantages in load balancing and fault tolerance. Its performance was analyzed theoretically in previous work; in this paper we describe the implementation of a consistent-hashing based system and experiments that support our thesis that it can provide performance improvements. }
}

@inproceedings{Karger:Infranet,
  author = {Nick Feamster and Magdalena Balazinska and Greg Harfst and
                  Hari Balakrishnan and David Karger},
  title = {Infranet: Circumventing Web Censorship and Surveillance},
  booktitle = {Proceedings of the $11^{th}$ USENIX Security
                  Symposium},
venue={USENIX Security},
  pages={247--262},
  address = {San Fransisco, CA},
  month = aug,
  year = {2002},
  note = {Best Student Paper Award},
  studentwork = student,
  cat:multiple =	{Systems;Theory; Applications of Theory},
  ps ={http://wind.lcs.mit.edu/papers/usenixsec2002.ps},
  psgz ={http://wind.lcs.mit.edu/papers/usenixsec2002.ps.gz},
  pdf = {http://wind.lcs.mit.edu/papers/usenixsec2002.pdf},
abstract = {An increasing number of countries and companies routinely block or monitor access to parts of the Internet. To counteract these measures, we propose Infranet, a system that enables clients to surreptitiously retrieve sensitive content via cooperating Web servers distributed across the global Internet. These Infranet servers provide clients access to censored sites while continuing to host normal uncensored content. Infranet uses a tunnel protocol that provides a covert communication channel between its clients and servers, modulated over standard HTTP transactions that resemble innocuous Web browsing. In the upstream direction, Infranet clients send covert messages to Infranet servers by associating meaning to the sequence of HTTP requests being made. In the downstream direction, Infranet servers return content by hiding censored data in uncensored images using steganographic techniques. We describe the design, a prototype implementation, security properties, and performance of Infranet. Our security analysis shows that Infranet can successfully circumvent several sophisticated censoring techniques.}
}

@inproceedings{Karger:Pipeline,
  author = {Daniel W. Engels and Jon Feldman and David R. Karger and
                  Matthias Ruhl},
  title = {Scheduling Trees with Communication and Precedence Delays},
  year = {2001},
  crossref = {SODA01},
  cat = {Theory},
  studentwork = student,
  ps = {Papers/engels01parallel.ps}
}

@inproceedings{Karger:P2PLoadBalance-IPTPS,
  author={David R. Karger and Matthias Ruhl},
  title= {Load Balancing in P2P Systems},
  crossref={iptps04},
  pdf = {http://iptps04.cs.ucsd.edu/papers/karger-load-balance.pdf},
  cat:multiple =	{Theory;P2P},
  year = 2004,
  month = feb,
abstract = {
Load balancing is a critical issue for the efficient operation of
peer-to-peer networks. We give new protocols for several scenarios,
whose provable performance guarantees are within a constant factor of
optimal.

First, we give an improved version of consistent hashing, a scheme
used for item to node assignments in the Chord system. In its original
form, it required every network node to operate $O(\log n)$ virtual
nodes to achieve a balanced load, causing a corresponding increase in
space and bandwidth usage. Our protocol eliminates the necessity of
virtual nodes while maintaining a balanced load. Improving on related
protocols, our scheme allows for the deletion of nodes and admits a
simpler analysis, since the assignments do not depend on the history
of the network.

We then analyze several simple protocols for load sharing by movements
of data from higher loaded to lower loaded nodes. These protocols can
be extended to preserve the ordering of data items. As an application,
we use the last protocol to give an efficient implementation of a
distributed data structure for range searches on ordered data.
}
}

@inproceedings{Karger:P2PLoadBalance,
 author = {David R. Karger and Matthias Ruhl},
 title = {Simple efficient load balancing algorithms for peer-to-peer systems},
 booktitle = {SPAA '04: Proceedings of the sixteenth annual ACM symposium on Parallelism in algorithms and architectures},
venue={SPAA},
 year = {2004},
 month = jun,
  cat:multiple =	{Theory;P2P},
 isbn = {1-58113-840-7},
 pages = {36--43},
 location = {Barcelona, Spain},
 doi = {http://doi.acm.org/10.1145/1007912.1007919},
 publisher = {ACM Press},
note={Preliminary version in IPTPS 2004},
ps={Papers/loadbalancing-spaa.ps},
pdf={Papers/loadbalancing-spaa.pdf},
abstract = {Load balancing is a critical issue for the efficient operation of peer-to-peer networks. We give two new load-balancing protocols whose provable performance guarantees are within a constant factor of optimal. Our protocols refine the consistent hashing data structure that underlies the Chord (and Koorde) P2P network. Both preserve Chord's logarithmic query time and near-optimal data migration cost.Consistent hashing is an instance of the distributed hash table (DHT) paradigm for assigning items to nodes in a peer-to-peer system: items and nodes are mapped to a common address space, and nodes have to store all items residing closeby in the address space.Our first protocol balances the distribution of the key address space to nodes, which yields a load-balanced system when the DHT maps items "randomly" into the address space. To our knowledge, this yields the first P2P scheme simultaneously achieving O(log n) degree, O(log n) look-up cost, and constant-factor load balance (previous schemes settled for any two of the three).Our second protocol aims to directly balance the distribution of items among the nodes. This is useful when the distribution of items in the address space cannot be randomized. We give a simple protocol that balances load by moving nodes to arbitrary locations "where they are needed." As an application, we use the last protocol to give an optimal implementation of a distributed data structure for range searches on ordered data.}
}

@article{Karger:P2PLoadBalance-Journal,
 author = {David R. Karger and Matthias Ruhl},
 title = {Simple efficient load balancing algorithms for peer-to-peer systems},
 journal = {Theory of Computing Systems},
 volume = 39,
 number = 6,
 year = {2006},
 month = nov,
  cat:multiple =	{Theory;P2P},
 pages = {787--804},
note={Preliminary versions in IPTPS 2004 and SPAA 2004},
pdf={Papers/dht-loadbalance-journal.pdf},
abstract = {Load balancing is a critical issue for the efficient operation of peer-to-peer (P2P) networks. We give two new load-balancing protocols whose provable performance guarantees are within a constant factor of optimal. Our protocols refine the consistent hashing data structure that underlies the Chord (and Koorde) P2P network. Both preserve Chord's logarithmic query time and near-optimal data migration cost.
Consistent hashing is an instance of the distributed hash table (DHT) paradigm for assigning items to nodes in a P2P system: items and nodes are mapped to a common address space, and nodes have to store all items residing closeby in the address space.
Our first protocol balances the distribution of the key address space to nodes, which yields a load-balanced system when the DHT maps items "randomly" into the address space. To our knowledge, this yields the first P2P scheme simultaneously achieving O(log n) degree, O(log n) look-up cost, and constant-factor load balance (previous schemes settled for any two of the three).
Our second protocol aims to balance directly the distribution of items among the nodes. This is useful when the distribution of items in the address space cannot be randomized. We give a simple protocol that balances load by moving nodes to arbitrary locations "where they are needed." As an application, we use the last protocol to give an optimal implementation of a distributed data structure for range searches on ordered data.}
}

@inproceedings{Karger:DetNetCoding,
author = {Nicholas J. A. Harvey and David R. Karger and Kazuo Murota},
title = {Deterministic Network Coding by Matrix Completion},
crossref={SODA05},
ps={Papers/detnetcode.ps},
pdf={Papers/detnetcode.pdf},
cat:multiple =	{Theory; Coding},
abstsract = { We present a new deterministic algorithm to construct network codes for multicast problems, a particular class of network information ow problems. Our algorithm easily generalizes to several variants of multicast problems. Our approach is based on a new algorithm for maximum-rank completion of mixed matrices---taking a matrix whose entries are a mixture of numeric values and symbolic variables, and assigning values to the variables so as to maximize the resulting matrix rank. Our algorithm is faster than existing deterministic algorithms and can operate over a smaller field.
}
}

@inproceedings{Karger:MatrixCompletion,
 author = {Nicholas J. A. Harvey and David R. Karger and Sergey
                  Yekhanin},
 title = {The Complexity of Matrix Completion},
  crossref =	 {SODA06},
 pages = {1103--1111},
 doi = {http://doi.acm.org/10.1145/1109557.1109679},
 pdf = {http://math.ias.edu/~yekhanin/Papers/Soda06.pdf},
 cat:multiple =	{Theory;Coding},
abstsract = {Given a matrix whose entries are a mixture of numeric values and symbolic variables, the matrix completion problem is to assign values to the variables so as to maximize the resulting matrix rank. This problem has deep connections to computational complexity and numerous important algorithmic applications. Determining the complexity of this problem is a fundamental open question in computational complexity. Under different settings of parameters, the problem is variously in P, in RP, or NP-hard. We shed new light on this landscape by demonstrating a new region of NP-hard scenarios. As a special case, we obtain the first known hardness result for matrices in which each variable appears only twice.Another particular scenario that we consider is the simultaneous matrix completion problem, where one must simultaneously maximize the rank for several matrices that share variables. This problem has important applications in the field of network coding. Recent work has given a simple, greedy, deterministic algorithm for this problem, assuming that the algorithm works over a sufficiently large field. We show an exact threshold for the field size required to find a simultaneous completion efficiently. This result implies that, surprisingly, the simple greedy algorithm is optimal: finding a simultaneous completion over any smaller field is NP-hard.}
 }

@inproceedings{Karger:SubRings,
  author={David R. Karger and Matthias Ruhl},
  title= {Diminished Chord: A Protocol for Heterogeneous Subgroup
                  Formation in Peer to Peer Systems},
  crossref={SODA04},
  ps = {Papers/subgroups-iptps.ps},
  pdf = {Papers/subgroups-iptps.pdf},
  cat:multiple =	{Theory;P2P},
abstract = {In most of the P2P systems developed so far, all nodes play essentially the same role. In some applications, however, different machine capabilities or owner preferences may mean that only a subset of nodes in the system should participate in offering a particular service. Arranging for each service to be supported by a different peer to peer network is, we argue here, a wasteful solution. Instead, we propose a version of the Chord peer-to-peer protocol that allows any subset of nodes in the network to jointly offer a service without forming their own Chord ring. Our variant supports the same efficient join/leave/insert/delete operations that the subgroup would get if they did form their own separate peer to peer network, but requires significantly less resources than the separate network would. For each subgroup of k machines, our protocol uses O(k) additional storage in the primal Chord ring. The insertion or deletion of a node in the subgroup and the lookup of the next node of a subgroup all require O(log n) hops.
}
}


@inproceedings{Rennie03,
note={see karger:fixbayes}
}


@InProceedings{Karger:BayesIR,
  author = 	 {Jaime Teevan and David R. Karger},
  title = 	 {Empirical Development of an Exponential
                  Probabilistic Model for Text Retrieval: Using
                  Textual Analysis to Build a Better Model},
  crossref =	 {sigir03},
  studentwork = student,
cat:multiple =	{Information Retrieval;Machine Learning},
  ps = hayweb # {teevan.sigir03.ps},
  pdf = hayweb # {teevan.sigir03.pdf},
abstract = {Much work in information retrieval focuses on using a model of documents and queries to derive retrieval algorithms. Model based development is a useful alternative to heuristic development because in a model the assumptions are explicit and can be examined and refined independent of the particular retrieval algorithm. We explore the explicit assumptions underlying the naive framework by performing computational analysis of actual corpora and queries to devise a generative document model that closely matches text. Our thesis is that a model so developed will be more accurate than existing models, and thus more useful in retrieval, as well as other applications. We test this by learning from a corpus the best document model. We find the learned model better predicts the existence of text data and has improved performance on certain IR tasks.}
}


@InProceedings{Karger:FixBayes,
  author = 	 {Jason D. M. Rennie and Lawrence Shih and Jaime
                  Teevan and David R. Karger},
  title = 	 {Tackling the Poor Assumptions of Naive Bayes Text
                  Classifiers},
  crossref =	 {icml03},
cat:multiple =	{Information Retrieval;Machine Learning},
  studentwork = student,
  psgz = hayweb # {rennie.icml03.ps.gz},
  pdf = hayweb # {rennie.icml03.pdf},
abstract = {Naive Bayes is often used as a baseline in
text classification because it is fast and easy
to implement. Its severe assumptions make
such efficiency possible but also adversely affect
the quality of its results. In this paper we
propose simple, heuristic solutions to some of
the problems with Naive Bayes classifiers, addressing
both systemic issues as well as problems
that arise because text is not actually
generated according to a multinomial model.
We find that our simple corrections result in a
fast algorithm that is competitive with stateof-
the-art text classification algorithms such
as the Support Vector Machine.}
}


@inproceedings{Karger:Markov,
        author = {David R. Karger and Nati Srebro},
        title = {Learning Markov Networks: Maximum
                  Bounded Tree-width Graphs},
cat:multiple =	{Theory;Machine Learning},
        postscript = {Papers/bayes.ps},
        psgz = {Papers/bayes.ps.gz},
        crossref ={SODA01},
        pages={392--401},
        studentwork = {\asteriskit{\labelwidth} },
abstract = {Markov networks are a common class of graphical models used in machine learning. Such models use an undirected graph to capture dependency information among random variables in a joint probability distribution. Once one has chosen to use a Markov network model, one aims to choose the model that ``best explains'' the data that has been observed---this model can then be used to make predictions about future data.
We show that the problem of learning a maximum likelihood Markov network given certain observed data can be reduced to the problem of identifying a maximum weight low-treewidth graph under a given input weight function. We give the first constant factor approximation algorithm for this problem. More precisely, for any fixed treewidth objective k, we find a treewidth-k graph with an f(k) fraction of the maximum possible weight of any treewidth-k graph.}
}

@inproceedings{Karger:Matroid-Conf,
	author = karger,
	title = {Random Sampling in Matroids, with Applications to
Graph Connectivity and Minimum Spanning Trees},
	crossref = {FOCS93},
        ps = {http://people.csail.mit.edu/karger/Papers/matroid.ps},
cat:multiple =	{Theory;Cuts and Flows},
        note = journal # mp # { B 82(1--2)},
	pages = {84--93},
abstract = {Random sampling is a powerful tool for gathering
                  information about a group by considering only a
                  small part of it. We discuss some broadly applicable
                  paradigms for using random sampling in combinatorial
                  optimization and demonstrate the effectiveness of
                  these paradigms for two optimization problems on
                  matroids: Finding an optimum matroid basis and
                  packing disjoint matroid bases. Applications of
                  these ideas to the graphic matroid led to fast
                  algorithms for minimum spanning trees and minimum
                  cuts.  An optimum matroid basis is typically found
                  by a greedy algorithm that grows an independent set
                  into an the optimum basis one element at a
                  time. This continuous change in the independent set
                  can make it hard to perform the independence tests
                  needed by the greedy algorithm. We simplify matters
                  by using sampling to reduce the problem of finding
                  an optimum matroid basis to the problem of verifying
                  that a given fixed basis is optimum, showing that
                  the two problems can be solved in roughly the same
                  time.  Another application of sampling is to packing
                  matroid bases, also known as matroid
                  partitioning. Sampling reduces the number of bases
                  that must be packed. We combine sampling with a
                  greedy packing strategy that reduces the size of the
                  matroid. Together, these techniques give accelerated
                  packing algorithms. We give particular attention to
                  the problem of packing spanning trees in graphs,
                  which has applications in network reliability
                  analysis. Our results can be seen as generalizing
                  certain results from random graph theory. The
                  techniques have also been effective for other
                  packing problems.}}

@article{Karger:Matroid,
	author = karger,
	title = {Random Sampling and Greedy Sparsification in Matroid
Optimization Problems},
	journal = mp # { {B}},
	month = jun,
	year = 1998,
        volume = {82},
        ps = {http://people.csail.mit.edu/karger/Papers/matroid.ps},
        number = {1--2},
	note = prelim # FOCS93,
        cat:multiple =	{Theory;Cuts and Flows},
	pages = {41--81},
abstract = {Random sampling is a powerful tool for gathering
                  information about a group by considering only a
                  small part of it. We discuss some broadly applicable
                  paradigms for using random sampling in combinatorial
                  optimization, and demonstrate the effectiveness of
                  these paradigms for two optimization problems on
                  matroids: finding an optimum matroid basis and
                  packing disjoint matroid bases. Applications of
                  these ideas to the graphic matroid led to fast
                  algorithms for minimum spanning trees and minimum
                  cuts.  An optimum matroid basis is typically found
                  by a greedy algorithm that grows an independent set
                  into an the optimum basis one element at a
                  time. This continuous change in the independent set
                  can make it hard to perform the independence tests
                  needed by the greedy algorithm. We simplify matters
                  by using sampling to reduce the problem of finding
                  an optimum matroid basis to the problem of verifying
                  that a given fixed basis is optimum, showing that
                  the two problems can be solved in roughly the same
                  time.  Another application of sampling is to packing
                  matroid bases, also known as matroid
                  partitioning. Sampling reduces the number of bases
                  that must be packed. We combine sampling with a
                  greedy packing strategy that reduces the size of the
                  matroid. Together, these techniques give accelerated
                  packing algorithms. We give particular attention to
                  the problem of packing spanning trees in graphs,
                  which has applications in network reliability
                  analysis. Our results can be seen as generalizing
                  certain results from random graph theory. The
                  techniques have also been effective for other
                  packing problems.}}

@inproceedings{Karger:Mincut,
	author = karger,
	title = {Global Min-cuts in {$\RNC$} and Other Ramifications
of a Simple Mincut Algorithm},
	crossref = {SODA93},
        ps = {Papers/mincut.ps},
        cat:multiple =	{Theory;Cuts and Flows},
        note = journal # jacm # {43(4)},
	pages = {21--30},
abstract = {This paper presents a new algorithm for
finding global min-cuts in weighted, undirected graphs.
One of the strengths of the algorithm is its extreme
simplicity. This randomized algorithm can be implemented
as a strongly polynomial sequential algorithm
with running time 6(mn2), even if space is restricted
to O(n), or can be parallelized as an Zn/C algorithm
which runs in time O(log2 n) on a CRCW PRAM with
mn2 log n processors. In addition to yielding the best
known processor bounds on unweighted graphs, this algorithm
provides the first proof that the min-cut problem
for weighted undirected graphs is in 7ZAfC. The
algorithm does more than find a single mm-cut; it finds
all of them. The algorithm also yields numerous results
on network reliability, enumeration of cuts, multi-way
cuts, and approximate mm-cuts.
1}}

@inproceedings{Karger:Makespan-Conf,
	author = {David R. Karger and Steven Phillips and Eric Torng},
	title = {A Better Algorithm for an Ancient Scheduling Problem},
	pages = {132--140},
  ps = {http://people.csail.mit.edu/karger/Papers/makespan.ps},
        cat:multiple =	{Theory;Scheduling},
        note = journal # JAlg # { 20},
	crossref = {SODA94},
abstract = {One of the oldest and simplest variants of multiprocessor
scheduling is the on-line scheduling problem studied by
Graham in 1966. In this problem, the jobs arrive on-line
and must be scheduled non-preemptively on m identical
machines so as to minimize the makespan. The size of
a job is known on arrival. Graham proved that the List
Processing Algorithm which assigns each job to the currently
least loaded machine has competitive ratio (2 - l/m).
Recently algorithms with smaller competitive ratios than
List Processing have been discovered, culminating in Bartal,
Fiat, Karloff, and Vohra's construction of an algorithm with
competitive ratio bounded away from 2. Their algorithm
has a competitive ratio of at most (2 - l/70) w 1.986 for
all m; hence for m > 70, their algorithm is provably better
than List Processing.
We present a more natural algorithm that outperforms
List Processing for any m 2 6 and has a competitive ratio
of at most 1.945 for all m, which is significantly closer
to the best known lower bound of 1.837 for the problem.
We show that our analysis of the algorithm is almost tight
by presenting a lower bound of 1.9378 on the algorithm's
competitive ratio for large m.}
}

@Article{Karger:Makespan,
  author = 	 {David R. Karger and Steven Phillips and Eric Torng},
  title = 	 {A Better Algorithm for an Ancient Scheduling Problem},
  journal =  JALG,
  year =	 1996,
	month = mar,
  volume =	 20,
  ps = {http://www.cse.msu.edu/~torng/Research/Pubs/ancient.ps},
  pages =	 "400--430",
        cat:multiple =	{Theory;Scheduling},
  note =	 prelim # SODA94,
abstract = {One of the oldest and simplest variants of multiprocessor
scheduling is the on-line scheduling problem studied by
Graham in 1966. In this problem, the jobs arrive on-line
and must be scheduled non-preemptively on m identical
machines so as to minimize the makespan. The size of
a job is known on arrival. Graham proved that the List
Processing Algorithm which assigns each job to the currently
least loaded machine has competitive ratio (2 - l/m).
Recently algorithms with smaller competitive ratios than
List Processing have been discovered, culminating in Bartal,
Fiat, Karloff, and Vohra's construction of an algorithm with
competitive ratio bounded away from 2. Their algorithm
has a competitive ratio of at most (2 - l/70) w 1.986 for
all m; hence for m > 70, their algorithm is provably better
than List Processing.
We present a more natural algorithm that outperforms
List Processing for any m 2 6 and has a competitive ratio
of at most 1.945 for all m, which is significantly closer
to the best known lower bound of 1.837 for the problem.
We show that our analysis of the algorithm is almost tight
by presenting a lower bound of 1.9378 on the algorithm's
competitive ratio for large m.
}
}
@unpublished{Karger:MST-manuscript,
	author = karger,
	title = {Approximating, Verifying, and Constructing
Minimum Spanning Forests},
	note = {Manuscript.},
        cat = {Theory},
	year = 1992}

@inproceedings{Karger:Maybecast,
        author = {David R. Karger and Maria Minkoff},
        title = {Building Routing Trees with Incomplete Global
                  Knowledge},
        crossref = {FOCS00},
        cat = {Theory},
        ps = {Papers/maybecast.ps},
  studentwork = {\asteriskit{\labelwidth} } # " ",
        pages = {613--623},
  cat = {Theory}
}

@inproceedings{Karger:2Stage,
 author = {Nicole Immorlica and David Karger and Maria Minkoff and
                  Vahab S. Mirrokni},
 title = {On the costs and benefits of procrastination: approximation
                  algorithms for stochastic combinatorial optimization
                  problems},
 pages = {691--700},
 pdf = {http://www.ece.northwestern.edu/~nickle/pubs/stochopt.pdf},
 crossref={SODA04},
 cat = {Theory},
 abstract = {Combinatorial optimization is often used to "plan ahead," purchasing and allocating resources for demands that are not precisely known at the time of solution. This advance planning may be done because resources become very expensive to purchase or difficult to allocate at the last minute when the demands are known. In this work we study the tradeoffs involved in making some purchase/allocation decisions early to reduce cost while deferring others at greater expense to take advantage of additional, late-arriving information. We consider a number of combinatorial optimization problems in which the problem instance is uncertain---modeled by a probability distribution---and in which solution elements can be purchased cheaply now or at greater expense after the distribution is sampled. We show how to approximately optimize the choice of what to purchase in advance and what to defer.}
 }

@article{Karger:DiscountTSP-Journal,
  author    = {Avrim Blum and
               Shuchi Chawla and
               David R. Karger and
               Terran Lane and
               Adam Meyerson and
               Maria Minkoff},
  title     = {Approximation Algorithms for Orienteering and Discounted-Reward
               TSP},
  journal   = sicomp,
  pdf = {orienteering-sicomp.pdf},
  note = prelim # FOCS03,
  volume    = {37},
  number    = {2},
  year      = {2007},
  cat = {Theory},
  pages     = {653-670},
  doi        = {http://dx.doi.org/10.1137/050645464}
}

@inproceedings{Karger:SmoothedBinPacking,
  author    = {David R. Karger and
               Krzysztof Onak},
  title     = {Polynomial approximation schemes for smoothed and random
               instances of multidimensional packing problems},
  crossref  = {SODA07},
  cat = {Theory},
  venue = {SODA},
  pages     = {1207-1216},
  ee        = {http://doi.acm.org/10.1145/1283383.1283513}
}

@InProceedings{Karger:DiscountTSP,
  author = 	 {Avrim Blum and Shuchi Chawla and David R. Karger and
                  Terran Lane and Adam Meyerson and Maria Minkoff},
  title = 	 {Approximation Algorithms for Orienteering and
                  Discounted-Reward TSP},
  crossref =	 {FOCS03},
  cat = {Theory},
  note = journal # sicomp # "37(2)",
  ps = {http://people.csail.mit.edu/karger/Papers/markovTSP.ps},
  studentwork = student,
  abstract = {In this paper, we give the first constant-factor
                  approximation algorithm for the rooted ORIENTEERING
                  problem, as well as a new problem that we call the
                  DISCOUNTED-REWARD-TSP, motivated by robot
                  navigation. In both problems, we are given a graph
                  with lengths on edges and rewards on nodes, and a
                  start node s. In the ORIENTEERING problem, the goal
                  is to find a path starting at s that maximizes the
                  reward collected, subject to a hard limit on the
                  total length of the path. In the DISCOUNTEDREWARD-
                  TSP, instead of a length limit we are given a
                  discount factor ?, and the goal is to maximize total
                  discounted reward collected, where reward for a node
                  reached at time t is discounted by ?t. This problem
                  is motivated by an approximation to a planning
                  problem in theMarkov decision process (MDP)
                  framework under the commonly employed infinite
                  horizon discounted reward optimality criterion. The
                  approximation arises from a need to deal with
                  exponentially large state spaces that emerge when
                  trying to model one-time events and non-repeatable
                  rewards (such as for package deliveries). We also
                  consider tree and multiple-path variants of these
                  problems and provide approximations for those as
                  well.  Although the unrooted ORIENTEERING problem,
                  where there is no fixed start node s, has been known
                  to be approximable using algorithms for related
                  problems such as k-TSP (in which the amount of
                  reward to be collected is fixed and the total length
                  is approximately minimized), ours is the first to
                  approximate the rooted question, solving an open
                  problem [3, 1]. We complement our approximation
                  result for ORIENTEERING by showing that the problem
                  is APX-hard.  }
}

@article{Karger:Paths,
crossref={Karger:Paths-Journal}}
@article{Karger:Paths-Journal,
	author = {David R. Karger and Daphne Koller and Steven J. Phillips},
	title = {Finding the Hidden Path: Time Bounds for All-Pairs
		Shortest Paths},
	pages = {1199--1217},
        year = 1993,
        month = dec,
 volume = 22,
number = 6,
ps = {http://people.csail.mit.edu/karger/Papers/path.journal.ps},
cat = {Theory},
        note = prelim # FOCS91,
        journal = sicomp,
abstract = {The all-pairs shortest-paths problem in weighted graphs is investigated. An algorithm---the Hidden-Paths Algorithm---that finds these paths in time $O(m^ *  n + n^2 \log n)$, where $m^ * $ is the number of edges participating in shortest paths, is presented. The algorithm is a practical substitute for Dijkstra's algorithm. It is argued that $m^ * $ is likely to be small in practice since $m^ *  = O(n\log n)$ with high probability for many probability distributions on edge weights. An $\Omega (mn)$ lower bound on the running time of any path-comparison-based algorithm for the all-pairs shortest-paths problem is also proved. Path-comparison-based algorithms form a natural class containing the Hidden-Paths Algorithm, as well as the algorithms of E. W. Dijkstra [Numer. Math., 1 (1959), pp. 269--271] and R. W. Floyd [Comm. ACM, 5 (1962), p. 345]. Lastly, generalized forms of the shortest-paths problem are considered, and it is shown that many of the standard shortest-paths algorithms are effective in this more general setting.}
}

@InProceedings{Karger:Paths-Conf,
  title={Finding the Hidden Path: Time Bounds for All-Pairs Shortest Paths},
  author={David R. Karger and Daphne Koller and Steven J. Phillips},
  pages={560--568},
  crossref={FOCS91},
  note = journal # sicomp #  { 22(6)},
  cat = {Theory},
  ps = {http://people.csail.mit.edu/karger/Papers/path.focs.ps},
  abstract = {The all-pairs shortest paths problem in weighted graphs is investigated. An algorithm called the hidden paths algorithm, which finds these paths in time O(m*+n n2 log n), where m* is the number of edges participating in shortest paths, is presented. It is argued that m* is likely to be small in practice, since m*=O(n log n) with high probability for many probability distributions on edge weights. An O(mn) lower bound on the running time of any path-comparison-based algorithm for the all-pairs shortest paths problem is proved}
}


@InProceedings{Karger:P2P-search,
  author = 	 {Jinyang Li and Book Thau Loo and Joe Hellerstein and
                  M. Frans Kaashoek and David R. Karger and Robert Morris},
  title = 	 {On the Feasibility of Peer-to-Peer Web Indexing and
                  Search},
  crossref = {iptps03},
  pages = {207--215},
cat:multiple =	{Systems;P2P},
pdf = {http://pdos.csail.mit.edu/~rtm/papers/search_feasibility.pdf},
  studentwork =  student,
abstract = {This paper discusses the feasibility of peer-to-peer full-text keyword search of the Web. Two classes of keyword search techniques are in use or have been proposed: flooding of queries over an overlay network (as in Gnutella), and intersection of index lists stored in a distributed hash table. We present a simple feasibility analysis based on the resource constraints and search workload. Our study suggests that the peer-to-peer network does not have enough capacity to make naive use of either of search techniques attractive for Web search. The paper presents a number of existing and novel optimizations for P2P search based on distributed hash tables, estimates their effects on performance, and concludes that in combination these optimizations would bring the problem to within an order of magnitude of feasibility. The paper suggests a number of compromises that might achieve the last order of magnitude.}
}

@InProceedings{Karger:P2P-Evol,
  author = 	 {David Liben-Nowell and Hari Balakrishnan and
                      David R. Karger},
  title = 	 {Analysis of the Evolution of Peer to Peer Systems},
  booktitle =	 podc,
  venue = {PODC},
  pages = {233--242},
  year = 2002,
  studentwork = {\asteriskit{\labelwidth} } # " ",
  address = {Monterey, CA},
  month = jul,
  cat:multiple = {Theory;Applications of Theory;P2P},
  ps = {http://pdos.lcs.mit.edu/chord/papers/podc2002.ps},
  pdf = {http://pdos.lcs.mit.edu/chord/papers/podc2002.pdf},
  abstract = {In this paper, we give a theoretical analysis of peer-to-peer (P2P) networks operating in the face of concurrent joins and unexpected departures. We focus on Chord, a recently developed P2P system that implements a distributed hash table abstraction, and study the process by which Chord maintains its distributed state as nodes join and leave the system. We argue that traditional performance measures based on run-time are uninformative for a continually running P2P network, and that the rate at which nodes in the network need to participate to maintain system state is a more useful metric. We give a general lower bound on this rate for a network to remain connected, and prove that an appropriately modified version of Chord's maintenance rate is within a logarithmic factor of the optimum rate.}
}

@InProceedings{Karger:P2P-Evol-IPTPS,
  author = {David Liben-Nowell and Hari Balakrishnan and David R. Karger},
  title = {Observations on the Dynamic Evolution of Peer to Peer Systems},
  studentwork = student,
  cat:multiple = {Theory;Applications of Theory;P2P},
  crossref={iptps02},
  abstract = {A fundamental theoretical challenge in peer-to-peer systems is proving statements about the evolution of the system while nodes are continuously joining and leaving. Because the system will operate for an infinite time, performance measures based on runtime are uninformative; instead, we must study the  rate at which nodes consume resources in order to maintain the system state. This ``maintenance bandwidth'' depends on the rate at which nodes tend to enter and leave the system. In this paper, we formalize this dependence. Having done so, we analyze the Chord peer-to-peer protocol. We show that Chord's maintenance bandwidth to handle concurrent node arrivals and departures is near optimal, exceeding the lower bound by only a logarithmic factor. We also outline and analyze an algorithm that converges to a correct routing state from an arbitrary initial condition.}
}


@inProceedings{Karger:Random-Conf,
  author = {David R. Karger and Daphne Koller},
  title = 	 "(De)Randomized Construction of Small Sample Spaces
                  in {$\NC$}",
  crossref =	 {FOCS94},
note = journal # JCSS # { 55},
pages = {252--263},
ps = {http://people.csail.mit.edu/karger/Papers/proc-random.ps},
cat = {Theory},
abstract = {Koller and Megiddo introduced the paradigm of constructing compact distributions that satisfy a given set of constraints and showed how it can be used to efficiently derandomize certain types of algorithms. In this paper, we significantly extend their results in two ways. First, we show how their approach can be applied to deal with more general expectation constraints.More importantly, we provide the first parallel (&Nscr;&Cscr;) algorithmfor constructing a compact distribution that satisfies the constraintsup to a small relative error. This algorithm deals with constraintsover any event that can be verified by finite automata, includingall independence constraints as well as constraints over eventsrelating to the parity or sum of a certain set of variables.Our construction relies on a new and independently interestingparallel algorithm for converting a solution to a linear systeminto an almost basic approximate solution to the same system.We use these techniques in the first &Nscr;&Cscr; derandomization of analgorithm for constructing large independent sets in d-uniformhypergraphs for arbitrary d. We also show how the linear programmingperspective suggests new proof techniques which might be usefulin general probabilistic analysis.}
}

@Article{Karger:Random,
  title =	 {{(De)randomized} Construction of Small Sample Spaces
                  in~{$\mathcal{NC}$}},
  author =	 {David R. Karger and Daphne Koller},
  pages =	 {402--413},
  journal =  JCSS,
  year =	 1997,
  month =	 dec,
  volume =	 55,
  number =	 3,
  preliminary =	 {focs::KargerK1994},
  brag =	 special # FOCS94,
  cat = {Theory},
  ps = {http://people.csail.mit.edu/karger/Papers/random.ps},
abstract = {Koller and Megiddo introduced the paradigm of constructing compact distributions that satisfy a given set of constraints and showed how it can be used to efficiently derandomize certain types of algorithms. In this paper, we significantly extend their results in two ways. First, we show how their approach can be applied to deal with more generalexpectation constraints. More importantly, we provide the firstparallel(NC) algorithm for constructing a compact distribution that satisfies the constraints up to a smallrelativeerror. This algorithm deals with constraints over any event that can be verified by finite automata, including allindependence constraintsas well as constraints over events relating to the parity or sum of a certain set of variables. Our construction relies on a new and independently interesting parallel algorithm for converting a solution to a linear system into an almost basic approximate solution to the same system. We use these techniques in the first NC derandomization of an algorithm for constructing large independent sets ind-uniform hypergraphs forarbitrary d. We also show how the linear programming perspective suggests new proof techniques which might be useful in general probabilistic analysis.}
}

@article{Karger:Ring,
  author =	 {Perry Fizzano and David R. Karger and Cliff Stein
                  and Joel Wein},
  title =	 {Job Scheduling in Rings},
  pages =	 "122--133",
  journal =	 {Journal of Parallel and Distributed Computing},
  volume =	 45,
  number =	 2,
  year =	 1997,
  month =	 sep,
  note =	 prelim # SPAA94,
  cat = {Theory},
abstract = {We give a distributed approximation algorithm for job scheduling in a ring architecture. In contrast to many other parallel scheduling models, the model we consider captures the influence of the underlying communications network by specifying that task migration from one processor to another takes time proportional to the distance between those two processors in the network. As a result, our algorithm must balance computational load and communication time. The algorithm is simple, requires no global control, and yields schedules of length at most 4.22 times optimal. We also give a lower bound on the performance of any distributed algorithm and the results of simulation experiments which suggest better performance than does our worst-case analysis.}
}

@InProceedings{Karger:Ring-Conf,
  author =	 {Perry Fizzano and David R. Karger and Cliff Stein
                  and Joel Wein},
  title =	 {Job Scheduling in Rings},
  ps = {Papers/ring.ps},
  pages =	 "210--219",
  crossref =	 {SPAA94},
  note =	 journal # jpdc # { 45(2)},
  cat = {Theory},
abstract = {We give a distributed approximation algorithm for job scheduling in a ring architecture. In contrast to many other parallel scheduling models, the model we consider captures the influence of the underlying communications network by specifying that task migration from one processor to another takes time proportional to the distance between those two processors in the network. As a result, our algorithm must balance computational load and communication time. The algorithm is simple, requires no global control, and yields schedules of length at most 4.22 times optimal. We also give a lower bound on the performance of any distributed algorithm and the results of simulation experiments which suggest better performance than does our worst-case analysis.}
}
@article{Karger:MST,
  note=	 {see Karger:MST-Journal}
}

@article{Karger:MST-Journal,
  author =	 {David R. Karger and Philip N. Klein and Robert
                  E. Tarjan},
  title =	 {A Randomized Linear-Time Algorithm to Find Minimum
                  Spanning Trees},
  journal =	 JACM,
  volume =	 42,
  number =	 2,
  pages =	 {321--328},
  year =	 1995,
  month =	 mar,
  cat = {Theory},
  ps = {http://people.csail.mit.edu/karger/Papers/mst.ps},
  url = {http://doi.acm.org/10.1145/201019.201022},
abstract = {We present a randomized linear-time algorithm to find a minimum spanning tree in a connected graph with edge weights. The algorithm uses random sampling in combination with a recently discovered linear-time algorithm for verifying a minimum spanning tree. Our computational model is a unit-cost random-access machine with the restriction that the only operations allowed on edge weights are binary comparisons.}
}
@inproceedings{Karger:Multicut,
  author =	 {David R. Karger and Philip N. Klein and Clifford
                  Stein and Mikkel Thorup and Neal Young},
  title =	 {Optimal Rounding Algorithms for a Geometric
                  Embedding of the Multiway Cut Problem},
  crossref =	 {STOC99},
  ps = {http://people.csail.mit.edu/karger/Papers/kcut.ps},
  pages =	 {668--677},
cat = {Theory},
abstract = {Given an undirected graph with edge costs and a subset of
k 2 3 nodes called terminals, a multiway, or k-way, cut is
a subset of the edges whose removal disconnects each terminal
from the others. The multiway cut problem is to find
a minimum-cost multiway cut. This problem is Max-SNP
hard. Recently Calinescu, Karloff, end Rabbi (STOC'98)
gave a novel geometric relaxation of the problem and a rounding
scheme that produced a (312 - l/k)-approximation algorithm.
In this paper. we study their geometric relaxation. In particular,
we study the worst-case ratio between the value of
the relaxation and the value of the minimum multicut (the
so-called integrality gap of the relaxation). For k = 3, we
show the integrality gap is 12/11. giving tight upper and lower
bounds. That is, we exhibit a graph with integrality gap 12/11
and give an algorithm that finds a cut of value 12/11 times
the relaxation value. This is the best possible perfom~ance
guarantee for any algorithm based purely on the value of the
relaxation and improves on Calinescu et al.'s factor of 716.
We also improve the upper hounds for all larger values of
k. Fork = 4,5, our best upper bounds are based on computer
constructed and analyzed rounding schemes, while fork > 6
we give an algorithm with performance ratio 1.3438 - a.
Our results were discovered with the help of computational
experiments that we also describe here.
}
}
@article{Karger:Multicut-Journal,
  author =	 {David R. Karger and Philip N. Klein and Clifford
                  Stein and Mikkel Thorup and Neal Young},
  title =	 {Optimal Rounding Algorithms for a Geometric
                  Embedding of the Multiway Cut Problem},
  pdf = {http://people.csail.mit.edu/karger/Papers/kcut-journal.pdf},
  journal = {Mathematics of Operations Research},
  volume = 29,
  number = 3,
pages = {436--461},
year = 2004,
cat = {Theory},
abstract = {Given an undirected graph with edge costs and a subset of k = 3 nodes called terminals, a multiway, or k-way, cut is a subset of the edges whose removal disconnects each terminal from the others. The multiway cut problem is to .nd a minimum-cost multiway cut. This problem is Max-SNP hard. Recently, Calinescu et al. (Calinescu, G., H. Karloff, Y. Rabani. 2000. An improved approximation algorithm for Multiway Cut. J. Comput. System Sci. 60(3) 564-574) gave a novel geometric relaxation of the problem and a rounding scheme that produced a (3/2-1/k)-approximation algorithm. In this paper, we study their geometric relaxation. In particular, we study the worst-case ratio between the value of the relaxation and the value of the minimum multicut (the so-called integrality gap of the relaxation). For k =3, we show the integrality gap is 12/11, giving tight upper and lower bounds. That is, we exhibit a family of graphs with integrality gaps arbitrarily close to 12/11 and give an algorithm that .nds a cut of value 12/11 times the relaxation value. Our lower bound shows that this is the best possible performance guarantee for any algorithm based purely on the value of the relaxation. Our upper bound meets the lower bound and improves the factor of 7/6 shown by Calinescu et al. For all k, we show that there exists a rounding scheme with performance ratio equal to the integrality gap, and we give explicit constructions of polynomial-time rounding schemes that lead to improved upper bounds. For k = 4 and 5, our best upper bounds are based on computer-constructed rounding schemes (with computer proofs of correctness). For general k we give an algorithm with performance ratio 1.3438-ek. Our results were discovered with the help of computational experiments that we also describe here.}
}

@inproceedings{Karger:Packing,
	author = {David R. Karger and Serge Plotkin},
	title = {Adding Multiple Cost Constraints to Combinatorial
		Optimization Problems, with Applications to
		Multicommodity Flows},
        pages = {18--25},
        ps = {Papers/packing.ps},
	crossref = {STOC95},
 cat = {Theory},
abstract = {Minimum cost multicommodity flow is an instance of a simpler problem (multicommodity flow)
to which a cost constraint has been added. In this paper we present a general scheme for solving a
large class of such ``cost-added'' problems---even if more than one cost is added. One of the main
applications of this method is a new deterministic algorithm for approximately solving the minimumcost
multicommodity flow problem.
Our algorithm finds a (1 + e) approximation to the minimum cost flow in 0(e-3kmn) time,
where k is the number of commodities, m is the number of edges, and n is the number vertices in
the input problem. This improves the previous best deterministic bounds of O(e-4kmn2 ) [9] and
6(e-2k2m2) [15] by f~ctors of n/6 and ekm/n respectively. In fact, it even dominates the best
randomized bound of 0(e-2km2) [15].
The algorithm presented in this paper efficiently solves several other interesting generalizations
of rein-cost flow problems, such as one in which each commodity can have its own distinct shipping
cost per edge, or one in which there is more than one cost measure on the flows and all costs must
be kept small simultaneously. Our approach is based on an extension of the approximate packing
techniques in [15] and a generalization of the round-robin approach of [16] to multicommodity flow
without costs.}
}
@inproceedings{Karger:Rejection,
author =       "Daniel W. Engels and David R. Karger and S. G. Kolliopoulos
                 and S. Sengupta and R. N. Uma and Joel Wein",
  title =        "Techniques for Scheduling with Rejection",
  booktitle =      "European Symposium on Algorithms (Lecture notes in
                  Computer Science) ",
venue={ESA},
  volume =       "1461",
  pages =        "490",
  studentwork = {\asteriskit{\labelwidth} } # " ",
  year =         "1998",
month=aug,
  cat = {Theory},
  ps = {Papers/rejection.ps},
  coden =        "LNCSD9",
abstract = {We consider the general problem of scheduling a set of jobs
where we may choose not to schedule certain jobs, and thereby incur a
penalty for each rejected job. More specifically, we focus on choosing a
set of jobs to reject and constructing a schedule for the remaining jobs
so as to optimize the sum of the weighted completion times of the jobs
scheduled plus the sum of the penalties of the jobs rejected.
We give several techniques for designing scheduling algorithms under this
criterion. Many of these techniques show how to reduce a problem with
rejection to a (potentially more complex) scheduling problem without re-
jection. Some of the reductions are based on general properties of certain
kinds of linear-programming relaxations of optimization problems, and
therefore are applicable to problems outside of scheduling; we demon-
strate this by giving an approximation algorithm for a variant of the
facility-location problem.
In the last section of the paper we consider a different notion of rejec-
tion in the context of scheduling: scheduling jobs with due dates so as
to maximize the number of jobs that complete by their due dates, or
equivalently to minimize the number of jobs that do not complete by
their due date and that thus can be considered \rejected." We inves-
tigate the approximability of a simple version of this problem, giving
approximation algorithms and characterizing integrality gaps of a class
of linear-programming relaxations.},
  ISSN =         "0302-9743"}

@inproceedings{Karger:Reliability-Conf,
	author = {David R. Karger},
	title = {A Randomized Fully Polynomial Approximation Scheme
for the All Terminal Network Reliability Problem},
pages = {11--17},
	note = journal # sicomp # { 29(2)},
	crossref = {STOC95},
ps = {http://people.csail.mit.edu/karger/Papers/reliability.ps},
cat:multiple =	{Theory;Cuts and Flows},
abstract = {The classic all-terminal network reliability problem posits a graph, each of whose edges fails independently with some given probability. The goal is to determine the probability that the network becomes disconnected due to edge failures. This problem has obvious applications in the design of communication networks. Since the problem is $\SP$-complete and thus believed hard to solve exactly, a great deal of research has been devoted to  estimating the failure probability. In this paper, we give a  fully polynomial randomized approximation scheme that, given any n-vertex graph with specified failure probabilities, computes in time polynomial in n and $1/\epsilon$ an estimate for the failure probability that is accurate to within a relative error of $1\pm\epsilon$ with high probability. We also give a deterministic polynomial approximation scheme for the case of small failure probabilities. Some extensions to evaluating probabilities of k-connectivity, strong connectivity in directed Eulerian graphs and r-way disconnection, and to evaluating the Tutte polynomial are also described.}
}
@article{Karger:Reliability,
	author = {David R. Karger},
	title = {A Randomized Fully Polynomial Approximation Scheme
for the All Terminal Network Reliability Problem},
     journal = sicomp,
       volume = 29,
       number = 2,
       year = 1999,
        pages = {492--514},
        note = prelim # STOC95 # ". A corrected version was published
                  in SIAM Review 43(3)",
        brag = {Winner, SIAM Outstanding Paper Prize, 2000},
        cat:multiple =	{Theory;Cuts and Flows},
ps = {http://people.csail.mit.edu/karger/Papers/reliability-journal.ps},
abstract = {The classic all-terminal network reliability problem posits a graph, each of whose edges fails independently with some given probability. The goal is to determine the probability that the network becomes disconnected due to edge failures. This problem has obvious applications in the design of communication networks. Since the problem is $\SP$-complete and thus believed hard to solve exactly, a great deal of research has been devoted to  estimating the failure probability. In this paper, we give a  fully polynomial randomized approximation scheme that, given any n-vertex graph with specified failure probabilities, computes in time polynomial in n and $1/\epsilon$ an estimate for the failure probability that is accurate to within a relative error of $1\pm\epsilon$ with high probability. We also give a deterministic polynomial approximation scheme for the case of small failure probabilities. Some extensions to evaluating probabilities of k-connectivity, strong connectivity in directed Eulerian graphs and r-way disconnection, and to evaluating the Tutte polynomial are also described.}
	}
@article{Karger:Reliability-SIREV,
	author = {David R. Karger},
	title = {A Randomized Fully Polynomial Approximation Scheme
for the All Terminal Network Reliability Problem},
        journal = sirev,
        volume = 43,
        number = 3,
        year = 2001,

        pages = {499--522},
        note = prelim # STOC95 # ". This corrects a version published

                  in SICOMP",
        brag = {Winner, SIAM Outstanding Paper Prize, 2000},
        cat:multiple =	{Theory;Cuts and Flows},
ps = {http://people.csail.mit.edu/karger/Papers/reliability-sirev.ps},
abstract = {The classic all-terminal network reliability problem posits a graph, each of whose edges fails independently with some given probability. The goal is to determine the probability that the network becomes disconnected due to edge failures. This problem has obvious applications in the design of communication networks. Since the problem is ?P-complete and thus believed hard to solve exactly, a great deal of research has been devoted to estimating the failure probability. In this paper, we give a fully polynomial randomized approximation scheme that, given any n-vertex graph with specified failure probabilities, computes in time polynomial in n and 1/e an estimate for the failure probability that is accurate to within a relative error of 1  e with high probability. We also give a deterministic polynomial approximation scheme for the case of small failure probabilities. Some extensions to evaluating probabilities of k-connectivity, strong connectivity in directed Eulerian graphs and r-way disconnection, and to evaluating the Tutte polynomial are also described. This version of the paper corrects several errata that appeared in the previous journal publication [D. R. Karger, SIAM J. Comput., 29 (1999), pp. 492-514].}
	}
@inproceedings{Karger:Release,
        author = {Foto Afrati and Evripidis Bampis and
Chandra Chekuri and
David Karger and
Claire Kenyon and
Sanjeev Khanna and
Ioannis Milis and
Maurice Queyranne and
Martin Skutella and
Cliff Stein and
Maxim Sviridenko},
        title = {Approximation Schemes for Minimizing Average Weighted
  Completion Time with Release Dates},
        crossref = {FOCS99},
        pages = {32--43},
ps = {release.ps},
cat = {Theory},
abstract = {We consider the problem of scheduling jobs with release dates on parallel machines so as to minimize average weighted completion time. While constant factor approximation algorithms for many variants have been developed in the last few years, we present the first known polynomial time approximation schemes for several of them. Our results include PTASs for the case of identical parallel machines and a constant number of unrelated machines with and without preemption allowed. Our PTASs are also efficient. For most variants, the running time for a (1+e)-approximation on an instance with n jobs and m machines is O(nlog n) for each fixed e, and for all variants the running time's dependence on n is a fixed polynomial whose degree is independent of e and m.}
}

@inproceedings{ScatterGather,
note={see karger:scatter}
 }

@inproceedings{Karger:Scatter,
	author = {Douglas Cutting and David R. Karger and Jan Pedersen
and John W. Tukey},
	title = {Scatter/Gather: A Cluster-based Approach to
 Browsing Large Document Collections},
	booktitle = SIGIR92,
venue={SIGIR},
	year = 1992,
month=jun,
 isbn = {0-89791-523-2},
 location = {Copenhagen, Denmark},
 doi = {http://doi.acm.org/10.1145/133160.133214},
ps = {http://people.csail.mit.edu/karger/Papers/SIGIR92.ps},
 publisher = {ACM Press},
cat = {Information Retrieval},
	pages = {318-329},
abstract = {Document clustering has not been well received as an information retrieval tool. Objections to its use fall into two main categories: first, that clustering is too slow for large corpora (with running time often quadratic in the number of documents); and second, that clustering does not appreciably improve retrieval.
We argue that these problems arise only when clustering is used in an attempt to improve conventional search techniques. However, looking at clustering as an information access tool in its own right obviates these objections, and provides a powerful new access paradigm. We present a document browsing technique that employs document clustering as its primary operation. We also present fast (linear time) clustering algorithms which support this interactive browsing paradigm.}
}

@inproceedings{Karger:Scatter2,
	author = {Douglas Cutting and David R. Karger and Jan Pedersen},
	title = {Constant Interaction-Time Scatter/Gather
Browsing of Very Large Document Collections},
	booktitle = SIGIR93,
venue={SIGIR},
pages={126--134},
	year = 1993,
        month = jul,
ps = {http://people.csail.mit.edu/karger/Papers/SIGIR93.ps},
cat = {Information Retrieval},
        note = {Pittsburgh, PA},
abstract = {The Scatter/Gather document browsing method uses fast document clustering to produce table-of-contents-like outlines of large document collections. Previous work [1] developed linear-time document clustering algorithms to establish the feasibility of this method over moderately large collections. However, even linear-time algorithms are too slow to support interactive browsing of very large collections such as Tipster, the DARPA standard text retrieval evaluation collection. We present a scheme that supports constant interaction-time Scatter/Gather of arbitrarily large collections after near-linear time preprocessing. This involves the construction of a cluster hierarchy. A modification of Scatter/Gather employing this scheme, and an example of its use over the Tipster collection are presented.}
}

@inproceedings{Karger:ScatterResults,
        author = {Marti A. Hearst and David R. Karger and Jan O. Pedersen},
        title = {Scatter/Gather as a Tool for Navigating Search
                  Results},
        booktitle = {Proceedings of the AAAI Fall Symposium on
                  Knowledge Navigation},
venue={AAAI},
cat = {Information Retrieval},
ps = {ftp://parcftp.xerox.com/pub/hearst/knowlnav95.ps},
        year = {1995},
abstract ={ An important information access problem arises when the user is confronted with a very large number of documents that have been retrieved in response to a query. In this paper we explore the use of a technique, called Scatter/Gather, for the navigation of large collections of retrieved documents. Scatter/Gather clusters the documents into semantically coherent groups on-the-fly and presents descriptive summaries of the groups to the user. These groups can be used in several ways: to indentify useful subsets of documents to be perused with other tools, to eliminate subsets whose contents appear nonrelevant, or to select promising document subsets for reclustering into more refined groups. This paper describes the Scatter/Gather algorithm and illustrates its application to retrieval results via two examples.}}

@incollection{Karger:Scheduling,
	author = {David R. Karger and Clifford Stein and Joel Wein},
	title = {Scheduling Algorithms},
	editor = {Mikhail J. Atallah},
	booktitle = {Algorithms and Theory of Computation Handbook},
 	isbn={0849326494},
	publisher = {CRC Press},
cat={Theory},
	year = {1998}}

@inproceedings{Karger:Skeleton-Conf,
	author = {David R. Karger},
	title = {Random Sampling in Cut, Flow, and Network Design
Problems},
	crossref = {STOC94},
	pages = {648--657},
cat:multiple =	{Theory;Cuts and Flows},
ps = {http://people.csail.mit.edu/karger/Papers/skeleton.ps},
	note = journal # mor # { 24(2), 1999},
abstract = {We explore random sampling as a tool for solving undirected graph problems. We show that the sparse graph's
or skeleton, which arises when we randomly sample a
graph's edges will accurately approximate the value of
all cuts in the original graph. This makes sampling effective
for problems involving cuts in graphs.
We apply these tools in fast randomized (Monte Carlo
and Las Vegas) algorithms for approximating and exactly
finding cuts and flows in an unweighted, undirected
graph. We also give weighted-graph versions of
these algorithms which use a form of scaling to achieve
a sublinear dependence on the maximum edge weight.
Our methods also reduce the work done by some parallel
cut algorithms.
Our sampling theorems also yield faster algorithms
for several other cut based problems, including approximating
the best balanced cut of a graph, finding a
k-connected orientation of a 2k-connected graph, and
finding integral multicommodity flows in graphs with a
great deal of excess capacity.
Our sampling theorems apply even when the sampling
probabilities are different for different edges. Using
this fact, we show how to use randomized rounding
in (1+0(1))-approximation algorithm for the NP-complete minimum $k$-connected subgraph problem when
$k > log n$; the best previous approximation factor was
$\log k$.   Our techniques generalize to many other survivable
network design problems.}}

@article{Karger:Skeleton,
	author = {David R. Karger},
	title = {Random Sampling in Cut, Flow, and Network Design
Problems},
	journal = {Mathematics of Operations Research},
        volume = {24},
        number = 2,
        month = may,
        year = {1999},
        pages = {383--413},
ps = {http://people.csail.mit.edu/karger/Papers/skeleton-journal.ps},
cat:multiple =	{Theory;Cuts and Flows},
	note = prelim # STOC94,
abstract = {We use random sampling as a tool for solving undirected graph problems. We show that the sparse graph, or skeleton, that arises when we randomly sample a graph's edges will accurately approximate the value of all cuts in the original graph with high probability. This makes sampling effective for problems involving cuts in graphs. We present fast randomized (Monte Carlo and Las Vegas) algorithms for approximating and exactly finding minimum cuts and maximum flows in unweighted, undirected graphs. Our cut-approximation algorithms extend unchanged to weighted graphs while our weighted-graph flow algorithms are somewhat slower. Our approach gives a general paradigm with potential applications to any packing problem. It has since been used in a near-linear time algorithm for finding minimum cuts, as well as faster cut and flow algorithms. Our sampling theorems also yield faster algorithms for several other cut-based problems, including approximating the best balanced cut of a graph, finding a k-connected orientation of a 2k-connected graph, and finding integral multicommodity flows in graphs with a great deal of excess capacity. Our methods also improve the efficiency of some parallel cut and flow algorithms. Our methods also apply to the network design problem, where we wish to build a network satisfying certain connectivity requirements between vertices. We can purchase edges of various costs and wish to satisfy the requirements at minimum total cost. Since our sampling theorems apply even when the sampling probabilities are different for different edges, we can apply randomized rounding to solve network design problems. This gives approximation algorithms that guarantee much better approximations than previous algorithms whenever the minimum connectivity requirement is large. As a particular example, we improve the best approximation bound for the minimum k-connected subgraph problem from 1.85 to [math not displayed].}
	}
@inproceedings{Karger:SmoothFlow,
  author = 	 karger,
  title = 	 {Better Random Sampling Algorithms for Flows in
                  Undirected Graphs},
  crossref = {SODA98},
cat:multiple =	{Theory;Cuts and Flows},
ps = {http://people.csail.mit.edu/karger/Papers/flow2.ps},
pages = {490--499},
abstract = {We present better random sampling algorithms for maximum
flows in undirected graphs. Our algorithms apply to capacitated
or uncapacitated graphs, and find a maximum flow of
value v in ~

O(

p

mnv) time. This improves on a previous
bound of ~ O(m

2=3

n

1=3

v) given by the author recently, which
in turn improved on the O(mv) time bound for a typical
augmenting path algorithm. In uncapacitated graphs without
parallel edges, the bound is no worse than ~ O(n

5=2

). We
give another algorithm that finds a (1 \Gamma ffl) times maximum
flow in time ~

O(m

p

n=ffl), regardless of v.
}
}

@InProceedings{Karger:AugmentingPath,
  author = 	 {David R. Karger and Matthew S. Levine},
  title = 	 {Random Sampling from Residual Graphs},
  crossref =	 {STOC02},
  pages = {63--66},
  studentwork = student,
  ps = {Papers/resflow.ps},
cat:multiple =	{Theory;Cuts and Flows},
  psgz = {Papers/resflow.ps.gz},
abstract = { Consider an n-vertex, m-edge, undirected graph with maximum flow value v. We give a new (m+nv)-time maximum flow algorithm based on finding augmenting paths in random samples of the edges of residual graphs. After assigning certain special sampling probabilities to edges in (m) time, our algorithm is very simple: repeatedly find an augmenting path in a random sample of edges from the residual graph.
}
}

@article{Karger:AugmentingPath-Journal,
  author = 	 {David R. Karger and Matthew S. Levine},
  title = 	 {Random Sampling from Residual Graphs},
journal=sicomp,
year=2011
}
@InProceedings{Karger:SimpleFlow,
  author = 	 {David R. Karger and Matthew Levine},
  title = 	 {Finding Maximum Flows in Simple Undirected Graphs
                  Seems Faster than Bipartite Matching},
  crossref =  {STOC98},
  studentwork = {\asteriskit{\labelwidth} } # " ",
cat:multiple =	{Theory;Cuts and Flows},
ps = {http://people.csail.mit.edu/karger/Papers/STOC98.ps},
  pages = 	 {69--78},
abstract = {Considear nr r-vertex, m-edge, undirected graph with maximum
llow value v. We give a method to find augmenting
paths in such a graph in amortized sub-linear (O(n@) time
per path. This lets us improve the time bound of the classic
augmenting path algorithm to O(m + nvsi2) on simple
graphs. The addition of a blocking flow subroutine gives a
simple, deterministic O(nm2/3v1/6)-time algorithm, We also
use our technique to improve known randomized algorithms,
giving @rtr+nv5/4)-time and d(m+-nt'~gv)-time algorithms
for capacitated undirected graphs.- For simple graphs, in
which v s II, the last bound is a(n2s2), improving on the best
previous bound of O(n2*5), which is also the best known time
bound for bipartite matching.}
}

@InProceedings{Karger:Stcut-conf,
  author = 	 benczur # and # karger,
  title = 	 "Approximate $s$--$t$ Min-Cuts in {$\Olog(n^2)$} Time",
  crossref =	 "STOC96",
  pages = {47--55},
cat:multiple =	{Theory;Cuts and Flows},
ps = {http://people.csail.mit.edu/karger/Papers/stcut.ps},
  studentwork = {\asteriskit{\labelwidth} } # " "
}

@article{Karger:Stcut-journal,
  author = 	 benczur # and # karger,
  title = 	 "Approximate $s$--$t$ Min-Cuts in {$\Olog(n^2)$} Time",
  journal=sicomp,
  year = 2011,
cat:multiple =	{Theory;Cuts and Flows},
  studentwork = {\asteriskit{\labelwidth} } # " "
}
@inproceedings{Hariharan:GomoryTree,
 author = {Hariharan, Ramesh and Kavitha, Telikepalli and Panigrahi,
                  Debmalya and Bhalgat, Anand},
 title = {An {O}(mn) Gomory-Hu tree construction algorithm for unweighted graphs},
 booktitle = {STOC '07: Proceedings of the thirty-ninth annual ACM
                  symposium on Theory of computing},
 year = {2007},
 isbn = {978-1-59593-631-8},
 pages = {605--614},
 location = {San Diego, California, USA},
 doi = {http://doi.acm.org/10.1145/1250790.1250879},
 publisher = {ACM},
 address = {New York, NY, USA},
 }
@article{Hariharan:Compression,
  author    = {Ramesh Hariharan and
               Debmalya Panigrahi},
  title     = {A General Framework for Graph Sparsification},
  journal   = {CoRR},
  volume    = {abs/1004.4080},
  year      = {2010},
  ee        = {http://arxiv.org/abs/1004.4080},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{Fung:Compression,
  author    = {Wai Shing Fung and Ramesh Hariharan and Harvey, Nicholas
and                  A. J.  and Debmalya Panigrahi},
  title     = {A General Framework for Graph Sparsification},
  crossref = {stoc11}
}

@article{Karger:Stcut,
  author = 	 benczur # and # karger,
  title = 	 "Approximate $s$--$t$ Min-Cuts in {$\Olog(n^2)$} Time",
  journal=sicomp,
  year = 2011,
cat:multiple =	{Theory;Cuts and Flows},
  studentwork = {\asteriskit{\labelwidth} } # " "
}
@phdthesis{Karger:Thesis,
        author = {David R. Karger},
	title = {Random Sampling in Graph Optimization Problems},
	school = {Stanford University},
	year = {1994},
	address = {Stanford, CA 94305},
        brag = {Winner, ACM Doctoral Dissertation Award, 1995.  To be
                  published by Springer Verlag},
        ps = {http://people.csail.mit.edu/karger/Papers/thesis.ps},
        pdf = {http://people.csail.mit.edu/karger/Papers/thesis.pdf},
cat:multiple =	{Theory;Cuts and Flows},
abstract = {The representative random sample is a central concept of statistics. It is often possible to
gather a great deal of information about a large population by examining a small sample
randomly drawn from it. This approach has obvious advantages in reducing the investiga

tor's work, both in gathering and in analyzing the data.
We apply the concept of a representative sample to combinatorial optimization. Our
general technique is to generate small random representative subproblems and solve them
in lieu of the original ones, producing approximately correct answers which may then be
refined to correct ones at little additional cost. Our focus is optimization problems on
undirected graphs. Highlights of our results include
\begin{itemize}
\item The first (randomized) linear time minimum spanning tree algorithm
\item A (randomized) minimum cut algorithm with running time roughly $O(n^2)$ as compared
to previous roughly $O(n^3)$ time bounds, as well as the first algorithm for finding all
approximately minimal cuts and multiway cuts
\item An efficient parallelization of the minimum cut algorithm, providing the first parallel
(RNC) algorithm for minimum cuts
\item The first proof that minimum cuts can be found deterministically in parallel (NC)
\item  Reliability theorems tightly bounding the connectivities and bandwidths in networks
with random edge failures, and a fully polynomial
time approximation scheme for estimating all-terminal reliability---the probability a particular graph remains connected
under edge failures
\item A linear time algorithm for approximating minimum cuts to within $1+\epsilon$ and a linear
processor parallel algorithm for $1+\epsilon$
approximation, and fast algorithms for approximat
ing $s$-$t$ minimum cuts and maximum Flows}}



@InProceedings{Karger:Turbo,
  author = 	 {Jon Feldman and David R. Karger},
  title = 	 {Decoding Turbo-Like Codes via Linear Programming},
  crossref =  {FOCS02},
  studentwork = student,
  psgz={Papers/LpTurboDecoding.ps.gz},
cat:multiple =	{Theory;Coding;Cuts and Flows},
  pdf={Papers/LpTurboDecoding.pdf},
  doi = {doi.ieeecomputersociety.org/10.1109/SFCS.2002.1181948},
abstract = {We introduce a novel algorithm for decoding turbo-like codes based on linear programming. We prove that for the case of Repeat-Accumulate (RA) codes, under the binary symmetric channel with a certain constant threshold bound on the noise, the error probability of our algorithm is bounded by an inverse polynomial in the code length. Our linear program (LP) minimizes the distance between the received bits and binary variables representing the code bits. Our LP is based on a representation of the code where code words are paths through a graph. Consequently, the LP bears a strong resemblance to the min-cost flow LP. The error bounds are based on an analysis of the probability, over the random noise of the channel, that the optimum solution to the LP is the path corresponding to the original transmitted code word.}
}


@InProceedings{Karger:IterativeDecoding,
  author = 	 {Jon Feldman and David R. Karger and Martin J. Wainwright},
  title = 	 {Linear Programming-Based Decoding of Turbo-Like Codes and its Relation to Iterative Approaches},
  booktitle =	 {Proceedings of the 40th Annual Allerton Conference on Communication, Control, and Computing},
venue={Allerton},
  year =	 2002,
  month =	 oct,
  psgz={Papers/allerton02.ps.gz},
cat:multiple =	{Theory;Coding},
  pdf={allerton02.pdf},
abstract = {In recent work (Feldman and Karger [8]), we introduced a new approach to decoding
turbo-like codes based on linear programming (LP). We gave a precise characterization of
the noise patterns that cause decoding error under the binary symmetric and additive white
Gaussian noise channels. We used this characterization to prove that the word error rate
is bounded by an inverse polynomial in the code length. Furthermore, for any turbo-like
code, our algorithm has the ML certificate property: whenever it outputs a code word, it is
guaranteed to be the maximum-likelihood (ML) code word.
In this paper we extend these results and give an iterative decoder whose output is
equivalent to that of the LP decoder. We also extend the MLcertificate property to the more
efficient iterative tree reweighted max-product message-passing algorithm developed by
Wainwright, Jaakkola, and Willsky [13]: we show that whenever this algorithm converges
to a code word, it must be the ML code word.
Finally, we demonstrate experimentally that the noise patterns that cause decoding
error in the LP decoder also cause decoding error in the standard iterative sum-product and
max-product (min-sum) message-passing algorithms. Consequently, the deterministically
constructible interleaver used by the LP decoder to achieve its bounds on error rate is
useful in practice not only for the LP decoder, but for these standard iterative decoders as
well.}
}

@article{Karger:Turbo-Journal,
  author = 	 {Jon Feldman and David R. Karger},
  title = 	 {Decoding Turbo-Like Codes via Linear Programming},
  journal = JCSS,
  volume = 68,
  number = 4,
  year = 2004,
  pages = {733--752},
  doi = {http://dx.doi.org/10.1016/j.jcss.2003.11.005},
  note = {Special Issue of Best Papers from FOCS 2002.},
cat:multiple =	{Theory;Coding;Cuts and Flows},
pdf = {http://www.columbia.edu/~jf2189/pubs/LpTurboDecoding.pdf},
  studentwork = student,
abstract = {We introduce a novel algorithm for decoding turbo-like codes based on linear programming. We prove that for the case of Repeat-Accumulate (RA) codes, under the binary symmetric channel with a certain constant threshold bound on the noise, the error probability of our algorithm is bounded by an inverse polynomial in the code length. Our linear program (LP) minimizes the distance between the received bits and binary variables representing the code bits. Our LP is based on a representation of the code where code words are paths through a graph. Consequently, the LP bears a strong resemblance to the min-cost flow LP. The error bounds are based on an analysis of the probability, over the random noise of the channel, that the optimum solution to the LP is the path corresponding to the original transmitted code word.}
}


@InProceedings{Karger:LDPC,
  author = 	 {Jon Feldman and David Karger and Martin Wainwright},
  title = 	 {Using Linear Programming to Decode Linear Codes},
  booktitle =	 {37th annual Conference on Information Sciences and Systems (CISS)},
venue={CISS},
  year =	 {2003},
  address =	 {Baltimore, MD},
  month =	 mar,
  studentwork = student,
psgz={Papers/ciss03.ps.gz},
cat:multiple =	{Theory;Coding},
pdf={Papers/ciss03.pdf},
abstract = {Given a linear code and observations
from a noisy channel, the decoding problem is to de-
termine the most likely (ML) codeword. We describe
a method for approximate ML decoding of an arbi-
trary binary linear code, based on a linear program-
ming (LP) relaxation that is defined by a factor graph
or parity check representation of the code. The result-
ing LP decoder, which generalizes our previous work
on turbo-like codes [FK02, FWK02], has the ML cer-
tificate property: it either outputs the ML codeword
with a guarantee of correctness, or acknowledges an
error. We provide a precise characterization of when
the LP decoder succeeds, based on the cost of pseu-
docodewords associated with the factor graph. We in-
troduce the notion of the fractional distance of a
code, defined with respect to a particular LP relax-
ation, and prove that the LP decoder will correct up
to $()$ errors. For the BEC, we prove that the
performance of LP decoding is equivalent to standard
iterative decoding.}
}


@Article{Karger:LDPC-Journal,
  author = 	 {Jon Feldman and David Karger and Martin Wainwright},
  title = 	 {Using Linear Programming to Decode Linear Codes},
  journal = {IEEE Transactions on Information Theory},
  year =	 {2005},
  month = mar,
  volume = 51,
  number = 3,
  pages = {954-972},
url = {http://ieeexplore.ieee.org/iel5/18/30405/01397933.pdf?isNumber=30405&prod=JNL&arnumber=1397933&arSt=+954&ared=+972&arauthor=+Feldman%2C+J.%3B++Wainwright%2C+M.J.%3B++Karger%2C+D.R.},
cat:multiple =	{Theory;Coding},
  studentwork = student,
abstract = {Abstract: A new method is given for performing approximate
maximum-likelihood (ML) decoding of an arbitrary binary linear
code based on observations received from any discrete memoryless
symmetric channel. The decoding algorithm is based on a linear
programming (LP) relaxation that is defined by a factor graph
or parity-check representation of the code. The resulting \emph{LP decoder} generalizes our previous work on turbo-like codes.
A precise combinatorial characterization of when the LP decoder
succeeds is provided, based on pseudocodewords associated
with the factor graph. Our definition of a pseudocodeword unifies
other such notions known for iterative algorithms, including \emph{stopping
sets,} \emph{irreducible closed walks,} \emph{trellis cycles,} \emph{deviation
sets,} and \emph{graph covers.}
The fractional distance frac of a code is introduced, which is a
lower bound on the classical distance. It is shown that the efficient
LP decoder will correct up to frac 2 1 errors and that there
are codes with frac =
( 1 ). An efficient algorithm to compute
the fractional distance is presented. Experimental evidence
shows a similar performance on low-density parity-check (LDPC)
codes between LP decoding and the min-sum and sum-product algorithms.
Methods for tightening the LP relaxation to improve performance
are also provided.
Index Terms: Belief propagation (BP), iterative decoding, low density
parity-check (LDPC) codes, linear codes, linear programming
(LP), LP decoding, minimum distance, pseudocodewords.}
}


@InProceedings{Karger:LPDecoding,
  author = 	 {Jon Feldman and David R. Karger and Martin J. Wainwright},
  title = 	 {LP Decoding},
venue={Allerton},
  booktitle =	 {Proceedings of the 41st Annual Allerton Conference on Communication, Control, and Computing},
  year =	 2003,
  month =	 oct,
  psgz={Papers/allerton03.ps.gz},
  pdf={Papers/allerton03.pdf},
cat:multiple =	{Theory;Coding},
abstract = {Linear programming (LP) relaxation is a common technique used to find good solutions to
complex optimization problems. We present the method of ``LP decoding'': applying LP relaxation to
the problem of maximum-likelihood (ML) decoding. An arbitrary binary-input memoryless channel is
considered. This treatment of the LP decoding method places our previous work on turbo codes [6] and
low-density parity-check (LDPC) codes [8] into a generic framework. We define the notion of a proper
relaxation, and show that any LP decoder that uses a proper relaxation exhibits many useful properties.
We describe the notion of pseudocodewords under LP decoding, unifying many known characterizations
for specific codes and channels. The fractional distance of an LP decoder is defined, and it is shown
that LP decoders correct a number of errors equal to half the fractional distance. We also discuss the
application of LP decoding to binary linear codes. We define the notion of a relaxation being symmetric
for a binary linear code. We show that if a relaxation is symmetric, one may assume that the all-zeros codeword is transmitted.}
}


@article{Karger:VLSI,
	author = {C. J. Alpert and T. C. Hu and J. H. Huang and A. B.
Kahng and David Karger},
	title = {Prim-{D}ijkstra Tradeoffs for Improved
Performance-Driven Routing Tree Design},
	journal = {IEEE Transactions on Computer Aided Design},
	month = jul,
	year = 1995,
	volume = 14,
	number = 7,
cat = {Applications of Theory},
	pages = {890--895},
abstract = {Analysis of Elmore delay in distributed RC tree structures shows the
influence of both tree cost
and tree radius on signal delay in VLSI interconnects. We give new
and efficient interconnection
tree constructions that smoothly combine the minimum cost and the
minimum radius objectives,
by combining respectively optimal algorithms due to Prim and
Dijkstra. Previous "shallow-light"
techniques [2, 3, 8, 13] are both less direct and less effective: in
practice, our methods achieve
uniformly superior cost-radius tradeoffs. Detailed timing simulations for a range of IC and MCM
interconnect technologies show that our wirelength savings yield
reduced signal delays when
compared to shallow-light or standard minimum spanning tree and
Steiner tree routing.}}

@InProceedings{Karger:Web,
  author = 	 {David R. Karger and Eric Lehman and Tom Leighton and
                  Matthew Levine and Daniel Lewin and Rina Panigrahy },
  title = 	 {Consistent Hashing and Random Trees: Distributed
                  Caching protocols for Relieving Hot Spots on the
                  World Wide Web},
  crossref =	 {STOC97},
  ps = {http://people.csail.mit.edu/karger/Papers/web.ps},
  pages =	 {654--663},
abstract = {We describe a family of caching protocols for distrib-uted networks
that can be used to decrease or eliminate the occurrence of hot spots
in the network. Our protocols are particularly designed for use with
very large networks such as the Internet, where delays caused by
hot spots can be severe, and where it is not feasible for every server
to have complete information about the current state of the entire
network. The protocols are easy to implement using existing network
protocols such as TCP/IP, and require very little overhead.
The protocols work with local control, make efficient use of existing
resources, and scale gracefully as the network grows.
Our caching protocols are based on a special kind of hashing
that we call consistent hashing. Roughly speaking, a consistent
hash function is one which changes minimally as the range of the
function changes. Through the development of good consistent
hash functions, we are able to develop caching protocols which do
not require users to have a current or even consistent view of the
network. We believe that consistent hash functions may eventually
prove to be useful in other applications such as distributed name
servers and/or quorum systems.},
cat:multiple =	{Theory;Applications of Theory},
  studentwork = {\asteriskit{\labelwidth} } # " "
}

@inproceedings{Karger:Cactus,
 author = {Karger, David R. and Panigrahi, Debmalya},
 title = {A near-linear time algorithm for constructing a cactus representation of minimum cuts},
 booktitle = {SODA '09: Proceedings of the Nineteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
 year = {2009},
 cat:multiple ={Theory;Cuts and Flows},
 month=jan,
 venue = {SODA},
 pages = {246--255},
 location = {New York, New York},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 pdf={SODA09-cactus.pdf}
 }

@inproceedings{Panigrahy:GomoryTree,
 author = {Hariharan, Ramesh and Kavitha, Telikepalli and Panigrahi,
                  Debmalya and Bhalgat, Anand},
 title = {An {O}(mn) Gomory-Hu tree construction algorithm for unweighted graphs},
 pages = {605--614},
 crossref={STOC07}
 }

@Article{Karger:CACM-Data,
  author = 	 {David R. Karger and William Jones},
  title = 	 {Data Unification in Personal Information Management},
  journal = 	 {Communications of the ACM},
  year = 	 2006,
  month =	 jan,
  volume = 49,
  number = 1,
  pages = {77-82},
  doi = {http://doi.acm.org/10.1145/1107458.1107496},
  cat = {Information Retrieval},
abstract = {Users need ways to unify, simplify, and consolidate information too often fragmented by location, device, and software application.}
}

@article{Ho:RandomLinearCoding,
  author = {Tracey Ho and Muriel M\'{e}dard and Ralf Koetter and David
                  R. Karger and Michelle Effros and  J. Shi and
                  B. Leong},
  title = {A Random Linear Network Coding Approach to Multicast},
  journal ={ IEEE Transactions on Information Theory},
  volume = 52,
  number = 10,
  pages ={ 4413-4430},
  year=2006,
cat:multiple =	{Theory;Coding;Cuts and Flows},
  pdf = {http://www.its.caltech.edu/~tho/itrandom-final.pdf},
abstract = {We present a distributed random linear network
coding approach for transmission and compression of information
in general multisource multicast networks. Network nodes
independently and randomly select linear mappings from inputs
onto output links over some field. We show that this achieves capacity
with probability exponentially approaching 1 with the code
length. We also demonstrate that random linear coding performs
compression when necessary in a network, generalizing error exponents
for linear Slepian-Wolf coding in a natural way. Benefits
of this approach are decentralized operation and robustness to
network changes or link failures. We show that this approach
can take advantage of redundant network capacity for improved
success probability and robustness. We illustrate some potential
advantages of random linear network coding over routing in two
examples of practical scenarios: distributed network operation
and networks with dynamically varying connections. Our derivation
of these results also yields a new bound on required field size
for centralized network coding on general multicast networks.}
}

@inproceedings{Ho:Byzantine,
author = {Tracey Ho and B. Leong and Ralf Koetter and Muriel M\'{e}dard and Michelle Effros and David R. Karger},
title={Byzantine Modification Detection in Multicast Networks Using Randomized Network Coding},
booktitle = {International Symposium on Information Theory (ISIT)},
venue = {ISIT},
year = 2004,
cat:multiple =	{Theory;Coding},
pdf = {http://www.its.caltech.edu/~tho/isit04.ps},
abstract = {Distributed randomized network coding, a robust approach to multicasting in distributed network settings, can be extended to provide Byzantine modification detection without the use of cryptographic functions is presented in this paper.}
}

@article{Karger:MinCostMulticast,
  author = {Desmond S. Lun and Niranjan Ratnakar and Muriel M\'{e}dard
                  and Ralf Koetter and David R. Karger and Tracey Ho
                  and Ebad Ahmed and Fang Zhao},
  title = {Minimum-cost multicast over coded packet networks},
cat:multiple =	{Theory;Coding;Cuts and Flows},
  journal ={IEEE Transactions on Information Theory},
  volume = 52,
  number = 6,
  pages ={2608-2623},
  year=2006,
abstract = {We consider the problem of establishing minimum-cost multicast connections over coded packet networks, i.e. packet networks where the contents of outgoing packets are arbitrary, causal functions of the contents of received packets. We consider both wireline and wireless packet networks as well as both static multicast (where membership of the multicast group remains constant for the duration of the connection) and dynamic multicast (where membership of the multicast group changes in time, with nodes joining and leaving the group).
For static multicast, we reduce the problem to a polynomial-time solvable optimization problem, and we present decentralized algorithms for solving it. These algorithms, when coupled with existing decentralized schemes for constructing network codes, yield a fully decentralized approach for achieving minimum-cost multicast. By contrast, establishing minimum-cost static multicast connections over routed packet networks is a very difficult problem even using centralized computation, except in the special cases of unicast and broadcast connections.
For dynamic multicast, we reduce the problem to a dynamic programming problem and apply the theory of dynamic programming to suggest how it may be solved.}
}

@inproceedings{Karger:NCoding1,
  author = {Tracey Ho and Muriel M\'{e}dard and J. Shi and Michelle Effros
                  and David R. Karger},
  title = {On Randomized Network Coding},
  booktitle = {$41^{st}$ Allerton Annual Conference on Communication,
                  Control, and Signal Processing},
pdf={http://www.its.caltech.edu/~tho/allerton.pdf},
venue={Allerton},
  year = {2003},
month=oct,
cat:multiple =	{Theory;Applications of Theory;Coding;Cuts and Flows},
  note = {Invited paper},
abstract = {We consider a randomized network coding approach for multicasting
from several

sources over a network, in which nodes independently and randomly
select

linear mappings from inputs onto output links over some field. This
approach was


first described in [3], which gave, for acyclic delay-free networks,
a bound on error

probability, in terms of the number of receivers and random coding
output links, that decreases exponentially with code length. The proof was based on
a result

in [2] relating algebraic network coding to network flows. In this
paper, we generalize

these results to networks with cycles and delay. We also show, for
any given

acyclic network, a tighter bound in terms of the probability of
connection feasibility

in a related network problem with unreliable links. From this we
obtain a success

probability bound for randomized network coding in link-redundant
networks with

unreliable links, in terms of link failure probability and amount of
redundancy.},

}

@inproceedings{Karger:NonMulticast,
author = {Muriel M\'{e}dard and Michelle Effros and Tracey Ho and David Karger},
title = {On Coding for Non-Multicast Networks},
  booktitle = {$41^{st}$ Allerton Annual Conference on Communication,
                  Control, and Signal Processing},
venue={Allerton},
  year = {2003},
cat:multiple =	{Theory;Applications of Theory;Coding;Cuts and Flows},
  note = {Invited paper},
pdf = {http://www.its.caltech.edu/~tho/allertonM03.pdf},
abstract = {We consider the issue of coding for non-multicast networks. For multicast networks,
it is known that linear operations over a field no larger than the number
of receivers are sufficient to achieve all feasible connections. In the case of nonmulticast
networks, necessary and sufficient conditions are known, if we restrict
ourselves to linear codes over a finite field [1]. However, no linearity sufficiency
results exist for non-multicast networks. Indeed, [2] shows that linearity over a
field is not sufficient in general. We present a coding theorem that provides necessary
and sufficient conditions, in terms of receiver entropies, for an arbitrary set
of connections to be achievable on any network. We conjecture that linearity is
sufficient to satisfy the coding theorem, when linear operations are performed over
vectors rather than scalars in a field. We illustrate the intuition of this conjecture
with an example. This work is part of an ongoing cooperation with R. Koetter.}
}

@InProceedings{Karger:NetworkCoding2,
  author = 	 {Tracey Ho and Ralf Koetter and  Muriel M\'{e}dard and
                  David R. Karger and Michelle Effros},
  title = 	 {The Benefits of Network Coding over Routing in a
                  Randomized Setting},
  crossref =  {isit03},
cat:multiple =	{Theory;Applications of Theory;Coding;Cuts and Flows},
pdf = {http://www.its.caltech.edu/~tho/isit03-1.pdf},
  studentwork = student,
abstract = {We present a novel randomized network
coding approach for robust, distributed transmission
and compression of information in networks,
and demonstrate its advantages over routing-based
approaches.}
}

@inproceedings{Karger:NCoding4,
author = {Michelle Effros and Muriel M\'{e}dard and Tracey Ho and S. Ray and David Karger and Ralf Koetter and B. Hassibi},
title = {Linear Network Codes: A Unified Framework for Source, Channel, and Network Coding},
note={Invited Paper},
booktitle={DIMACS workshop on network information theory},
venue = {DIMACS},
pdf = {http://www.its.caltech.edu/~tho/dimacs03.pdf},
cat:multiple =	{Theory;Coding;Cuts and Flows},
year=2003,
abstract = {We examine the issue of separation and code design for network
data transmission environments. We demonstrate that source-channel sep-
aration holds for several canonical network channel models when the whole
network operates over a common nite eld. Our approach uses linear codes.
This simple, unifying framework allows us to re-establish with economy the
optimality of linear codes for single transmitter channels and for Slepian-Wolf
source coding. It also enables us to establish the optimality of linear codes
for multiple access channels and for erasure broadcast channels. Moreover, we
show that source-channel separation holds for these networks. This robustness
of separation we show to be strongly predicated on the fact that noise and
inputs are independent. The linearity of source, channel, and network coding
blurs the delineation between these codes, and thus we explore joint linear de-
sign. Finally, we illustrate the fact that design for individual network modules
may yield poor results when such modules are concatenated, demonstrating
that end-to-end coding is necessary. Thus, we argue, it is the lack of decom-
posability into canonical network modules, rather than the lack of separation
between source and channel coding, that presents major challenges for coding
in networks.}
}

@InProceedings{KLO,
  author = 	 {Kuhn, Fabian and Lynch, Nancy and Oshman, Rotem},
  title = 	 {Distributed Computation in Dynamic Networks},
  booktitle = {Proc.\ of the 42nd Annual
                  ACM Symposium on Theory of Computing (STOC)},
  pages =	 {557--570},
  year =	 2010
}

@inproceedings{Karger:NCoding3,
note={see Ho:RandomLinearCoding}
}

@inproceedings{Karger:AdversarialNetworks,
author={Bernhard Haeupler},
title={Analyzing Network Coding Gossip Made Easy (simpler proofs for
                  stronger results even in adversarial dynamic
                  networks)},

 cat:multiple={Theory},

booktitle={Forty-Eighth Annual Allerton Conference on Communication,
                  Control, and Computing},
year={2010}
}

@InProceedings{Karger:NetworkCoding,
  author = 	 {Tracey Ho and David R. Karger and Muriel M\'{e}dard and
                  Ralf Koetter},
  title = 	 {Network Coding from a Network Flow Perspective},
cat:multiple =	{Theory;Applications of Theory;Coding;Cuts and Flows},
  crossref =  {isit03},
pdf = {http://www.its.caltech.edu/~tho/isit03-2.pdf},
  studentwork = student,
abstract = {We make precise connections between
algebraic network coding and network flows. Our
combinatorial formulations offer new insights, mathe-
matical simplicity, and lead to a substantially tighter
upper bound on the coding field size required for a
given connection problem than that in [5].}
}

@InProceedings{Karger:UIContinuations,
  author = 	 {Dennis Quan and David Huynh and David R. Karger and
                  Robert Miller},
  title = 	 {User Interface Continuations},
  crossref =	 {uist03},
	conferenceURL = "http://www.uist.org/",
  cat:multiple =	{Information Retrieval;Haystack;Semantic Web;CHI},
	pdfurl = "http://haystack.csail.mit.edu/papers/uist2003-uicont.pdf",
	pdfkb = "111",
  pdf = hayweb # {uist2003-uicont.pdf},
abstract = {Dialog boxes that collect parameters for commands often
create ephemeral, unnatural interruptions of a program's
normal execution flow, encouraging the user to complete the
dialog box as quickly as possible in order for the program to
process that command. In this paper we examine the idea of
turning the act of collecting parameters from a user into a
first class object called a user interface continuation. Programs
can create user interface continuations by specifying
what information is to be collected from the user and supplying
a callback (i.e., a continuation) to be notified with the
collected information. A partially completed user interface
continuation can be saved as a new command, much as
currying and partially evaluating a function with a set of
parameters produces a new function. Furthermore, user
interface continuations, like other continuation-passing
paradigms, can be used to allow program execution to continue
uninterrupted while the user determines a command's
parameters at his or her leisure.}
}

@InProceedings{Karger:UIContinuation,
note={see karger:UIContinuations}
}

@InProceedings{Karger:HaystackDemo,
  author = 	 {Dennis Quan and David R. Karger},
  title = 	 {Haystack: A User Interface for Creating, Browsing
                  and Organizing Arbitrary Semistructured Information},
  booktitle =	 {Proceedings of the ACM CHI Conference on Human Factors in Computing Systems},
  venue = {CHI},
  year =	 2004,
month=apr,
  cat:multiple =	{CHI;Information Retrieval;Haystack;Semantic Web},
doi = {http://doi.acm.org/10.1145/985921.985931},
note = {Demo},
abstract = { Much past HCI research has examined the usability concerns of information management software for specific domains such as object-oriented software design, e-mail, and the Web. We believe that many of the results uncovered by these studies are applicable across multiple domains but that more broadly-scoped experiments require a system that can integrate multiple data sources. Haystack is a general-purpose information management environment designed to attack this very problem. Haystack's user interface, which incorporates capabilities from previous research such as context-specific visualization paradigms and attribute-based categorization, is built upon a highly expressive semistructured data model and data integration capabilities. In our demonstration we show how combination of a direct-manipulation-based UI paradigm and an expressive, federated data model can begin to address many of the information management problems plaguing general desktop computing today and can serve as a basis for further, yet unexplored, crossover information interaction experiments.
}
}


@inproceedings{Karger:Magnet,
 author = {Vineet Sinha and David R. Karger},
 title = {Magnet: supporting navigation in semistructured data environments},
 booktitle = {SIGMOD '05: Proceedings of the 2005 ACM SIGMOD international conference on Management of data},
venue={SIGMOD},
 year = {2005},
month=jun,
 isbn = {1-59593-060-4},
 pages = {97--106},
 location = {Baltimore, Maryland},
 doi = {http://doi.acm.org/10.1145/1066157.1066169},
 pdf = {http://haystack.lcs.mit.edu/papers/magnet-sigmod2005.pdf},
 publisher = {ACM Press},
 address = {New York, NY, USA},
cat:multiple =	{Semantic Web;Information Retrieval},
abstract = {With the growing importance of systems containing arbitrary semistructured
relationships, the need for supporting users searching in
such repositories has grown. Currently support for users' search
needs either has required domain-specific user interfaces or has required
users to be schema experts. We have developed a generalpurpose
tool that offers users helpful navigation and refinement options
for seeking information in these semistructured repositories.
We show how a tool can be built without requiring domain-specific
assumptions about the information being explored. In addition to
describing a general approach to the problem, we provide a set of
natural, general-purpose refinement tactics, many generalized from
past work on textual information retrieval.}
 }

@InProceedings{Karger:Spam,
  author = 	 {Hari Balakrishnan and David R. Karger},
  title = 	 {{Spam-I-am}: A Proposal for Spam Control Using
                  Distributed Quota Management},
  booktitle =	 {Proceedings of the Third Annual ACM SIGCOMM Workshop on Hot Topics in
                  Networking ({HotNets-III})},
  pdf = {http://ramp.ucsd.edu/conferences/HotNets-III/HotNets-III%20Proceedings/spamiam.pdf},
venue={HotNets},
   month =        {November},
   address =      {San Diego, CA},
  year =	 2004,
cat:multiple =	{Systems;P2P},
  editor =	 {Alex Snoeren},
abstract = {Email spam has reached alarming proportions because it
costs virtually nothing to send email; even a small number
of people responding to a spam message is adequate
incentive for a spammer to send as many messages as possible.
Since spammers need to send messages at high rates
to as many recipients as they can, quotas on email senders
could throttle spam. We argue for separating the allocation
of quotas, a relatively rare activity, from the enforcement
of quotas, a frequent activity that must scale to the billions
of messages sent daily.
This paper tackles the quota enforcement problem,
where the goal is to ensure that no sender can grossly
violate its quota. The challenge is to design an enforcement
scheme that is scalable, is robust against malicious
attackers or participants, and preserves the privacy of communication,
in a large, distributed, and untrusted environment.
We discuss the design of such a system, Spam-Iam,
based on a managed distributed hash table (DHT) interface,
showing that it can be used in conjunction with
electronic stamps (for quota allocation) to ensure that any
non-negligible reuse of stamps will be detected.}
}

@inproceedings{Karger:DQE,
  author = {Michael Walfish and J. D. Zamfirescu and Hari Balakrishnan
                  and David R. Karger and Scott Shenker},
  title = {Distributed Quota Enforcement for Spam Control},
  booktitle = {NSDI: Networking Systems Design and Implementation},
venue={NSDI},
  pdf = {http://nms.csail.mit.edu/papers/dqe-nsdi06.pdf},
cat:multiple =	{Systems;P2P},
  year = 2006,
  month = may,
abstract = {Spam, by overwhelming inboxes, has made email a less
reliable medium than it was just a few years ago. Spam
filters are undeniably useful but unfortunately can flag
non-spam as spam. To restore email's reliability, a recent
spam control approach grants quotas of stamps to
senders and has the receiver communicate with a wellknown
quota enforcer to verify that the stamp on the
email is fresh and to cancel the stamp to prevent reuse.
The literature has several proposals based on this general
idea but no complete system design and implementation
that: scales to today's email load (which requires the enforcer
to be distributed over many hosts and to tolerate
faults in them), imposes minimal trust assumptions, resists
attack, and upholds today's email privacy. This paper
describes the design, implementation, analysis, and
experimental evaluation of DQE, a spam control system
that meets these challenges. DQE's enforcer occupies a
point in the design spectrum notable for simplicity: mutually
untrusting nodes implement a storage abstraction
but avoid neighbor maintenance, replica maintenance,
and heavyweight cryptography.}
}

@inproceedings:{Karger:Fightfire-SIGCOMM,
  author = {Michael Walfish and Mythili Vutukuru and Hari Balakrishnan
                  and David R. Karger and Scott Shenker},
  title = {DDoS defense by offense},
  booktitle = {SIGCOMM 2006},
venue={SIGCOMM},
cat:multiple =	{Systems;P2P},
  pdf = {http://nms.csail.mit.edu/papers/ddos-offense-sigcomm06.pdf},
  pages ={303-314},
abstract = {This paper presents the design, implementation, analysis, and experimental
evaluation of speak-up, a defense against applicationlevel
distributed denial-of-service (DDoS), in which attackers cripple
a server by sending legitimate-looking requests that consume
computational resources (e.g., CPU cycles, disk). With speak-up,
a victimized server encourages all clients, resources permitting, to
automatically send higher volumes of trafc. We suppose that attackers
are already using most of their upload bandwidth so cannot
react to the encouragement. Good clients, however, have spare upload
bandwidth and will react to the encouragement with drastically
higher volumes of trafc. The intended outcome of this trafc ination
is that the good clients crowd out the bad ones, thereby capturing
a much larger fraction of the server's resources than before. We
experiment under various conditions and nd that speak-up causes
the server to spend resources on a group of clients in rough proportion
to their aggregate upload bandwidth. This result makes the
defense viable and effective for a class of real attacks.}
}

@inproceedings{Karger:LessIsMore,
  author = {Harr Chen and David R. Karger},
  title ={Less is more: probabilistic models for retrieving fewer
                  relevant documents},
  pdf = {http://www.csail.mit.edu/~harr/papers/sigir2006.pdf},
  confurl = {http://www.sigir.org/sigir2006/},
cat = {Information Retrieval},
  crossref = {sigir06},
  pages = {429-436},
abstract = {Traditionally, information retrieval systems aim to maximize the
number of relevant documents returned to a user within some window
of the top. For that goal, the probability ranking principle,
which ranks documents in decreasing order of probability of relevance,
is provably optimal. However, there are many scenarios
in which that ranking does not optimize for the user's information
need. One example is when the user would be satisfied with some
limited number of relevant documents, rather than needing all relevant
documents. We show that in such a scenario, an attempt to
return many relevant documents can actually reduce the chances of
finding any relevant documents.
We consider a number of information retrieval metrics from the
literature, including the rank of the first relevant result, the %no
metric that penalizes a system only for retrieving no relevant results
near the top, and the diversity of retrieved results when queries
have multiple interpretations. We observe that given a probabilistic
model of relevance, it is appropriate to rank so as to directly optimize
these metrics in expectation. While doing so may be computationally
intractable, we show that a simple greedy optimization
algorithm that approximately optimizes the given objectives
produces rankings for TREC queries that outperform the standard
approach based on the probability ranking principle.}
}

@inproceedings{karger:Haystack-CIDR,
	title = "Haystack: A General Purpose Information Management Tool for End Users of Semistructured Data",
	year = "2005",
        booktitle =    {Conference on Innovative Database Research (CIDR)},
        pages = {13--26},
	venue = "CIDR",
month=jan,
	work-done-at = "MIT CSAIL",
	confurl = "http://www-db.cs.wisc.edu/cidr/cidr2005/",
	pdf = "http://www-db.cs.wisc.edu/cidr/cidr2005/papers/P02.pdf",
	author = "David R. Karger and Karun Bakshi and David Huynh and Dennis Quan and Vineet Sinha",
	abstract = "We posit that a semistructured data model offers the right balance of rich structure and flexible (or lack of) schema allowing naive end users to record information in whatever form makes it easy for them to manage. We describe our Haystack system, which exposes the richness and flexibility of the data model while offering the user natural, traditional interfaces that shield them from the specifics of schemas, tuples, and database queries. We outline research challenges that remain to be addressed.",
cat:multiple =	{Haystack;Information Retrieval},
}

@techreport{ shih2001,
author = "Lawrence Shih and David Karger",
title = "Learning Classes Correlated to a Hierarchy",
institution = "MIT AI Lab",
year = 2001,
cat:multiple =	{Information Retrieval;Machine Learning},
abstract = {Trees are a common way of organizing large amounts of information
by placing items with similar characteristics near one another
in the tree. We introduce a classification problem where a given tree
structure gives us information on the best way to label nearby elements.
We suggest there are many practical problems that fall under
this domain. We propose a way to map the classification problem
onto a standard Bayesian inference problem. We also give a
fast, specialized inference algorithm that incrementally updates relevant
probabilities. We apply this algorithm to web-classification
problems and show that our algorithm empirically works well.}
}

@unpublished{Karger97,
 author = "David Karger and Lynn Stein",
 title = "Haystack: Per-User Information Environments.",
cat:multiple =	{Information Retrieval;Haystack},
 year = 1997}

@inproceedings{ScatterGatherClusterHypothesis,
 author = {Marti A. Hearst and Jan O. Pedersen},
 title = {Reexamining the cluster hypothesis: scatter/gather on retrieval results},
 booktitle = {Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval},
venue={SIGIR},
 year = {1996},
 isbn = {0-89791-792-8},
 pages = {76--84},
 location = {Zurich, Switzerland},
 doi = {http://doi.acm.org/10.1145/243199.243216},
 publisher = {ACM Press},
cat = {Information Retrieval},
 }

@InProceedings{Karger:Fresnel-ISWC06,
  author = 	 {Emmanuel Pietriga and Chris Bizer and David Karger
                  and Ryan Lee},
  title = 	 {Fresnel: A Browser-Independent Presentation
                  Vocabulary for RDF},
  pages =	 {158--171},
  pdf   =        {Papers/fresnel.pdf},
  slides   =        {Papers/fresnel-talk.pdf},
cat:multiple =	{Information Retrieval;Haystack;Semantic Web},
  crossref={iswc06},
 location = {Athens, GA},
doi = {10.1007/11926078_12},
abstract = {Semantic Web browsers and other tools aimed at displaying RDF data to end users are all concerned with the same problem: presenting content primarily intended for machine consumption in a human-readable way. Their solutions differ but in the end address the same two high-level issues, no matter the underlying representation paradigm: specifying (i) what information contained in RDF models should be presented (content selection) and (ii) how this information should be presented (content formatting and styling). However, each tool currently relies on its own ad hoc mechanisms and vocabulary for specifying RDF presentation knowledge, making it difficult to share and reuse such knowledge across applications. Recognizing the general need for presenting RDF content to users and wanting to promote the exchange of presentation knowledge, we designed Fresnel as a browser-independent vocabulary of core RDF display concepts. In this paper we describe Fresnel's main concepts and present several RDF browsers and visualization tools that have adopted the vocabulary so far.}
}



@inproceedings{Karger:Piggy,
author = {David Huynh and Stefano Mazzochi and David Karger},
title = {Piggy Bank: Experience the Semantic Web Inside your Web
                  Browser},
booktitle = {International Semantic Web Conference (ISWC)},
	venue = "ISWC",
year = 2005,
month=nov,
	pdf = "http://simile.mit.edu/papers/iswc05.pdf",
	pdfkb = "2400",
	abstract = "<p>The Semantic Web Initiative envisions a Web wherein information is offered free of presentation, allowing more effective exchange and mixing across web sites and across web pages. But without substantial Semantic Web content, few tools will be written to consume it; without many such tools, there is little appeal to publish Semantic Web content.</p><p>To break this chicken-and-egg problem, thus enabling more flexible information access, we have created a web browser extension called Piggy Bank that lets users make use of Semantic Web content within Web content as users browse the Web. Wherever Semantic Web content is not available, Piggy Bank can invoke screenscrapers to re-structure information within web pages into Semantic Web format. Through the use of Semantic Web technologies, Piggy Bank provides direct, immediate benefits to users in their use of the existing Web. Thus, the existence of even just a few Semantic Web-enabled sites or a few scrapers already benefits users. Piggy Bank thereby offers an easy, incremental upgrade path to users without requiring a wholesale adoption of the Semantic Web's vision.</p><p>To further improve this Semantic Web experience, we have created Semantic Bank, a web server application that lets Piggy Bank users share the Semantic Web information they have collected, enabling collaborative efforts to build sophisticated Semantic Web information repositories through simple, everyday's use of Piggy Bank.</p>",
cat:multiple =	{Haystack;Semantic Web;Information Retrieval},
}


@article{Karger:Piggy-Journal,
author = {David Huynh and Stefano Mazzochi and David Karger},
title = {Piggy Bank: Experience the Semantic Web Inside your Web
                  Browser},
journal = {Journal of Web Semantics},
volume = 5,
number = 1,
pages = {16-27},
year = 2007,
	pdf = "http://simile.mit.edu/papers/iswc05.pdf",
	pdfkb = "2400",
	abstract = "<p>The Semantic Web Initiative envisions a Web wherein information is offered free of presentation, allowing more effective exchange and mixing across web sites and across web pages. But without substantial Semantic Web content, few tools will be written to consume it; without many such tools, there is little appeal to publish Semantic Web content.</p><p>To break this chicken-and-egg problem, thus enabling more flexible information access, we have created a web browser extension called Piggy Bank that lets users make use of Semantic Web content within Web content as users browse the Web. Wherever Semantic Web content is not available, Piggy Bank can invoke screenscrapers to re-structure information within web pages into Semantic Web format. Through the use of Semantic Web technologies, Piggy Bank provides direct, immediate benefits to users in their use of the existing Web. Thus, the existence of even just a few Semantic Web-enabled sites or a few scrapers already benefits users. Piggy Bank thereby offers an easy, incremental upgrade path to users without requiring a wholesale adoption of the Semantic Web's vision.</p><p>To further improve this Semantic Web experience, we have created Semantic Bank, a web server application that lets Piggy Bank users share the Semantic Web information they have collected, enabling collaborative efforts to build sophisticated Semantic Web information repositories through simple, everyday's use of Piggy Bank.</p>",
cat:multiple =	{Haystack;Semantic Web;Information Retrieval},
}

@inproceedings{Christiano:Flow,
 author = {Christiano, Paul and Kelner, Jonathan A. and Madry,
                  Aleksander and Spielman, Daniel A. and Teng,
                  Shang-Hua},
 title = {Electrical flows, laplacian systems, and faster
                  approximation of maximum flow in undirected graphs},
 crossref={stoc11},
 pages = {273--282},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1993636.1993674},
 doi = {http://doi.acm.org/10.1145/1993636.1993674},
 keywords = {electrical flows, laplacian linear systems, maximum
                  flows, minimum cuts, multiplicative weights update
                  method},
}


@inproceedings{Karger:Orienteering,
 author = {Jaime Teevan and Christine Alvarado and Mark S. Ackerman and David R. Karger},
 title = {The Perfect Search Engine is not Enough: a Study of Orienteering Behavior in Directed Search},
 booktitle = {CHI '04: Proceedings of the SIGCHI conference on Human factors in computing systems},
venue = {CHI},
 year = {2004},
 isbn = {1-58113-702-8},
 pages = {415--422},
 location = {Vienna, Austria},
 doi = {http://doi.acm.org/10.1145/985692.985745},
pdf={http://people.csail.mit.edu/teevan/work/publications/papers/chi04.pdf},
 publisher = {ACM Press},
cat:multiple =	{Information Retrieval;CHI}, abstract = { This paper presents a modified diary study that investigated how people performed personally motivated searches in their email, in their files, and on the Web. Although earlier studies of directed search focused on keyword search, most of the search behavior we observed did not involve keyword search. Instead of jumping directly to their information target using keywords, our participants navigated to their target with small, local steps using their contextual knowledge as a guide, even when they knew exactly what they were looking for in advance. This stepping behavior was especially common for participants with unstructured information organization. The observed advantages of searching by taking small steps include that it allowed users to specify less of their information need and provided a context in which to understand their results. We discuss the implications of such advantages for the design of personal information management tools.
}
}

@inproceedings{Quan,
author="Dennis Quan and David F. Huynh and Vineet Sinha and Marina Zhurakhinskaya and David Karger",
title="Basic Concepts for Managing Semi-structured Information in Haystack",
year="2002",
cat:multiple={Haystack;Semantic Web},
booktitle="2nd Annual Student Oxygen Workshop, Gloucester, MA, USA",
venue = {Oxygen}
}

@unpublished{Karger:JournalDone,
        note = "{\bf Finished Journals}"
}

@unpublished{Karger:JournalAppear,
        note = "{\bf Journals to appear}"
}

@unpublished{Karger:ConfDone,
        note = "{\bf Conference Proceedings}"
}

@unpublished{Karger:ConfAppear,
        note = "{\bf Conf To appear}"
}


@phdthesis{Lewin:Thesis,
  author = {Daniel Lewin},
  title = {Consistent Hashing and Random Trees: Algorithms for Caching
                  in Distributed Networks},
  year = {1998},
  school = {MIT},
  note = {Available at the MIT Library, {\tt http://thesis.mit.edu}}
  }

@InProceedings{Karloff:3SAT,
  author = 	 {Howard Karloff and Uri Zwick},
  title = 	 {A $7/8 -\epsilon$ approximation for MAX-3SAT?},
  crossref =	 {FOCS97}
}

@mastersthesis{Bakshi:Thesis,
title = "Tools for End-User Creation and Customization of Interfaces for
Information Management Tasks",
author = "Karun Bakshi",
year = "2004",
month = "June",
school = "Massachusetts Institute of Technology",
abstract = "In this thesis, we advocate breaking the rigidity of
applications by allowing users to create and customize their own
task-oriented interfaces that aggregate and present task-specific
information and tools on the same screen."
 }

@inproceedings{Jerrum:Ising,
    author = "Mark Jerrum and Alistair Sinclair",
    title = "Polynomial-Time Approximation Algorithms for Ising Model (Extended Abstract)",
    booktitle = "Automata, Languages and Programming",
    pages = "462-475",
    year = "1990",
    url = "citeseer.ist.psu.edu/jerrum93polynomialtime.html" }

@Article{Jain:NetworkDesign,
  author = 	 {Kamal Jain},
  title = 	 {A factor 2 approximation algorithm for the generalized Steiner network problem},
  journal = 	 {Combinatorica},
  year = 	 2001,
  volume =	 21,
  number =	 1,
  pages =	 {39--60}
}

@InProceedings{Aingworth:Diameter,
  author =       "Donald Aingworth and Chandra Chekuri and Rajeev Motwani",
  title =        "Fast Estimation of Diameter and Shortest Paths
                 (without Matrix Multiplication)",
  pages =        "547--553",
  ISBN =         "0-89871-366-8",
  booktitle =    "Proceedings of the Seventh Annual {ACM}-{SIAM}
                 Symposium on Discrete Algorithms",
  month =        jan # "~28--30",
  publisher =    "ACM/SIAM",
  address =      "New York/Philadelphia",
  year =         "1996",
}

@Article{Akra:Recurrence,
  author = 	 {M. A. Akra and Louay M. Bazzo},
  title = 	 {On the Solution of Linear Recurrence Relations},
  journal = 	 {Combinatorial Optimization and Application},
  year = 	 1998,
  volume =	 10,
  pages =	 {195--210}
}

@inproceedings{Alon:Moments,
    author = "Noga Alon and Yossi Matias and Mario Szegedy",
    title = "The space complexity of approximating the frequency moments",
    pages = "20--29",
    year = "1996",
    crossref={STOC96},
    url = "citeseer.nj.nec.com/alon96space.html" }

@InProceedings{Dor:Diameter,
  title =        "All Pairs Almost Shortest Paths",
  author =       "Dorit Dor and Shay Halperin and Uri Zwick",
  pages =        "452--461",
  booktitle =    "37th Annual Symposium on Foundations of Computer
                 Science",
  month =        "14--16 " # oct,
  year =         "1996",
  address =      "Burlington, Vermont",
  organization = "IEEE",
  references =   "\cite{SODA::AingworthCM1996} \cite{FOCS::AlonGM1991}
                 \cite{FOCS::AlonGMN1992} \cite{JACM::Awerbuch1985}
                 \cite{FOCS::AwerbuchBCP1993} \cite{FOCS::Cohen1993}
                 \cite{STOC::Cohen1994} \cite{JSYMC::CoppersmithW1990}
                 \cite{STOC::FederM1991} \cite{JACM::FredmanT1987}
                 \cite{JCOMP::GalilM1993} \cite{JACM::Johnson1977}
                 \cite{STOC::Seidel1992} \cite{SICOMP::UllmanY1991}",
}

@Article{Char99,
 title={A constant-factor approximation algorithm for the $k$-median problem},
 author={M. Charikar and S. Guha and E. Tardos and David B. Shmoys},
 journal= {Proceedings of 31st Annual ACM Symposium on Theory of Computing},
 year=1999,
 pages={1--10}
}

@Article{Jain99,
 title={Primal-Dual Approximation Algorithms for Metric Facility Location
 and $k$-Median Problems},
 author={Kamal Jain and Vijay V. Vazirani},
 journal="Proceedings of 40th Symposium on Foundations of Computer Science",
 year = 1999
}

@InProceedings{Awerbuch:Steiner,
  author =       "Baruch Awerbuch and Yossi Azar and Yair Bartal",
  title =        "On-line Generalized Steiner Problem",
  pages =        "68--74",
  ISBN =         "0-89871-366-8",
  booktitle =    "Proceedings of the Seventh Annual {ACM}-{SIAM}
                 Symposium on Discrete Algorithms",
  month =        jan # "~28--30",
  publisher =    "ACM/SIAM",
  address =      "New York/Philadelphia",
  year =         "1996",
}

@InProceedings{GalilY95,
title={Short Length Versions of {Menger's} Theorem (Extended
Abstract)},
author={Zvi Galil and Xiangdong Yu},
crossref= {STOC95},
pages={499--508},
source={http://theory.lcs.mit.edu/~dmjones/STOC/stoc.bib}
}

@techreport{Henzinger:Menger,
author = {Monika Rauch Henzinger and Jon Kleinberg and Satish Rao},
title = {Short-Length {M}enger Theorems},
INSTITUTION= {Digital Systems Research Center},
ADDRESS = {130 Lytton Ave., Palo Alto, CA 94301},
NUMBER={1997-022},
year=1997}

@TECHREPORT{3lisp,
        author = {Brian Cantwell Smith},
        title = {Reflection and Semantics in a Procedural Language},
        INSTITUTION = MITLCS,
        year = {1982},
        NUMBER = {272},
        ADDRESS = MIT-ADDR,
        MONTH = jan
}

@MISC{DublinCore,
	author = {Stuart L. Weivel and Eric J. Miller},
	title = {Dublin Core MetaData Element Set},
	HOWPUBLISHED = {{\tt http://www.oclc.org:5046/research/dublin\_core/}},
	MONTH = may,
	year = {1996}
}

@ARTICLE{WarwickFramework,
	author = {Carl Lagoze},
	title = {The Warwick MetaData Workshop},
	JOURNAL = {DLIB Magazine},
	year = {1996},
	MONTH = aug,
	note = {{\tt http://www.dlib.org/dlib/july96/lagoze/07lagoze.html}}
}

@MISC{DSTC,
	author = {DSTC},
	title = {What'sHot Information Broker},
	HOWPUBLISHED = {{\tt http://www.dstc.edu.au/BDU/APAP/WhatsHot/WhatsHot.html}},
	KEY = {What's Hot}
}

@MISC{Cyperdog,
	organization = {{Apple Computer, Inc.}},
	title = {Cyberdog},
	HOWPUBLISHED = {{\tt http://www.cyberdog.apple.com/overview}},
	KEY = {Cyberdog}
}

@MISC{MCF,
	title = {MetaContent Format},
	HOWPUBLISHED = {{\tt http://mcf.research.apple.com/}},
	KEY = {MetaContent Format}
}

@inproceedings{Karger:Soylent,
 author = {Bernstein, Michael S. and Little, Greg and Miller, Robert
                  C. and Hartmann, Bj\"{o}rn and Ackerman, Mark S. and
                  Karger, David R. and Crowell, David and Panovich,
                  Katrina},
 title = {Soylent: a word processor with a crowd inside},
 booktitle = {UIST '10: Proceedings of the 23nd annual ACM symposium
                  on User interface software and technology},
 abstract={This paper introduces architectural and interaction
                  patterns for integrating crowdsourced human
                  contributions directly into user interfaces. We
                  focus on writing and editing, complex endeavors that
                  span many levels of conceptual and pragmatic
                  activity. authoring tools offer help with
                  pragmatics, but for higher-level help, writers
                  commonly turn to other people. We thus present
                  Soylent, a word processing interface that enables
                  writers to call on Mechanical Turk workers to
                  shorten, proofread, and otherwise edit parts of
                  their documents on demand. To improve worker
                  quality, we introduce the Find-Fix-Verify crowd
                  programming pattern, which splits tasks into a
                  series of generation and review stages. Evaluation
                  studies demonstrate the feasibility of crowdsourced
                  editing and investigate questions of reliability,
                  cost, wait time, and work time for edits.},
 year = {2010},
 month=nov,
 pdf={http://people.csail.mit.edu/msbernst/papers/soylent-uist2010.pdf},
 cat:multiple={CHI;Systems;Mechanism Design},
 isbn = {978-1-4503-0271-5},
 pages = {313--322},
 location = {New York, New York, USA},
 doi = {http://doi.acm.org/10.1145/1866029.1866078},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{Karger:Atomate,
 author = {Van Kleek, Max and Moore, Brennan and Karger, David R. and
                  Andr\'{e}, Paul and schraefel, m. c.},
 title = {Atomate it! end-user context-sensitive automation using
                  heterogeneous information sources on the web},
 booktitle = {WWW '10: Proceedings of the 19th international
                  conference on World wide web},

 abstract={The transition of personal information management (PIM)
                  tools off the desktop to the Web presents an
                  opportunity to augment these tools with capabilities
                  provided by the wealth of real-time information
                  readily available. In this paper, we describe a
                  next-generation personal information assistance
                  engine that lets end-users delegate to it various
                  simple context- and activity-reactive tasks and
                  reminders. Our system, Atomate, treats RSS/ATOM
                  feeds from social networking and life-tracking sites
                  as sensor streams, integrating information from such
                  feeds into a simple unified RDF world model
                  representing people, places and things and their
                  timevarying states and activities. Combined with
                  other information sources on the web, including the
                  user's online calendar, web-based e-mail client,
                  news feeds and messaging services, Atomate can be
                  made to automatically carry out a variety of simple
                  tasks for the user, ranging from context-aware
                  filtering and messaging, to sharing and social
                  coordination actions. Atomate's open architecture
                  and world model easily accommodate new information
                  sources and actions via the addition of feeds and
                  web services. To make routine use of the system easy
                  for non-programmers, Atomate provides a
                  constrained-input natural language interface (CNLI)
                  for behavior specification, and a
                  direct-manipulation interface for inspecting and
                  updating its world model.},
 year = {2010},
 month=apr,
 pdf={http://people.csail.mit.edu/emax/papers/atomate-www2010-camera.pdf},
 cat:multiple={CHI;Information Retrieval;Semantic Web;Haystack},
 isbn = {978-1-60558-799-8},
 pages = {951--960},
 location = {Raleigh, North Carolina, USA},
 doi = {http://doi.acm.org/10.1145/1772690.1772787},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{Karger:Datapress,
  author    = {Edward Benson and
               Adam Marcus and
               Fabian Howahl and
               David R. Karger},
  title     = {Talking about Data: Sharing Richly Structured
                  Information through Blogs and Wikis},
  booktitle = {International Semantic Web Conference},
  year      = {2010},
  month=nov,
  venue={ISWC},
  location = {Shanghai, China},
  url={http://projects.csail.mit.edu/datapress},
  pages     = {48--63},
  pdf={http://people.csail.mit.edu/eob/papers/iswc2010-datapress.pdf},
  doi        = {http://dx.doi.org/10.1007/978-3-642-17746-0_4},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@misc{Karger:Datapress-Poster,
 author = {Benson, Edward and Marcus, Adam and Howahl, Fabian and
                  Karger, David},
 title = {Talking about data: sharing richly structured information
                  through blogs and wikis},
 booktitle = {WWW '10: Proceedings of the 19th international
                  conference on World wide web},
 year = {2010},
 venue={WWW},
month=may,
 url={http://projects.csail.mit.edu/datapress},
 cat:multiple={CHI;Semantic Web;Haystack},
 pub-type={Poster},
note={Poster},
 isbn = {978-1-60558-799-8},
 pages = {1057--1058},
 location = {Raleigh, North Carolina, USA},
 doi = {http://doi.acm.org/10.1145/1772690.1772802},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{Karger:SyncKit,
 author = {Benson, Edward and Marcus, Adam and Karger, David and
                  Madden, Samuel},
 title = {Sync kit: a persistent client-side database caching toolkit
                  for data intensive websites},
 abstract={The web has dramatically enhanced people's ability to
                  communicate ideas, knowledge, and opinions. But the
                  authoring tools that most people understand, blogs
                  and wikis, primarily guide users toward authoring
                  text. In this work, we show that substantial gains
                  in expressivity and communication would accrue if
                  people could easily share richly structured
                  information in meaningful visualizations. We then
                  describe several extensions we have created for
                  blogs and wikis that enable users to publish, share,
                  and aggregate such structured information using the
                  same workflows they apply to text. In particular, we
                  aim to preserve those attributes that make blogs and
                  wikis so effective: one-click access to the
                  information, one-click publishing of content,
                  natural authoring interfaces, and the ability to
                  easily copy-and-paste information and visualizations
                  from other sources.},
 booktitle = {WWW '10: Proceedings of the 19th international
                  conference on World wide web},
 year = {2010},
 month=apr,
 venue={WWW},
 pdf={http://people.csail.mit.edu/marcua/papers/synckit-www2010.pdf},
 cat:multiple={Systems;Semantic Web},
 isbn = {978-1-60558-799-8},
 pages = {121--130},
 location = {Raleigh, North Carolina, USA},
 doi = {http://doi.acm.org/10.1145/1772690.1772704},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{Karger:Feedme,
 author = {Bernstein, Michael S. and Marcus, Adam and Karger, David
                  R. and Miller, Robert C.},
 title = {Enhancing directed content sharing on the web},
 booktitle = {CHI '10: Proceedings of the 28th international
                  conference on Human factors in computing systems},
 year = {2010},
 month=apr,
 abstract={To find interesting, personally relevant web content,
                  people rely on friends and colleagues to pass links
                  along as they encounter them. In this paper, we
                  study and augment link-sharing via e-mail, the most
                  popular means of sharing web content today. Armed
                  with survey data indicating that active sharers of
                  novel web content are often those that actively seek
                  it out, we developed FeedMe, a plug-in for Google
                  Reader that makes directed sharing of content a more
                  salient part of the user experience. FeedMe
                  recommends friends who may be interested in seeing
                  content that the user is viewing, provides
                  information on what the recipient has seen and how
                  many emails they have received recently, and gives
                  recipients the opportunity to provide lightweight
                  feedback when they appreciate shared content. FeedMe
                  introduces a novel design space within
                  mixed-initiative social recommenders: friends who
                  know the user voluntarily vet the material on the
                  user's behalf. We performed a two-week field
                  experiment (N=60) and found that FeedMe made it
                  easier and more enjoyable to share content that
                  recipients appreciated and would not have found otherwise.},
 url={http://feedme.csail.mit.edu/},
 pdf={http://people.csail.mit.edu/marcua/papers/feedme-chi2010.pdf},
 abstract={},
 cat:multiple={CHI;Machine Learning;Information Retrieval},
 isbn = {978-1-60558-929-9},
 pages = {971--980},
 location = {Atlanta, Georgia, USA},
 doi = {http://doi.acm.org/10.1145/1753326.1753470},
 publisher = {ACM},
 address = {New York, NY, USA},
 }
@misc{Karger:Eyebrowse-poster,
 author = {Van Kleek, Max and Moore, Brennan and Xu, Christina and
                  Karger, David R.},
 title = {Eyebrowse: real-time web activity sharing and
                  visualization},
 booktitle = {CHI EA '10: Proceedings of the 28th of the international
                  conference extended abstracts on Human factors in
                  computing systems},
 year = {2010},
 month=apr,
 isbn = {978-1-60558-930-5},
 pages = {3643--3648},
 location = {Atlanta, Georgia, USA},
 doi = {http://doi.acm.org/10.1145/1753846.1754032},
 publisher = {ACM},
 pub-type={Poster},
 note={Poster},
 address = {New York, NY, USA},
 }

@article{Karger:Speakup-journal,
 author = {Walfish, Michael and Vutukuru, Mythili and Balakrishnan,
                  Hari and Karger, David and Shenker, Scott},
 title = {DDoS defense by offense},
 cat:multiple={Systems;P2P},
 pdf={www.cs.utexas.edu/~mwalfish/papers/speakup-tocs10.pdf},
 abstract={This article presents the design, implementation, analysis,
                  and experimental evaluation of speak-up, a defense
                  against application-level distributed
                  denial-of-service (DDoS), in which attackers cripple
                  a server by sending legitimate-looking requests that
                  consume computational resources (e.g., CPU cycles,
                  disk). With speak-up, a victimized server encourages
                  all clients, resources permitting, to automatically
                  send higher volumes of traffic. We suppose that
                  attackers are already using most of their upload
                  bandwidth so cannot react to the encouragement. Good
                  clients, however, have spare upload bandwidth so can
                  react to the encouragement with drastically higher
                  volumes of traffic. The intended outcome of this
                  traffic inflation is that the good clients crowd out
                  the bad ones, thereby capturing a much larger
                  fraction of the server's resources than before. We
                  experiment under various conditions and find that
                  speak-up causes the server to spend resources on a
                  group of clients in rough proportion to their
                  aggregate upload bandwidths, which is the intended result.},
 journal = {ACM Trans. Comput. Syst.},
 volume = {28},
 number = {1},
 year = {2010},
 month=mar,
 issn = {0734-2071},
 pages = {1--54},
 doi = {http://doi.acm.org/10.1145/1731060.1731063},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

@inproceedings{Lucani:Gossip,
 author = {Lucani, Daniel E. and M\'{e}dard, Muriel and Stojanovic,
                  Milica and Karger, David R.},
 cat:multiple={Coding;P2P},
 abstract={We study random linear network coding for time-division
                  duplexing channels for sharing information between
                  nodes. We assume a packet erasure channel with nodes
                  that cannot transmit and receive information
                  simultaneously. Each node will act as both a sender
                  of its own information and a receiver for the
                  information of the other nodes. When a node acts as
                  the sender, it transmits coded data packets
                  back-to-back before stopping to wait for the
                  receivers to acknowledge the number of degrees of
                  freedom, if any, that are required to decode
                  correctly the information. This acknowledgment comes
                  in the header of the coded packets that are sent by
                  the other nodes. We study the mean time to complete
                  the sharing process between the nodes. We provide a
                  simple algorithm to compute the number of coded
                  packets to be sent back-to-back depending on the
                  state of the system. We present numerical results
                  for the case of two nodes sharing data and show that
                  the mean completion time of our scheme is close to
                  the performance of a full duplex network coding
                  scheme and can outperform full duplex schemes with
                  no coding.},
 title = {Sharing information in time-division duplexing channels: a
                  network coding approach},
 booktitle = {Allerton'09: Proceedings of the 47th annual Allerton
                  conference on Communication, control, and
                  computing},
 year = {2009},
 month=sep,
 isbn = {978-1-4244-5870-7},
 pages = {1403--1410},
 location = {Monticello, Illinois, USA},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 }

@inproceedings{AielloAMR93,
	author={W. Aiello and Baruch Awerbuch and Bruce Maggs and Satish Rao},
	title={Approximate Load Balancing on Dynamic and Asynchronous
Networks},
	crossref = {STOC93},
	pages={632--641}}

@article{AllenBCCF88,
	author={F. Allen and M. Burke and P. Charles and R. Cytron and J. Ferrante},
	title={An overview of the PTRAN analysis system for multiprocessing},
	journal=jpdc,
	volume=5,
	year=1988,
	pages={617-640}}

@article{Aggarwal:DFS,
	author = {Alok Aggarwal and R. J. Anderson},
	title = {A Random {$\NC$} Algorithm for Depth First Search},
        journal = COMB,
        volume = 8,
	pages = {1--12},
        year = 1988}

@article{Agrawal:Steiner,
	author = {Ajit Agrawal and Philip Klein and R. Ravi},
	title = {When Trees Collide: An Approximation Algorithm
for the Generalized {S}teiner Problem on Networks},
	journal = sicomp,
	month = jun,
	year = 1995,
	pages = {440--456},
	volume = 24,
	number = 3,
	note = prelim # STOC91 # {pp. 134--144}
        }

@InProceedings{Aggarwal:Steiner,
        author = 	 {Manica Aggarwal and Naveen Garg},
        title = 	 {A Scaling Technique for Better Network Design},
        crossref =	 {SODA94},
        pages =	 {233--240}
        }

@book{Aho:DataStructures,
	author = {Alfred V. Aho and John E. Hopcroft and Jeffrey D.
Ullman},
	title = {Data Structures and Algorithms},
	publisher = {Addison Wesley},
	year = 1983
        }

@book{Ahuja:Flow,
	title = {Network Flows: Theory, Algorithms, and Applications},
	author = {Ravindra K. Ahuja and Thomas L. Magnanti and James
B. Orlin},
	publisher = {Prentice Hall},
	address = {Englewood Cliffs, New Jersey},
	year = 1993}

@inproceedings{Ajtai:Expander,
	author = {Miklos Ajtai and J. Koml{\'o}s and Endre Szemer{\'e}di},
	title = {Deterministic Simulation in Logspace},
	crossref = {STOC87},
	pages = {132--140}}

@book{Aldous,
	author = {David Aldous},
	title = {Probability Approximations via the Poisson Clumping
Heuristic},
	publisher = sv,
	address = {New York},
	year =  1989}

@Article{Aldous:MetropolisTree,
  author = 	 {David Aldous},
  title = 	 {A Metropolis-Type Optimization Algorithm on the
                  Infinite Tree},
  journal =   ALGO,
  year = 	 1998,
  volume =	 22,
  pages =	 {388--412}
}

@InProceedings{Aldous:Winners,
  author = 	 {David Aldous and Umesh Vazirani},
  title = 	 {Go With the Winners Algorithms},
  crossref =	 {STOC94},
  pages =	 {492--501}
}

@INPROCEEDINGS{Aldous:Coupling,
	author = {D Aldous},
	title = {Random Walks on Finite Groups and Rapidly Mixing Markov Chains},
	booktitle = {Siminaire de Probabilites XVII 1981/1982. Lecture notes in Mathematics},
	year = {1983},
	pages = {243--297},
	publisher = {Springer-Verlag}
}

@InProceedings{Aleliunas:Walks,
        author = 	 aleliunas # and # karp # and # lipton # and # lovasz # and # rackoff,
        title = 	 "Random Walks, Universal Traversal Sequences, and the
		  Complexity of  Maze Problems",
        crossref =	 {focs79},
        pages =	 "218--223"
}

@Article{Alizadeh,
        author = 	 {Farid Alizadeh},
        title = {Interior point methods in semidefinite programming with
        applications to combinatorial optimization},
  journal = 	 {Siam Journal on Optimization},
  year = 	 1995,
  volume =	 5,
  number =	 1,
  pages =	 {13--51},
  note =	 {Preliminary version appeared in IPCO 1992}
}

@inproceedings{Alizadeh-conf,
	author = {Farid Alizadeh},
	title = {Interior point methods in semidefinite programming with
applications to combinatorial optimization},
	booktitle = proc # { 2nd MPS Conference on Integer
Programming and Combinatorial Optimization},
	address = {Carnegie-Mellon University},
	year =1992,
	note = {Journal version in {\em SIAM
Journal on Optimization}.}}

@article{AS,
  author = 	 {Sanjeev Arora and Shmuel Safra},
  title = 	 {Probabilistic checking of proofs: A new characterization of {NP}},
  journal = jacm,
  volume = 45,
  number = 1,
  pages = {70--122},
  year = 1998,
  note = prelim # FOCS92
}
@inproceedings{almss,
	author = {Sanjeev Arora and Carsten Lund and Rajeev Motwani and
Madhu Sudan and Mario Szegedy},
	title = {Proof Verification and Hardness of Approximation
Problems},
	crossref = {FOCS92},
	pages = {14--23}}

@InProceedings{Arora:Assignment,
  title =        "A New Rounding Procedure for the Assignment Problem
                 with Applications to Dense Graph Arrangement Problems",
  author =       "Sanjeev Arora and Alan Frieze and Haim Kaplan",
  pages =        "21--30",
  booktitle =    "37th Annual Symposium on Foundations of Computer
                 Science",
  month =        "14--16 " # oct,
  year =         "1996",
  address =      "Burlington, Vermont",
  organization = "IEEE",
  references =   "\cite{FOCS::Arora1996} \cite{STOC::AroraKK1995}
                 \cite{FOCS::AroraLMSS1992} \cite{JACM::Baker1994}
                 \cite{FOCS::FriezeK1996} \cite{JACM::IbarraK1975}
                 \cite{FOCS::KarmarkarK1982} \cite{STOC::KhannaM1996}
                 \cite{FOCS::LeightonR1988} \cite{STOC::LubyN1993}
                 \cite{JACM::SahniG1976} \cite{JACM::Yannakakis1985}"
}
@techreport{Alon:Witnesses,
	author = {Noga Alon and Zvi Galil and Oded Margalit and Moni Naor},
	title = {Witnesses for Boolean Matrix Multiplication and for
		Shortest Paths},
	institution = {IBM},
	year = 1992,
	number = {RJ 8744}}

@inproceedings{Alon:Tutte,
        author = {Noga Alon and Alan Frieze and Dominic Welsh},
        title = {Polynomial Time Randomized Approximation Schemes for
		  the {T}utte Polynomial of Dense Graphs},
        crossref = {FOCS94},
        pages = {24--35}}

@misc{alon:comm,
        author = {Noga Alon},
	title = {Personal Communication},
	month= aug,
	year = 1994}

@Article{Alon:Independent,
  author = 	 {Noga Alon and Nabil Kahale},
  title = 	 {Approximation the Independence Number via the
                  $\theta$-function},
  journal = 	 mp,
  year = 	 1998,
  volume =	 80,
  pages =	 {253--264}
}

@inproceedings{Alon:Coloring,
	author = {Noga Alon and Nabile Kahale},
	title = {A Spectral Technique for Coloring Random
$3$-Colorable Graphs},
	crossref = {STOC94},
	pages = {346--355}}

@inproceedings{Alon:ExcludedMinors,
author =  "Noga Alon  and Paul Seymour and Thomas R.",
title = "A Separator Theorem for Graphs with an Excluded Minor and its Applications.",
crossref = {STOC90},
pages = {293-299},
mynote={The paper by Alon Seymour and Thomas is beautiful stuff.  (We use
essentially the same proof in Plotkin Rao Smith..with a (I think)
clearer explanation.)} }

@misc{AKS:comm,
        author = {Noga Alon and Nabil Kahale and Mario Szegedy},
	title = {Personal Communication},
	month = aug,
	year = 1994}

@inproceedings{Alon:Paths,
	author = {Noga Alon and Zvi Galil and Oded Margalit},
	title = {On the Exponent of the All Pairs
		Shortest Path Problem},
	crossref = {FOCS91},
	pages = {569--575}
}

@techreport{Alon:Trees,
	author = {Noga Alon and Baruch Schieber},
	title = {Optimal Preprocessing for Answering Online Product Queries},
	year = 1987,
	institution = {Tel Aviv University}}

@book{Alon:ProbabilisticMethod,
	author = {Noga Alon and Joel H. Spencer},
	title = {The Probabilistic Method},
	publisher = {John Wiley \& Sons, Inc.},
	address = {New York, NY},
	year = 1992}

@misc{Applegate:Private,
	author = {David Applegate},
	note = {Personal Communication.},
	year = 1992,
	howpublished={AT\&T Bell Labs}}

@misc{Applegate:Private96,
	author = {David Applegate},
	note = {Personal Communication.},
	year = 1996,
	howpublished={AT\&T Bell Labs}}

@TechReport{Applegate:TSP,
  author = 	 applegate # and # bixby # and # chvatal # and # cook,
  title = 	 "Finding Cuts in the TSP",
  institution =  "DIMACS",
  year = 	 1995,
  number =	 "95-05",
  address =	 "Rutgers University, New Brunswick, NJ"
}

@Article{Aragon:Treaps,
  title =        "Randomized Search Trees",
  author =       "Raimund Seidel and C. R. Aragon",
  pages =        "464--497",
  journal =      "Algorithmica",
  year =         "1996",
  month =        oct # "/" # nov,
  volume =       "16",
  number =       "4/5",
  references =   "\cite{FOCS::AnderssonO1991}
                 \cite{SODA::BaumgartenJM1992} \cite{ACTAI::BayerM1972}
                 \cite{SICOMP::BentST1985} \cite{JACM::Brent1976}
                 \cite{JACM::Devroye1986} \cite{SODA::GalperinR1993}
                 \cite{FOCS::GuibasS1978} \cite{IC::HoffmanMRT1986}
                 \cite{SICOMP::McCreight1985}
                 \cite{SICOMP::NievergeltR1973} \cite{POPL::PughT1989}
                 \cite{JACM::DleatorT1985}",
}
@Article{Aumann:MultiCut,
  author = 	 {Yonatan Aumann and Yuval Rabani},
  title = 	 {An {$O(\log k)$} Approximate Min-Cut Max-Flow
                  Theorem and Approximation Algorithm},
  volume = {27},
number = 1,
pages ={291--301},
  journal =   sicomp,
  year = 	 1998,
}

@article{Awerbuch:MST,
	author = {Baruch Awerbuch and Y. Shiloach},
	title = {New Connectivity and {MSF} Algorithms for
Shuffle-Exchange Network and {PRAM}},
	journal = {IEEE Transactions on Computers},
	volume = {C-36},
	number = 10,
	month = oct,
	year = 1987,
	pages = {1258--1263}}

@inProceedings{Awerbuch:Flow,
title={Improved Approximation Algorithms for the Multi-Commodity Flow
Problem and Local Competitive Routing in Dynamic Networks},
author={Baruch Awerbuch and Tom Leighton},
pages={487--496},
crossref={STOC94},
source={http://theory.lcs.mit.edu/~dmjones/STOC/stoc.bib}
}

@INCOLLECTION{BB-93,
author = "T. Badics and R. Boros",
title = "{Implementing a Maximum Flow Algorithm:
	Experiments with Dynamic Trees}",
booktitle = "{Network Flows and Matching: First DIMACS Implementation
              Challenge}",
publisher = "AMS",
EDITOR = "D. S. Johnson and C. C. McGeoch",
year = 1993,
PAGES = "43--64"}

@Article{BNS,
         author =       babai # and # nisan # and # szegedy,
         title =        "Multiparty Protocols, Pseudorandom Generators for
                        Logspace, and Time-Space Trade-offs",
         journal =      "Journal of Computer and System Sciences",
         volume =       "45",
		  number = 2,
		  pages = {204--232},
         year =         "1992",
       }
@article{Baker:Discards,
  author = "Nicholson Baker",
  title = "Discards",
  journal = "The New Yorker",
  year = 1994,
  month = apr,
  day = 4,
  pages = {68,81-83}
}
@TechReport{Balabanovic:BrosweAgent,
  author = 	 {Marko Balabanovic and Yoav Shoham and Yeogirl Yun},
  title = 	 {An Adaptive Agent for Automated Web Browsing},
  institution =  {Stanford University},
  year = 	 1997,
  number =	 {CS-TN-97-52}
}
@TechReport{Baldonado:SenseMaker,
  author = 	 {Michelle Q Wang Baldonado and Terry Winograd},
  title = 	 {SenseMaker: An Information-Exploration Interface
                  Supporting the Contextual Evolution of a User's
                  Interests},
  institution =  {Stanford University},
  year = 	 1997,
  type =	 {Stanford Digital Library Project},
  number =	 {SIDL-WP-1996-0048},
  note =	 {also available at {\tt http://www-diglib.stanford.edu/cgi-bin/WP/get/SIDL-WP-1996-0048}}
}
@Article{Barahona:SparseQuotient,
	author = {Francisco Barahona},
  title = 	"Separating from the Dominant of the Spanning Tree Polytope",
  journal = 	"Operations Research Letters",
  year = 	1992,
  volume =	 12,
  pages =	 "201--203"
}
@article{Barahona:TreePacking,
	author = {Francisco Barahona},
	title = {Packing Spanning Trees},
	journal = mor,
	volume = 20,
	number = 1,
	month = feb,
	year = 1995,
	pages = {104--115}}

@InProceedings{Barnes:stConnectivity,
  author = 	 barnes # and # ruzzo,
  title = 	 "Deterministic algorithms for undirected {$s$-$t$}
		  connectivity using polynomial time and sublinear
		  space",
  crossref =	 "STOC91",
  pages =	 "48--53",
  abstract =     "The $s$-$t$ connectivity problem for undirected graphs
                        is to decide whether two designated vertices, $s$ and
                        $t$, are in the same connected component. This paper
                        presents the first known deterministic algorithms
                        solving undirected $s$-$t$ connectivity using sublinear
                        space and polynomial time. There is some evidence that
                        such algorithms are impossible for the analogous
                        problem on directed graphs. Our algorithms provide a
                        nearly smooth time-space tradeoff between depth-first
                        search and Savitch's algorithm. For $n$ vertex, $m$
                        edge graphs, the simplest of our algorithms uses space
                        $s$, $O(n^{1/2} \log n) \le s \le O(n\log n)$, and time
                        $O(((m + n)n^{2}\log^{2} n)/s)$. We give a variant of
                        this method that is faster at the higher end of the
                        space spectrum. For example, with space $\Theta(n\log
                        n)$, its time bound is $O((m+n)\log n)$, close to the
                        optimal time for the problem. Another generalization
                        uses less space, but more time: space
                        $O((n^{\epsilon}\log{n})/\epsilon)$, for
                        $1/\log{n}\leq\epsilon\le 1/2$, and time
                        $n^{O(\xfrac{1}{\epsilon})}$. For constant $\epsilon$
                        the time remains polynomial.",}

@inproceedings{Barnes:Walks,
         author =       barnes # and # feige,
         title =        "Short Random Walks on Graphs",
         crossref={STOC93},
         pages =        "728--737",
       }

@inproceedings{Bartal:Scheduling,
	author = {Y. Bartal and Amos Fiat and Howard Karloff and R.
Vohra},
	title = {New Algorithms for an Ancient Scheduling
Problem},
	crossref = {STOC92},
	pages = {51-58}}

@article{Bellare:Expander,
	author = {Mihir Bellare and Oded Goldreich and Shafi
Goldwasser},
	title = {Randomness in Interactive Proofs},
        journal = {Computational Complexity},
        note = prelim # FOCS90,
        year = 1993,
        volume = 3,
	pages ={319--354}}

@inproceedings{Bellare:Sampling,
        author = {Mihir Bellare and John Rompel},
        title = {Randomness-Efficient Oblivious Sampling},
        crossref = {FOCS94},
        pages = {276--287}}

@inproceedings{bellare,
	author = {Mihir Bellare and Madhu Sudan},
	title = {Improved Non-approximability Results},
	crossref = {STOC94},
	pages = {184--193}}

@inproceedings{Benczur:Augmentation,
	author = benczur,
	title = {Augmenting Undirected Connectivity in {$\RNC$} and in
Randomized {$\Olog(n^3)$} Time},
	crossref = {STOC94},
	note = {Journal version in preparation},
	pages = {658--667}}

@inproceedings{Benczur:ApproxCut,
     author = benczur,
title={A representation of cuts within 6/5 times the edge
connectivity with applications},
pages={92--102},
crossref={FOCS95}}


@phdthesis{Benczur:Thesis,
	author = benczur,
	title = {Cut structures and randomized
    algorithms in edge-connectivity problems},
	school = {Massachusetts Institute of Technology},
	year = 1997,
	note = {Available at {{\tt
    http://pele.ilab.sztaki.hu/\~{}benczur/\~{}Mypapers/Thesis.ps.gz}}}
	}

@book{berge,
	author = {C. Berge},
	title = {Graphs and Hypergraphs},
	publisher = {North-Holland},
	address = {Amsterdam},
	year =  1973}

@article{Berkman:LCA,
	author = {Omer Berkman and Uzi Vishkin},
	title = {Recursive Star-Tree Parallel Data Structure},
	journal = sicomp,
	month = apr,
	year = 1993,
	volume = 22,
	number = 2,
	pages = {221--242}}

@book{Bickel:Statistics,
author = {Bickel, P. J. and Doksum, K. A.},
  year = 1977,
  title = {Mathematical Statistics: Basic Ideas and Selected
  Topics},
  publisher = {Holden-Day},
  address = {Oakland, CA.}}

@techreport{Bloniarz:Paths,
	author = {P. A. Bloniarz},
	title = {A Shortest-path Algorithm with Expected Time
		{$O(n^2\log n \log^* n)$}},
	institution = {Department of Computer Science, State University of New York at Albany},
	year = 1980,
	month = aug,
	number = {80-3}
}
@article{Blum:Median,
	author = {Manuel Blum and Robert W. Floyd and V. R. Pratt and
Ronald L. Rivest and Robert E. Tarjan},
	title = {Time Bounds for Selection},
	journal = JCSS,
	volume = 7,
	year = 1973,
	pages = {448-461}}

@inproceedings{blum89,
	author = {Avrim Blum},
	title = {An {$O(n^{0.4})$}-Approximation Algorithm for
3-Coloring (and Improved Approximation Algorithms for $k$-Coloring)},
	crossref = {STOC89},
	pages = {535--542}}

@inproceedings{blum90,
	author = {Avrim Blum},
	title = {Some tools for approximate 3-coloring},
	crossref = {FOCS90},
	pages = {554--562}}

@article{Blum:Coloring,
	author = {Avrim Blum},
	title = {New Approximation Algorithms for Graph Coloring},
	journal = jacm,
	volume = 41,
	number = 3,
	month = may,
	year = 1994,
	pages = {470--516}}

@book{Bollobas,
	author= bollobas,
	title = {Random Graphs},
	publisher = {Harcourt Brace Janovich},
	year = 1985}

@Book{Bollobas:ExtremalBook,
  author = 	 bollobas,
  title = 	 "Extremal Graph Theory with Emphasis on Probabilistic
		  Methods",
  publisher = 	 "American Mathematical Society",
  year = 	 1986,
  number =	 62,
  series =	 "Regional Conference Series in Mathematics",
  address =	 "Providence, RI"
}
@incollection{Bollobas:kConnectivity,
	author = bollobas # and # {A. G. Thomason},
	title = {Random Graphs of Small Order},
	booktitle = {Random Graphs},
	editor = {Michal Karnoski and Zbignew Palka},
	pages = {47-97},
	series = {Annals of Discrete Mathematics},
	number = 33,
	publisher = {Elsevier Science Publishing Company},
	year = 1987}

@article{boppana:IS,
	author = {R. B. Boppana and Magnus M. Halldorsson},
	title = {Approximating maximum independent sets by
excluding subgraphs},
	journal = {BIT},
	volume = 32,
	pages = {180--196},
	year = {1992}}

@article{Boppana:Bisection,
	author = {R. B. Boppana},
	title =  {Eigenvalues and graph bisection: an average-case
analysis},
	crossref = {FOCS87},
	pages = {280--285}}

@article{Boruvka:MST,
	author = {O. Bor\o{u}vka},
	title = {O Jist{\'e}m Probl{\'e}mu Minim{\'a}ln{\'i}m},
	journal = {Pr{\'a}ca Moravsk{\'e}
P{\v{r}}{\'i}rodov{\v{e}}deck{\'e} Spol{\v{c}}nosti},
	volume = 3,
	year = {1926},
	pages = {37-58},
	language ={Czech}}

@inproceedings{Botafogo:Hypertext,
	author = {Rodrigo A. Botafogo},
	title = {Cluster Analysis for Hypertext Systems},
	booktitle = SIGIR93,
	year = 1993,
	pages = {116--125},
	month = jun}

@inproceedings{briggs,
	author = {P. Briggs and K. D. Cooper and K. Kennedy and L.
Torczon},
	title = {Coloring heuristics for register allocation},
	booktitle = SIGPLAN89,
	pages = {275--274},
	year =  1989}

@Article{Brown:Finger,
  author = 	 "Mark Brown" # and # tarjan,
  title = 	 "Design and Analysis of a Data Structure for
                      Representing Sorted Lists",
  journal =  sicomp,
  year =	 1980,
  volume =	 9,
  pages =	 "594--614"
}
@Article{Brown:MergeTrees,
  author = 	 "Mark Brown" # and # tarjan,
  title = 	 "A Fast Merging Algorithm",
  journal =	 jacm,
  year =	 1979,
  volume =	 26,
  number =	 2,
  pages =	 "211--226",
  month =	 apr
}

@article{Cai:Augmentation,
	author = {Cai, G--P. and Y--G. Sun},
	title = { The minimum augmentation of any
  graph to a $k$-edge-connected graph},
	journal = {Networks},
	volume = 19,
	year=1989,
  	pages = {151--172}
	}

@article{Camerini:Matroid,
	author = {P. M. Camerini and G. Galbiati and F. Maffioli},
	title = {Random Pseudo-Polynomial Algorithms for Exact
Matroid Problems},
	journal = JALG,
	volume = 13,
	number = 2,
	year = 1992,
	month = jun,
	pages = {258--273}}

@inproceedings{chaitin,
	author = {G. J. Chaitin},
	title = {Register allocation and spilling via graph coloring},
	booktitle = SIGPLAN89,
	pages = {98--101},
	year = 1982}

@article{chandra,
author = {G. J. Chaitin and M. A. Auslander and A. K. Chandra and J.
Cocke and M. E. Hopkins and P. W. Markstein},
	title = {Register allocation via coloring},
	journal = {Computer Languages},
 	volume = 6,
	pages = {47--57},
	year = 1981}

@InProceedings{Chaterjee:Personal,
  author = 	 {S. Chaterjee and  J. R. Gilver and  R. Schreiber and T. J. Sheffler},
  title = 	 {Array Distribution in Parallel Programs},
  booktitle = 	 {Languages and Compilers for Parallel Computing},
  volume =	 369,
  series =	 {Lecture notes in Computer Science series},
  year =	 1996,
  publisher =	 {Springer-Verlag},
  pages =	 {76--91}
}

@article{Chazelle:Trees,
	author = {Bernard Chazelle},
	title = {Computing on a Free Tree via Complexity-Preserving Mappings},
	journal = ALGO,
	year = 1987,
	volume = 2,
        number = 3,
	pages = {337-361}}

@article{Chazelle:RangeSearch,
	author = {Bernard Chazelle},
        title = {A Functional Approach to Data Structures and its Use
                  in Multidimensional Searching},
        journal = sicomp,
        year = 1988,
        volume = 17,
        number = 3,
        month = jun,
        pages = {427--461}
}

@article {Cheriyan:Maxflow,
	title = {A Randomized Maximum-flow Algorithm},
	author = {Joseph Cheriyan  and Torben Hagerup},
        journal = sicomp,
	volume = 24,
        number = {2},
        pages = {203--226},
	month = apr,
	note = prelim # FOCS90,
        year = 1995}

@incollection{Cheriyan:DenseMaxflow,
	author = {Joseph Cheriyan and T. Hagerup and Kurt Mehlhorn},
	title = {Can a maximum flow be computed in {$o(nm)$} time?},
	editor = {Michael S. Patterson},
	booktitle = ICALP90,
	year = 1990,
	publisher = sv,
	address = {Berlin},
	pages = {135--48}}

@inproceedings{Cheriyan:Paths,
	author = {Joseph Cheriyan and Ramki Thurimella},
	title = {Algorithms for Parallel {$k$}-Vertex Connectivity and
		Sparse Certificates\typeout{SUPERSEDED BY JOURNAL?}},
	crossref = {STOC91},
	pages = {391--401}}

@article{Cheriyan:Connectivity,
	author = {Joseph Cheriyan and Ming Yang Kao and Ramki
Thurimella},
	title = {Scan-First Search and Sparse Certificates: An
Improved Parallel Algorithm for $k$-vertex Connectivity},
	journal = sicomp,
	volume = 22,
	number = 1,
	pages = {157--174},
	month = feb,
	year = 1993}

@article{Chernoff,
	author = {H. Chernoff},
	title = {A measure of the Asymptotic Efficiency for Tests
of a Hypothesis Based on the Sum of Observations},
	journal = {Annals of Mathematical Statistics},
	volume = 23,
	pages = {493--509},
	year = 1952}

@Article{CLC,
  author = 	 "F. Y. Chin and J. Lam and I. N. Chen",
  title = 	 "Efficient Parallel Algorithms for some Graph Problems",
  journal =	 cacm,
  year =	 1982,
  volume =	 25,
  number =	 9,
  pages =	 "659--665",
  month =	 sep
}

@inproceedings{Chong:Proc-Connectivity,
	author = {Ka Wong Chong and Tak Wah Lam},
	title = {Connected Components in {$O(\log n\log\log n)$}
Time on the {EREW} {PRAM}},
	crossref = {SODA93},
	pages = {11-20},
	note = {To appear in {\it Algorithmica}\typeout{CL93 appeared yet?}}}

@Article{Chong:Connectivity,
         author =       "Chong and Lam",
         title =        "Finding Connected Components in {$O(\log n
		  \log \log n)$} Time on the {EREW} {PRAM}",
         journal =      "Journal of Algorithms",
         volume =       "18",
	  number = 3,
	  pages = {378--402},
         year =         "1995",
		  month = may,
	  note = prelim # SODA93,
       }

@article{Chor:pairwise,
        author = {B. Chor and Oded Goldreich},
        title = {On the power of two-point sampling},
        journal = {Journal of Complexity},
	volume = 5,
	pages = {96--106},
        year = 1989}

@article{Chow:RegisterAllocation,
	author = {Fred C. Chow and John L. Hennessy},
	title = {The Priority Based Coloring Approach to Register
Allocation},
	journal = {Transactions on Programming Languages and Systems},
	year = 1990,
	volume = 12,
	number = 4,
	month = oct,
	pages = {501--536}}

@article{Clarkson:LP,
	author = {Ken L. Clarkson},
	title = {{L}as {V}egas Algorithms for Linear and Integer
Programming when the Dimension is Small},
	journal = jacm,
	volume = 42,
	number= 2,
	year = 1995,
	pages = {488--499}}

@article{Clarkson:Sampling,
	author = {Ken L. Clarkson},
	title = {New Applications of Random Sampling in Computational
Geometry},
	journal = {Discrete and Computational Geometry},
	volume = 2,
	year = 1987,
	pages = {195--222}}

@article{Clarkson:SamplingII,
	author = {Ken L. Clarkson and Peter W. Shor},
	title = {Applications of Random Sampling in Computational
Geometry, {II}},
	journal = {Discrete and Computational Geometry},
	volume = 4,
	number = 5,
	pages = {387--421},
	year = 1987}

@inproceedings{Cohen:Expander,
	author={A. Cohen and Avi Wigderson},
	title={Dispersers, deterministic amplification, and weak random
		sources},
	crossref = {FOCS89},
	pages={14--19}}

@inproceedings{Cohen:Wheel,
	author = {Robert F. Cohen and Giuseppe Di~Battista and Arkady
Kanevsky and Roberto Tamassia},
	title = {Reinventing the Wheel: An Optimal Data Structure
for Connectivity Queries},
	crossref = {STOC93},
	pages = {194--200}}

@Article{Cohen:Round,
  author = 	 {Edith Cohen},
  title = 	 {Approximate Max-Flows in Small-Depth Networks},
  journal =   sicomp,
  year = 	 1995,
  volume =	 24,
  number =	 3,
  month =	 jun,
  pages =	 {579--599}
}

@InProceedings{Cohen:TransitiveClosure,
title={Estimating the Size of the Transitive Closure in Linear Time},
author={Edith Cohen},
pages={190--200},
crossref={FOCS94},
source={http://theory.lcs.mit.edu/~dmjones/FOCS/focs.bib}
}

@book{Colbourn,
	author = {Charles J. Colbourn},
	title = {The Combinatorics of Network Reliability},
	publisher = {Oxford University Press},
	year = 1987,
	series = {The International Series of Monographs on Computer
Science},
	editors = {John E. Hopcroft and Gordon D. Plotkin and Jacob T.
Schwartz and Dana S. Scott and Jean Vuillemin},
	volume = 4}

@article{Cole:Sort,
	author = {Richard Cole},
	title = {Parallel Merge-Sort},
	journal = sicomp,
	volume = 17,
	number = 4,
	pages = {770-785},
	month = aug,
	year = 1988}

@inproceedings{Cole:Connectivity,
	author = {Richard Cole and Uzi Vishkin},
	title = {Approximate and Exact Parallel Scheduling with
Applications to List, Tree and Graph Problems},
crossref={FOCS86}}

@Article{Cole:ParallelSchedulingI,
  author = 	 cole # and # vishkin,
  title = 	 "Approximate Parallel Scheduling, Part {I}: he Basic
		  Technique with Applications to Optimal Parallel List
		  Ranking in Logarithmic Time",
  journal =  sicomp,
  year =	 1988,
  volume =	 17,
  number =	 1,
  pages =	 "128--142"
}

@Article{Cole:ParallelSchedulingII,
         author = cole # and # vishkin,
         title =  "Approximate Parallel Scheduling.
		  {II}. {A}pplications to
                   Logarithmic-Time Optimal Parallel Graph Algorithms",
         journal =  "Information and Computation (formerly Information and
                     Control)",
         volume =  92,
		  number = 1,
		  month = may,
	  pages={1--47},
         year =  1991
       }

@inproceedings{Cole:MST,
	author = {Richard Cole and Philip N. Klein and Robert E. Tarjan},
	title = {A Linear-Work Parallel Algorithm for Finding
Minimum Spanning Trees},
	pages = {11--16},
	crossref = {SPAA94}}

@book{ConcreteMathematics,
	author = {Ronald L. Graham and Donald E. Knuth and Oren
Patashnik},
	title = {Concrete Mathematics},
	publisher = {Addison-Wesley},
	address = {Reading, Massachusetts},
	year = 1989}

@article{Cook:EREW,
	author = {Stephen Cook} # and # dwork # and # reischuk,
	title = {Upper and Lower Bounds for Parallel Random Access
Machines Without Simultaneous Writes},
	journal = sicomp,
		  volume = 15, number = 1, pages = {87--97},
	year = 1986,
	month = feb}

@misc{copper,
	author ={Dan Coppersmith},
	note = {Personal Communication.},
	month = mar,
	year =  1994,
	howpublished={IBM T. J. Watson Laboratories}}

@article{Coppersmith:Matrix,
	author = {Dan Coppersmith and Shmuel Winograd},
	title = {Matrix Multiplication via Arithmetic Progressions},
	journal = {Journal of Symbolic Computation},
	year = 1990,
	volume = 9,
	pages = {251-280}}

@book{Cormen:Algorithms,
	author = {Thomas H. Cormen and Charles E. Leiserson and Ronald
L. Rivest},
	title = {Introduction to Algorithms},
	publisher = {{MIT} Press},
	year=1990,
	address = {Cambridge, MA}}

@article{Dantzig:TSP,
	author = {George~B. Dantzig and Delbert~R. Fulkerson and S.~M.
Johnson},
	title  = {Solution of a Large-Scale Traveling Salesman
Problem},
	journal = OR,
	volume = 2,
	pages = {393--410},
	year = 1954}

@Article{Dahlhaus:NPComplete,
  author = 	 "E. Dahlhaus and David S. Johnson and Christos H.
		Papadimitriou and Paul D. Seymour and Mihalis Yannakakis",
  title = 	 "The Complexity of Multiterminal Cuts",
  journal =  sicomp,
  year =	 1994,
  volume =	 23, number = 4,
  pages =	 "864--894",
  note = prelim # STOC92,
}

@article{Dial,
	author = {R.~B. Dial},
	title = {Algorithm 360: Shortest Path Forest with Topological
		Ordering},
	journal = cacm,
	year = 1969,
	volume = 12,
	pages = {632--633}}

@Article{DietzEtAl95,
         author =       "Dietz and Kurt Mehlhorn and Raman and Uhrig",
         title =        "Lower Bounds for Set Intersection Queries",
         journal =      "Algorithmica",
         volume =       "14",
         number = 2,
         year =         "1995",
         note = "gives a bound of $q+n\sqrt{q}$ for performing n set
                  updates and q intersection queries.  Does not rule
                  out runtime proportional to output set size, since
                  their bound applies to large sets."
       }

@Article{Dietzfelbinger:EW,
         author =       "M. Dietzfelbinger and M. Kutylowski" # and # reischuk,
         title =        "Exact Lower Time Bounds for Computing Boolean
                        Functions on {CREW} {PRAM}s",
         journal =      "Journal of Computer and System Sciences",
         volume =       "48",
		  number = 2,
		  pages = {231--254},
		  month = apr,
         year =         "1994",
note = prelim # SPAA92,
       }

@article{Dijkstra,
	author = {E. W. Dijkstra},
	title = {A note on Two Problems in Connection with Graphs},
	journal = {Numerische Mathematik},
	year = 1959,
	volume = 1,
	pages = {260--271}}

@incollection{Dinitz:Cactus,
	author = {Efim A. Dinitz and Alexander~V. Karzanov and Micael V.
Lomonosov},
	title = {On the Structure of a Family of Minimum Weighted
Cuts in a Graph},
	booktitle = {Studies in Discrete Optimization},
	editor = {A. A. Fridman},
	publisher = {Nauka publishers},
	address = {Moscow},
	year = 1976,
	pages = {290-306}}

@incollection{Dinic:Scaling,
        author = {E.A. Dinic},
        title = {The bitwise residual decreasing method and transportation
type problems},
        booktitle =  {Studies in  Discrete  Mathematics},
        editor = {A. A. Fridman},
        publisher ={ Nauka publishers},
        city = { Moscow},
        year = {1973},
        pages = {46--57},
        notes = {in Russian}
}

@ARTICLE{Dinitz:BlockingFlow,
author = "E. A. Dinitz",
title = "{Algorithm for Solution of a Problem of Maximum Flow in
Networks with Power Estimation}",
JOURNAL ="Soviet Math. Dokl.",
volume = 11,
year = 1970,
PAGES = "1277-1280"}

@article{Dixon:MST,
	author = {Brandon Dixon and Monika Rauch and Robert E.
Tarjan},
	title = {Verification and Sensitivity Analysis of Minimum
Spanning Trees in Linear Time},
	journal = sicomp,
	year = 1992,
	volume = 21,
	number = 6,
	pages = {1184-1192}}

@article{Dumais:LSI,
	author = {Scott Deerwester and Susan Dumais and George Furnas
and Thomas K. Landauer and Richard Harshman},
	title = {Indexing by Latent Semantic Analysis},
	journal = {Journal of the American Society for Information
Science},
	volume = {41},
	number = {6},
	pages = {391--407},
	year = {1990}}

@article{Alon:ColorCoding,
    author = "Noga Alon and Raphy Yuster and Uri Zwick",
    title = "Color-Coding",
    journal = "Electronic Colloquium on Computational Complexity (ECCC)",
    volume = "1",
    number = "009",
    year = "1994",
    note = "Full paper appears in J.ACM 42:4, July 1995, 844-856",
    url = "citeseer.ist.psu.edu/alon95colorcoding.html" }

@article{Dyer:volume,
	author = {M. E. Dyer and Alan M. Frieze and Ravi Kannan},
	title = {A Random Polynomial Time Algorithm for Approximating
		  the volume of Convex Bodies},
	journal = jacm,
	volume = 38,
	pages = {1--17},
	year = {1991}}

@article{Elias:Maxflow,
	author = {P. Elias and A. Feinstein and C. E. Shannon},
	title = {note on Maximum Flow Through a Network},
	journal = {{IRE} Transactions on Information Theory {IT-2}},
	pages = {117-199},
	year = 1956}

@article{Edmonds:Flow,
	author = {Jack Edmonds and Richard M. Karp},
	title = {Theoretical Improvements in Algorithmic Efficiency
for Network Flow Problems},
	journal = jacm,
	volume = 19,
	pages = {248--264},
	year = 1972}

@article{Edmonds:Matroid,
	author = {Jack Edmonds},
	title = {Matroids and the Greedy Algorithm},
	journal = mp,
	volume = 1,
	pages = {126--136},
	year = 1971}

@article{Edmonds:Packing,
	author = {Jack Edmonds},
	title = {Minimum Partition of a Matroid into Independents
Subsets},
	journal = {Journal of Research of the National Bureau of
Standards},
	year = {1965},
	pages = {67--72},
	volume = {69},
	series = {B}}

@incollection{Edmonds:Branchings,
	author = {Jack Edmonds},
	title = {Edge-disjoint Branchings},
	booktitle = {Combinatorial Algorithms},
	editor = {R. Rustin},
	publisher = {Algorithmics Press},
	address = {New York},
	year = {1972},
	pages = {91--96}}

@article{Edwards:Coloring,
        author = {Keith Edwards},
	title = {The Complexity of Colouring Problems on Dense Graphs},
	journal = {Theoretical Computer Science},
	volume = {43},
	year = {1986},
	pages = {337--343}}

@inproceedings{Eppstein:Sparsification,
	author = {David Eppstein and Zvi Galil and Giuseppe F.
Italiano and Amnon Nissenzweig},
	title = {Sparsification---A Technique for Speeding up
Dynamic Graph Algorithms},
	crossref = {FOCS92},
	pages = {60-69}}

@article{Erdos:RandomGraphs,
	author = erdos # { and } # renyi,
	title = {On Random Graphs {I}},
	year = 1959,
	journal = {Publ. Math. Debrecen},
	volume = 6,
	pages = {290-297}}

@Article{Erdos:Connectivity,
  author = 	 erdos # { and } # renyi,
  title = 	 {On the Strength of Connectedness of a Random Graph },
  journal = 	 {Acta Mathematica Acad. Sci. Hungar.},
  year = 	 {1961},
  volume = 	 {12},
  pages = 	 {261--267},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@article{Eswaran:Augmentation,
	author = {K. P. Eswaran and Robert E. Tarjan},
	title = {Augmentation Problems},
	journal = sicomp,
	year = 1976,
	volume = 5,
	pages = {653--665}}

@Book{Even:GraphAlgorithms,
  author = 	 {Shimon Even},
  title = 	 {Graph Algorithms},
  publisher = 	 {Computer Science Press},
  year = 	 1979,
  address =	 {Potomac, MD}
}

@ARTICLE{Even:Flow,
author = "Shimon Even and Robert E. Tarjan",
title = "{Network Flow and Testing Graph Connectivity}",
JOURNAL = sicomp,
volume = 4,
year = 1975,
PAGES = "507-518"}

@inproceedings{Feder:Compression,
	author = {Tomas Feder and Rajeev Motwani},
	title = {Clique Partitions, Graph Compression and Speeding-up
		Algorithms},
	crossref = {STOC91},
	pages = {123--133},
	note = {Journal version in {\em Journal of Computer and System Sciences}.}
	}

@inproceedings{Feder:Matroid,
	author = {Tomas Feder and Milena Mihail},
	title = {Balanced Matroids},
	crossref = {STOC92},
	pages = {26--38}}

@book{Feller,
	author = {William Feller},
	title = {An Introduction to Probability Theory and its
Applications},
	edition = {third},
	volume = 1,
	publisher = {John Wiley \& Sons},
	address = {New York},
	year = 1968}

@inproceedings{FGLSS,
	author = {U. Feige and Shafi Goldwasser and }
 # lovasz # { and S. Safra and Mario Szegedy},
	title = {Approximating clique is almost {NP}-complete},
	crossref = {FOCS91},
	pages ={2--12}}

@inproceedings{Feige:2SAT,
 author = {U. Feige and Michel X. Goemans},
title = { Approximating the value of 2-Prover proof systems, with
                  applications to MAX-2SAT and MAX-DICUT},
booktitle = istcs95,
year  = 1995,
 pages ={182--189}}

@article{Floyd,
	author = {Robert W. Floyd},
	title = {Algorithm 97: Shortest path},
	journal = {Communications of the ACM},
	year = 1962,
	volume = 5,
	pages = {345}}

@article{Floyd:Median,
	author = {Robert W. Floyd and Ronald L. Rivest},
	title = {Expected Time Bounds for Selection},
	journal = cacm,
	volume = 18,
	number = 3,
	pages = {165-172},
	year = 1975}

@article{FlynnHS91,
	author = {S. Flynn Hummel and E. Schonberg},
	title = {Low-Overhead Scheduling of Nested Parallelism},
	journal = {IBM Journal of Research and Development},
	volume = {35(5/6)},
	pages = {743--765},
	year = 1991}

@article{FlynnHS92,
	author = {S. Flynn Hummel and  E. Schonberg and L. E. Flynn},
	title = {Factoring:  A Practical and Robust Method for
	Scheduling Parallel Loops},
	journal = cacm,
	volume = 35,
	number = 8,
	pages = {90--101},
	year = 1992}

@article{Ford:Maxflow,
	author = {Ford, Jr., Lester R. and Delbert~R. Fulkerson},
	title = {Maximal Flow Through a Network},
	JOURNAL = {Canadian Journal of Mathematics},
	volume = 8,
	year = 1956,
	PAGES = {399-404}}

@book{Ford:FlowBook,
	author = {Ford, Jr., Lester R. and Delbert~R. Fulkerson},
	title = {Flows in Networks},
	year = 1962,
	publisher = {Princeton University Press},
	address = {Princeton, New Jersey}}

@article{Frank:Augmentation,
	author = frank,
	title = {Augmenting graphs to meet edge connectivity
  requirements},
	journal = {SIAM Journal on Discrete Mathematics},
	volume = 5,
	year = 1992,
	number =1,
	pages={25--53},
	note = prelim # FOCS90
	}

@article{FranklRodl,
        author = {P. Frankl and V. Rodl},
	title = {Forbidden Intersections},
	journal = {Transactions of the American Mathematical
	Society},
	volume = 300,
	pages = {259--286},
	year = 1994}

@article{Fredman:Fibonacci,
	author = {Michael L. Fredman and Robert E. Tarjan},
	title = {Fibonacci Heaps and their Uses in Improved Network
		Optimization Algorithms},
	journal = jacm,
	year = 1987,
	volume = 34,
	number = 3,
	pages = {596--615}
	}

@inproceedings{Fredman:MST,
	author = {Michael Fredman and D. E. Willard},
	title = {Trans-dichotomous Algorithms for Minimum
		Spanning Trees and Shortest Paths},
	crossref = {FOCS90},
	pages = {719--725}}

@article{Fredman:Paths,
	author = {Michael L. Fredman},
	title = {New Bounds on the Complexity of the Shortest Path
		Problem},
	journal = sicomp,
	year = 1976,
	volume = 5,
	pages = {83--89}}

@article{Frederickson:MST,
	author = {G. N. Frederickson},
	title = {Data Structures for On-line Updating of Minimum
Spanning Trees},
	journal = sicomp,
	year = 1984,
	volume = 14,
	pages = {781--798}}

@Article{Frederickson:ShortestPaths,
  author = 	 "Greg N. Frederickson",
  title = 	 "Fast Algorithms for Shortest Paths in Planar Graphs,
		  with Applications",
  journal =  sicomp,
  year =	 1987,
  volume =	 16,
  number =	 6,
  pages =	 "1004-1022",
  month =	 dec
}

@book{Frakes:IR,
	editor = {William B. Frakes and Ricardo Baeza-Yates},
	title = {Information Retrieval: Data Structures and Algorithms},
	publisher = {Prentice Hall},
	address = {Englewood Cliffs, New Jersey},
	year = 1992}

@Unpublished{Frank:Mincut,
  author = 	 frank,
  title = 	 "On the Edge-Connectivity Algorithm of {Nagamochi}
		  and {Ibaraki}",
  note = 	 "Labarotoire Artemis, IMAG, Universit\'e J. Fourier,
		  Grenoble",
  year =	 1994,
  month =	 mar,
}

@incollection{Frank:Submodularity,
	author = frank,
	title = {Applications of submodular functions},
	booktitle= {Surveys in Combinatorics},
	series = {London Math. Society Lecture notes},
	number = 187,
	editor = {K. Walker},
	publisher = {Cambridge},
	year = 1993,
	pages = {85--36}
	}

@InCollection{Frank:PathSurvey,
  author = 	 {Andr\'as Frank},
  title = 	 {Packing Paths, Circuits, and Cuts---A Survey},
  booktitle =    {Paths, Flows, and VLSI Layout},
  chapter = 	 {4},
  publisher = 	 {Springer-Verlag},
  year = 	 {1990},
  editor = 	 {Bernhard Korte and } #  lovasz # { and Hans J\"urgen
                  Pr\"omel and Alexander Schrijver},
  volume = 	 {9},
  series = 	 {Algorithms and Combinatorics},
  address = 	 {Heidelberg},
}

@article{Frederickson,
	author = {Gary N. Frederickson},
	title = {Planar Graph Decomposition and All Pairs Shortest Paths},
	journal = jacm,
	year = 1991,
	volume = 38,
	number = 1,
	pages = {162--204}}

@article{Frieze:Paths,
	author = {Alan M. Frieze},
	title = {Minimum Paths in Directed Graphs},
	journal = {Operations Research Quarterly},
	publisher = {Pergamon Press},
	year = 1977,
	volume = 28}

@Article{Jerrum:EasyColoring,
  author = 	 {Mark R. Jerrum},
  title = 	 {A very simple algorithm for estimating the number of
                  $k$-colourings of a low-degree graph},
  journal = 	 {Random Structures and Algorithms},
  year = 	 1995,
  volume =	 7,
  pages =	 {157--165}
}

@unpublished{FriJer,
	author = {Allan Frieze and Mark Jerrum},
	title = {Improved Approximation Algorithms for {MAX} {$k$-CUT}
and {MAX} {BISECTION}},
	note = {Manuscript.},
	month = jun,
	year = 1994}

@article{FriezeGrimmet:Paths,
	author = {Alan M. Frieze and G.~R. Grimmet},
	title = {The Shortest-path Problem for Graphs with
		Random Arc-lengths},
	journal = {Discrete Applied Mathematics},
	year = 1985,
	volume = 10,
	pages = {57--77}}

@InProceedings{Frieze:Regularity,
  title =        "The Regularity Lemma and Approximation Schemes for
                 Dense Problems",
  author =       "Alan M. Frieze and Ravi Kannan",
  pages =        "12--20",
crossref={FOCS96},
  references =   "\cite{JALGO::AlonDLRY1994} \cite{STOC::AroraKK1995}
                 \cite{FOCS::AroraLMSS1992} \cite{STOC::Broder1986}
                 \cite{SODA::DyerFJ1994} \cite{TCS::GareyJS1976}
                 \cite{SICOMP::JerrumS1989}
                 \cite{JCSS::PapadimitriouY1991}",
}

@unpublished{Furer:Coloring,
        author={Martin F{\"u}rer},
	title = {Improved Hardness Results for
Approximating the Chromatic Number},
	year = 1994,
	note = {Private Communication\typeout{find Furer Paper}},
	howpublished = {Pennsylvania State University}}

@book{Garey:NP,
	author = {Michael R. Garey and David S. Johnson},
	title = {Computers and Intractability: A Guide to the Theory
of {NP}-Completeness},
	year = 1979,
	publisher = {W. H. Freeman and Company},
	address = {San Francisco}}

@article{Gabber,
	author = {O. Gabber and Zvi Galil},
	title = {Explicit Construction of Linear-Sized
Superconcentrators},
	journal = JCSS,
	volume = 22,
	pages = {407--420},
	year = 1981}

@article{Gabow:Connectivity,
	author = {Harold N. Gabow},
	title = {A Matroid Approach to Finding Edge Connectivity
and Packing Arborescences},
	journal = JCSS,
	volume = {50},
	number = {2},
	month = apr,
	year = {1995},
	note = prelim # STOC91,
	pages = {259--273}}

@Article{Gabow:LCA,
  author = 	 gabow # and # tarjan,
  title = 	 "A Linear Time Algorithm for a Special Case of
		  Disjoint Set Union",
  journal =  JCSS,
  year =	 1985,
  volume =	 30,
  pages =	 "209--221"
}

@inproceedings{Gabow:MST0,
	author = {Harold N. Gabow and  Zvi Galil and T. H. Spencer},
	title = {Efficient Implementation of Graph Algorithms
Using Contraction},
	crossref = {FOCS84},
	pages = {347--357}}

@article{Gabow:MST,
	author = {Harold N. Gabow and Zvi Galil and T. H. Spencer and
Robert E. Tarjan},
	title = {Efficient Algorithms for Finding Minimum Spanning
Tree in Undirected and Directed Graphs},
	journal = COMB,
	volume = 6,
	year = 1986,
	pages = {109-122}}

@article{Gabow:Packing,
	author = {Harold N. Gabow and Herbert H. Westermann},
	title = {Forests, Frames, and Games: Algorithms for
Matroid Sums and Applications},
	journal = ALGO,
	year = 1992,
	volume = 7,
		  number=5,
	pages = {465--497},
	publisher = {Springer-Verlag New York Inc.}
	}

@inproceedings{Gabow:Poset,
	author = {Harold N. Gabow},
	title = {Applications of a Poset Representation to Edge
Connectivity and Graph Rigidity},
crossref={FOCS91},
	pages = {812-821}}

@techreport{Gabow:Poset-tech,
	author = {Harold N. Gabow},
	title = {Applications of a Poset Representation to Edge
Connectivity and Graph Rigidity},
	institution={University of Colorado Department of Computer Science},
	number = {CU--CS--545--91},
	year = 1991}

@inproceedings{Gabow:Splitting,
	author = {Harold N. Gabow},
	title=  {Efficient Splitting Off Algorithms for
  Graphs},
	crossref = {STOC94},
	pages = {696--705}
	}

@article{Gabow:Scaling,
	author = {Harold N. Gabow and Robert E. Tarjan},
	title = {Faster Scaling Algorithms for Network Problems},
	journal = sicomp,
	year = 1989,
	volume = 18,
	number = 5,
	pages = {1013--1036}
}

@inproceedings{Gabow:SubmodularScaling,
	author = {Harold N. Gabow},
	title = {A Framework for Cost-scaling Algorithms for
Submodular Flow Problems},
	crossref = {FOCS93},
	pages = {449-458}}

@inproceedings{Gabow:SurvivableNetwork,
	author = {Harold N. Gabow and Michel X. Goemans and David P.
Williamson},
	title = {An Efficient Approximation Algorithm for the
Survivable Network Design Problem},
	booktitle = proc # { Third {MPS} Conference on
Integer Programming and Combinatorial Optimization},
	pages = {57-74},
	year = 1993}

@article{GalilPan,
	author = {Zvi Galil and Victor Pan},
	title = {Improved Processor Bounds for Combinatorial
Problems in {$\RNC$}},
	journal = COMB,
	volume = 8,
	pages = {189-200},
	year = 1988}

@inproceedings{Gazit:Proc-Connectivity,
	author = {H. Gazit},
	title = {An Optimal Randomized Parallel Algorithm for
Finding Connected Components in a Graph\typeout{GAZIT PAGES}},
	booktitle = FOCS86,
	publisher = ieeep,
	year = 1986}

@misc{Goldberg:comm,
        author = {Andrew Goldberg},
	title = {Personal Communication},
	month= oct,
	year = 1997}

@inproceedings{Goldberg:CapacitatedBlocking,
  author = 	 {Andrew Goldberg and Satish Rao},
  title = 	 {Beyond the Flow Decomposition Barrier},
  crossref = {FOCS97},
  pages = {2--11}
}

@inproceedings{Goldberg:SparseBlocking,
  author = 	 {Andrew Goldberg and Satish Rao},
  title = 	 {Flows in Undirected Unit Capacity Networks},
  crossref = {FOCS97},
pages = {32--35}
}

@Article{Goldberg:Tapestry,
  author = 	 {Goldberg, David and  Oki, Brian and  Nichols, David and  Terry, Douglas B.},
  title = 	 {Using Collaborative Filtering
       to Weave an Information Tapestry},
  journal = 	 cacm,
  year = 	 1992,
  volume =	 35,
  number =	 12,
  month =	 dec,
  pages =	 {61--70}
}

@Article{Gazit:Connectivity,
         author =       "H. Gazit",
         title =        "An Optimal Randomized Parallel Algorithm for Finding
                        the Connected Components of a Graph",
         journal =      sicomp,
         year =         "1991",
         volume =       "20",
         number =       "6",
         pages =        "1046--1067",
	  note = prelim # FOCS86,
         abstract =         "The expected running time of this algorithm is
                        $O(\log{n})$ with $O((m+n)/\log{n})$ processors, where
                        $n$ is the number of vertices and $m$ is the number of
                        edges. It uses $O(m+n)$ space. The algorithm is optimal
                        in the time-processor product sense, as well as in
                        space complexity.",
       }

@inproceedings{Gibbons:Distinct,
       author = {Phillip Gibbons},
       title = {Distinct Sampling for Highly-Accurate Answers to
                  Distinct Values Queries and Event Reports},
       booktitle = {27th VLDB Conference},
       year = 2001}

@techreport{Gibbons:QRQW,
	author = {Phillip B. Gibbons and Vijaya Ramachandran},
	title = {{QRQW}: Accounting for concurrency in {PRAM}s and
asynchronous {PRAM}s},
	institution = {AT\&T Bell Laboratories},
	number = {BL011211-930331-05TM},
	year = 1993}

@inproceedings{Gillman:Expander,
        author = {D. Gillman},
        title = {A {Chernoff} Bound for Random Walks on Expanders},
        crossref = {FOCS93},
        pages = {680--691}}

@misc{Goemans:Private,
	author = {Michel X. Goemans and {\'E}va Tardos and David P. Williamson},
	note = {Personal Communication.},
	year = {1994}}

@incollection{Goemans:PrimalDual,
	author = {Michel X. Goemans  and David P. Williamson},
	title = {The primal-dual method for
  approximation algorithms and its application to network design
problems},
	booktitle={Approximation Algorithms for NP-hard Problems},
	editor ={Dorit S. Hochbaum},
	publisher = {PWS
  Publishing Co.},
	address = {Boston, MA},
	year = 1997
	}

@article{Goemans:Parsimonious,
	author = {Michel X. Goemans and Dimitris J. Bertsimas},
	title = {Survivable Networks, Linear Programming Relaxations
and the Parsimonious Property},
	journal = mp,
	volume =60,
	year = 1993,
	pages = {145--166}}

@article{Gilbert:Separator,
author= "John R. Gilbert and Joan P. Hutchinson and Robert E. Tarjan",
title = "A separator theorem for graphs of bounded genus",
journal = JALG,
volume =  5,
year = 1984,
pages= "375-390"}

@inproceedings{GW:maxcut,
	author = {Michel X. Goemans and David P. Williamson},
	title = {$.878$-Approximation Algorithms for {MAX CUT} and
{MAX 2SAT}},
	crossref = {STOC94},
	pages = {422-431}}

@Article{GW:maxcut,
  author = 	 {Michel X. Goemans and David P. Williamson},
  title = 	 {Improved Approximation Algorithms for Maximum Cut and
     Satisfiability Problems Using Semidefinite Programming},
  journal = 	 jacm,
  year = 	 {1995},
  volume = 	 {42},
  number = 	 {6},
  month = 	 may,
  pages = 	 {1115--1145},
  note = 	 prelim # STOC94 # { pages 422--431. ACM, ACM Press, May 1994},
}

@Article{Goldberg:Paths,
  author =       "Andrew V. Goldberg",
  title =        "Scaling Algorithms for the Shortest Paths Problem",
  journal =      "SIAM Journal on Computing",
  volume =       "24",
  number =       "3",
  pages =        "494--504",
  month =        jun,
  year =         "1995",
  coden =        "SMJCAT",
  ISSN =         "0097-5397 (print), 1095-7111 (electronic)",
  mrclass =      "68R10 (05C85 68Q20)",
  mrnumber =     "96c:68151",
  bibdate =      "Sat Dec 5 17:26:53 MST 1998",
  url =          "http://epubs.siam.org/sam-bin/dbq/article/23117",
  acknowledgement = ack-nhfb,
}
@TECHREPORT{Goldberg:GlobalUpdates,
author = "A. V. Goldberg and Robert Kennedy",
title = "{Global Price Updates Help}",
INSTITUTION = "Department of Computer Science, Stanford University",
NUMBER = "STAN-CS-94-1509",
note = "To appear in SIAM J.\ on Discrete Math.",
year = 1994}

@article{Goldberg:Maxflow,
	author = {Andrew V. Goldberg and Robert E. Tarjan},
	title = {A New Approach to the Maximum Flow Problem},
	journal = jacm,
	volume = 35,
	year = 1988,
	pages = {921-940}}

@InProceedings{Goldreich:Regularity,
  title =        "Property Testing and its Connection to Learning and
                 Approximation",
  author =       "Oded Goldreich and Shafi Goldwasser and Dana Ron",
  pages =        "339--348",
  booktitle =    "37th Annual Symposium on Foundations of Computer
                 Science",
  month =        "14--16 " # oct,
  year =         "1996",
  address =      "Burlington, Vermont",
  organization = "IEEE",
  references =   "\cite{JALGO::AlonDLRY1994} \cite{FOCS::AroraFK1996}
                 \cite{STOC::AroraKK1995} \cite{FOCS::AroraLMSS1992}
                 \cite{FOCS::AroraS1992} \cite{STOC::BabaiFLS1991}
                 \cite{FOCS::BellareCHKS1995} \cite{FOCS::BellareGS1995}
                 \cite{STOC::BellareGLR1993} \cite{STOC::BellareS1994}
                 \cite{STOC::Ben-David1992} \cite{JCSS::BlumLR1993}
                 \cite{JACM::BlumerEHW1989} \cite{TCS::Edwards1986}
                 \cite{FOCS::FeigeGLSS1991} \cite{FOCS::FriezeK1996}
                 \cite{STOC::GemmellLRSW1991}
                 \cite{STOC::KearnsMRRSS1994} \cite{JACM::PittV1988}
                 \cite{JACM::PittW1993} \cite{TCS::RivestV1976}
                 \cite{FOCS::Rubinfeld1994}
                 \cite{SICOMP::RubinfeldS1996} \cite{CACM::Valiant1984}
                 \cite{FOCS::Yao1987}",
}

@inproceedings{Goldschmidt:Multicut,
	author = {Oliver Goldschmidt and Dorit Hochbaum},
	title = {Polynomial Algorithm for the {$k$}-cut Problem},
	booktitle = FOCS88,
	year = 1988,
	pages = {444-451},
	publisher = ieeep}

@inproceedings{Schmidt:Kway,
       author={ Jeanette Schmidt and Alan Siegel and  Aravind Srinivasan},
      title = {Chernoff-Hoeffding Bounds for Applications with Limited
                  Independence},
       crossref={SODA93}}

@book{Golub:Matrix,
	author = {Gene H. Golub and C. F. Van Loan},
	title = {Matrix Computations},
	publisher = {Johns Hopkins University Press},
	address = {Baltimore, MD},
	year = 1983}

@article{Gomory:FlowTree,
	author={Ralph E. Gomory and Tien Chung Hu},
	title= {Multi-Terminal Network Flows},
	journal = {Journal of the Society of Industrial and Applied
			Mathematics},
	month = dec,
	year = 1961,
	volume = 9,
	Number = 4,
	pages = {551-570}}

@article{Graham:MST,
	author = {R. L. Graham and P. Hell},
	title  = {On the History of the Minimum Spanning Tree
Problem},
	journal = {Annals of the History of Computing},
	volume = 7,
	year = 1985,
	pages = {43--57}}

@book{Grotschel:Optimization,
	author = {Martin Gr{\"o}tschel and } # lovasz # { and
Alexander Schrijver},
	title = {Geometric Algorithms and Combinatorial Optimization},
	series = {Algorithms and Combinatorics},
	volume = 2,
	editors = {R. L. Graham and B. Korte and L{\'a}szl{\'o} Lov{\'}asz},
	publisher = sv,
        address={Berlin},
	year = 1988}

@article{GLS,
	author = grotschel # { and } # lovasz # { and
Alexander Schrijver},
	title = {The ellipsoid method and its consequences in
combinatorial  optimization},
	journal = COMB,
	volume= 1,
	pages={169--197},
	year = 1981}

@Article{Gusfield:TreePacking,
  author = 	"Dan Gusfield",
  title = 	"Connectivity and Edge Disjoint Spanning Trees",
  journal = 	"ipl",
  year = 	"1983",
  volume = 	"16",
  pages = 	"87--89",
  OPTmonth = 	"",
  OPTnote = 	""
}

@InProceedings{Henzinger:DynamicMincut,
  author = 	 "Monika Rauch Henzinger",
  title = 	 "Approximating Minimum Cuts under Insertions",
  crossref =	 "icalp95",
  pages =	 "280--291"
}

@Inproceedings{Henzinger:DynamicConnectivity-Conf,
  author = 	 "Monika Rauch Henzinger and Valerie King",
  title = "Randomized Dynamic Graph Algorithms with PolyLogarithmic
                  Time per Operation",
  crossref="STOC95",
  pages="519--527"
}

@article{Henzinger:DynamicConnectivity,
  author = 	 "Monika Rauch Henzinger and Valerie King",
  title = "Randomized Dynamic Graph Algorithms with PolyLogarithmic
                  Time per Operation",
  journal = jacm,
  volume = 46,
  number = 4,
  month = jul,
  pages="502-516"
}

@inproceedings{Halperin:Connectivity,
	author = {Shay Halperin and Uri Zwick},
	title = {An Optimal Randomized Logarithmic Time Connectivity
Algorithm for the {EREW PRAM}},
	crossref = {SPAA94},
	pages = {1-10}}

@InProceedings{Halperin:Forests,
  author = 	 "Shay Halperin and Uri Zwick",
  title = 	 "Optimal Randomized {EREW} {PRAM} Algorithms for
		  Finding Spanning Forests and Other Basic Graph
		  Connectivity Problems",
  crossref =	 "SODA96",
  pages =	 "438--447"
}

@article{halldorsson,
	author = {Magnus M. Halld{\'o}rsson},
	title = {A Still Better Performance Guarantee for Approximate Graph Coloring},
	journal = IPL,
	volume = 45,
	pages = {19--23},
	year = 1993}

@inproceedings{Hao:Mincut-conf,
	author = {Jianxiu Hao and James~B. Orlin},
	title = {A Faster algorithm for finding the minimum cut in
a graph},
	crossref = {SODA92},
	pages = {165-174}}

@Article{Hao:Mincut,
       author =       "Jianxiu Hao and James~B. Orlin",
       title =        "A Faster Algorithm for Finding the Minimum Cut in a
                      Directed Graph",
       journal =      "Journal of Algorithms",
       volume =       "17", number = 3, pages = {424-446},
       year =         "1994",
       note = prelim # SODA92
     }

@inproceedings{Hastad:CRCW-conf,
	author = {Johann Hastad},
	title = {Almost Optimal Lower Bounds for Small Depth Circuits},
        crossref = {STOC86},
	pages = {6--20}}

@Article{Hastad:CRCW,
       author =       "Hastad",
       title =        "Almost Optimal Lower Bounds for Small Depth Circuits",
       journal =      "Advances in Computing Research",
       volume =       "5",
       year =         "1989",
       editor = {S. Miscale},
       publisher = {JAI Press},
       address = {Greenwich, CT},
       pages = {143--170},
       note = prelim # STOC96,
     }

@MastersThesis{Hogue:Thesis,
  author = 	 {Andrew Hogue},
  title = 	 {Tree Pattern Inference and Matching for Wrapper Induction on the World Wide Web},
  school = 	 {M.I.T.},
  year = 	 2004,
  month =	 may
}

@mastersthesis { hogue2004,
author = "A. Hogue",
title = "Tree Pattern Inference and Matching for Wrapper Induction on the {W}orld {W}ide {W}eb",
school = "Massachusetts Institute of Technology",
month = "May",
year = "2004"
}

@article{Hassin:paths,
	author = {Refael Hassin and Eitan Zemel},
	title = {On Shortest Paths in Graphs with Random Weights},
	journal = {Mathematics of Operations Research},
	volume = 10,
	number= 4,
	year = 1985,
	month = nov,
	pages = {557--564}
}

@inproceedings{HerlihyLS92,
	author={Maurice Herlihy and B. Lim and Nir Shavit},
	title={Low contention load-balancing on large-scale multiprocessors},
	crossref = {SPAA92},
	pages={219--227}}

@InProceedings{Hill:ReadWear,
  author = 	 {Hill, W.C. and Hollan, J.D. and Wroblewski, D. and
                  McCandless, T.},
  title = 	 {Edit Wear and Read Wear},
  booktitle = 	 {Proceedings of CHI 92 Conference on Human Factors in Computing Systems},
  year =	 1992,
  organization = {ACM},
  address =	 {New York},
  pages =	 {3--9}
}

@Article{HCS,
  author = 	 "D S Hirschberg and A. K. Chandra and D. V. Sarwate",
  title = 	 "Computing Connected Components on Parallel Computers",
  journal =	 cacm,
  year =	 1979,
  volume =	 22,
  number =	 8,
  pages =	 "461--464",
  month =	 aug
}

@article{Hoare:Quicksort,
	author = {C. A. R. Hoare},
	title = {Quicksort},
	journal = {Computer Journal},
	volume = 5,
	number = 1,
	pages = {10--15},
	year = 1962}

@article{Hochbaum:Packing,
	author = {Dorit S. Hochbaum},
	title = {Efficient bounds for the Stable Set, Vertex
Cover, and Set Packing Problems},
	journal = {Discrete Applied Mathematics},
	year = 1983,
	volume = 6,
	pages = {243-254}}

@Article{Hoeffding:Bound,
  author =       "W. Hoeffding",
  title =        "Probability inequalities for sums of bounded random
                 variables",
  journal =      "Journal of the American Statistical Association",
  volume =       "58",
  number =       "301",
  pages =        "13--30",
  month =        mar,
  year =         "1964",
  coden =        "JSTNAL",
  ISSN =         "0162-1459",
}

@book{Hopcroft:Automata,
	author = {John E. Hopcroft and Jeffrey D. Ullman},
	title = {Introduction to Automata Theory, Languages and Computation},
	publisher = {Addison-Wesley},
	series = {Series in Computer Science},
	year = 1979
}

@InProceedings{Hoppe:Evacuation,
       author =       "Bruce Hoppe and Eva Tardos",
       title =        "Polynomial Time Algorithms for Some Evacuation
                      Problems",
        crossref={SODA94}
     }

@article{Ibarra:Knapsack,
        author = {O. H. Ibarra and C. E. Kim},
        title = {Fast Approximation Algorithms for the Knapsack and
		  Sum of Subsets Problems},
	journal = jacm,
	volume = {22},
	number = {4},
	year = {1975},
	pages = {463--468}}

@inproceedings{Impagliazzo:Expander,
	author={Russel Impagliazzo and David Zuckerman},
	title={How to Recycle Random Bits},
	booktitle=FOCS89,
	year=1989,
	pages={222--227}}

@article{Israeli:Matching,
	author = {Amos Israeli and Y. Shiloach},
	title = {An Improved  Parallel Algorithm for Maximal
Matching},
	journal = IPL,
	volume = 22,
	year = 1986,
	pages = {57--60}}

@Article{Itai:Routing,
  author = 	"A. Itai and M. Rodeh",
  title = 	"The Multi-tree Approach to Reliability in Distributed Networks",
  journal = 	"Information and Control",
  year = 	"1988",
  volume = 	"79",
  pages = 	"43--59",
}

@inproceedings{Jakobsson,
	author = {Hakan Jakobsson},
	title = {Mixed-approach Algorithms for Transitive Closure\typout{J:PAGES?}},
	booktitle = PODS91,
	year = 1991,
	pages = {199--205}
}

@Article{Jerrum:RandomGeneration,
  author = 	 jerrum # and # valiant # and # vvazirani,
  title = 	 "Random Generation of Combinatorial Structures from a
Uniform Distribution",
  journal =	 "Theoretical Computer Science",
  year =	 1986,
  volume =	 43,
  pages =	 "169--188"
}

@article{Johnson:SetCover,
	author = {David S. Johnson},
	title = {Approximation Algorithms for Combinatorial
Problems},
	journal = JCSS,
	volume = 9,
	year = 1974,
	pages = {256--278}}

@article{Johnson:StrongPoly,
	author = {David S. Johnson},
	title = {The {NP}-Completeness Column: An Ongoing Guide},
	journal = JALG,
	volume = 8,
	number = 2,
	year = 1987,
	pages = {285--303}}

@incollection{Johnson:Coloring,
        author = {David S. Johnson},
        title = {Worst Case Behavior of Graph Coloring Algorithms},
        booktitle = {Proceedings of the 5th Southeastern Conference on
		  Combinatorics, Graph Theory and Computing},
        series = {Congressus Numerantium},
	number = {X},
        pages = {513--527},
        year = 1974}

@inproceedings{Johnson:Connectivity,
	author = johnson # and # metaxas,
	title = {Connected Components in {$O(\log^{3/2} |V|)$}
Parallel Time for the {CREW} {PRAM}},
        crossref={FOCS91},
        pages = {688-697}}

@article{Johnson,
	author = {Donald B. Johnson},
	title = {Efficient Algorithms for Shortest Paths in
		Sparse Networks},
	journal = jacm,
	year = 1977,
	volume = 24,
	number = 1,
	pages = {1--13}
}

@inproceedings{Johnson:MST,
	author = {Donald B. Johnson and Panagiotis Metaxas},
	title = {A Parallel Algorithm for Computing Minimum
Spanning Trees},
	crossref = {SPAA92},
	pages = {363-372}}
@Article{Jones:Corpus,
  author = 	 {Karen Sparck Jones},
  title = 	 {Report on Building and Using Test Collections Panel,
                  SIGIR 1996},
  journal = 	 {SIGIR Forum},
  year = 	 1996,
  volume =	 30,
  number =	 3,
  pages =	 {5--6}
}

@InProceedings{Kommareddy:Neighbor,
  author = 	 {Christopher Kommareddy and Narendar Shankar and Bobby
                  Bhattacharjee},
  title = 	 {Finding close friends on the internet},
  booktitle = 	 {9th International Conference on Network Protocols},
  year =	 2001,
  editor =	 {Magda El Zarki and Klara Nahrstedt},
  address =	 {Riverside, CA},
  month = 	 nov,
  organization = {IEEE},
  note = 	 {To appear}
}

@inproceedings{Kannan:Counting,
        author = {Ravi Kannan},
        title = {Markov Chains and Polynomial Time Algorithms},
        crossref = {FOCS94},
        pages = {656--671}}

@inproceedings{Kao:TransClosure-conf,
	author = {Min-Yang Kao and Philip N. Klein},
	title = {Towards overcoming the transitive-closure bottleneck:
                 Efficient parallel algorithms for planar digraphs},
	crossref = {STOC90},
	pages = {181--192}}
@Article{Kao:TransClosure,
       author = {Min-Yang Kao and Philip N. Klein},
       title =        {Towards Overcoming the Transitive-Closure Bottleneck:
                      Efficient Parallel Algorithms for Planar Digraphs},
       journal =      {Journal of Computer and System Sciences},
       volume =       47,
       number = 3,
       pages ={459-500},
       month = dec,
       year = 1993,
       note = prelim # STOC90,
     }

@InProceedings{Kannan:Clustering,
  author = 	 {Ravi Kannan and Santosh Vempala and Adrian Vetta},
  title = 	 {On Clusterings. Good, Bad and Spectral},
  crossref =	 {FOCS00},
  key =		 {367--377}
}

@inproceedings{Kaelbling:HierarchicalPlanning,
        author = {Terran Lane and Leslie Pack Kaelbling},
        title = {Toward Hierarchical Decomposition for Planning in
                  Uncertain Environments},
        booktitle = {Workshop on Planning under Uncertainty and
                 Incomplete Information At the 2001 International
                 Joint Conference on Artificial Intelligence
                 (IJCAI-2001)},
        note ={To appear}}


@Article{Karapetian:Coloring,
  author = 	 {Iskandar A. Karapetian},
  title = 	 {On Coloring of Arc Graphs},
  journal = 	 {Dokladi (Reports) of the Academy of Science of the
                  Armenian Soviet Socialist Republic},
  year = 	 1980,
  volume =	 70,
  number =	 5,
  pages =	 {306--311}
}

@InProceedings{Little06,
  author = {Greg Little and Robert C. Miller},
  title = {Translating Keyword Commands into Executable Code},
  booktitle = 	 {Proceedings of the ACM Symposium on User Interface Software
                  and Technology (UIST)},
  year =	 2006
}

@MastersThesis{Sinha:Thesis,
  author = 	 {Vineet Sinha},
  title = 	 {Dynamically Expoloiting Available Metadata for
                  Browsing and Information Retrieval},
  school = 	 {M.I.T.},
  year = 	 2003,
  month =	 sep
}

@Misc{Bose:Private,
  author={Vanu Bose},
  year = {2005},
  note = {Private Communication}
}


@phdthesis{Bose:Thesis,
  author = "Vanu Bose",
  title = "Virtual Radios",
  year = {1999},
  school = {{MIT}},
  url = "citeseer.ist.psu.edu/bose98virtual.html" }

@InProceedings{Feldman:LPTurboCapacity,
  author = 	 {Jon Feldman and Cliff Stein},
  title = 	 {LP Decoding Achieves Capacity},
  crossref =	 {SODA05}
}

@Phdthesis{Veksler:Thesis,
  author = "Olga Veksler",
  title = "Efficient graph-based energy minimization methods in computer vision",
  school = {Department of Computer Science, Cornell University},
  year = "1999",
  url = "citeseer.ist.psu.edu/veksler99efficient.html" }


@inproceedings{Boykov:Mincuts,
    author = "Yuri Boykov and Olga Veksler and Ramin Zabih",
    title = "Fast Approximate Energy Minimization via Graph Cuts",
    booktitle = "{ICCV} (1)",
    pages = "377-384",
    year = "1999",
    url = "citeseer.ist.psu.edu/article/boykov99fast.html" }

@inproceedings{Medard:NetworkCoding,
  author = {Ralf Koetter and Muriel M\'{e}dard},
  title = {An Algebraic Approach to Network Coding},
  year = {2002},
  booktitle={INFOCOM}
}

@InProceedings{Katti:NetworkCoding,
  author = 	 {Sachin Katti and Dina Katabi and Wenjun Hu and Hariharan Rahul and Muriel M\'{e}dard},
  title = 	 {The Importance of Being Opportunistic: Practical Network Coding For Wireless Environments},
  booktitle =	 {The Forty-Third Annual Allerton Conference on Communication, Control, and Computing},
  year =	 2005
}

@inproceedings{Srebro:Markov,
        author={Nati Srebro},
        title={Maximum Lielihood Bounded Tree-Width Markov Networks},
        booktitle={$17^{th}$ Conference on Uncertainty in Artificial
                  Intelligence (UAI)},
        year={2001},
        note={Best student paper}
}

@inproceedings{Karmarkar:BinPack,
	author = {N. Karmarkar and Richard M. Karp},
	title = {An efficient Approximation Scheme for the
		  One-Dimensional Bin-Packing Problem},
	crossref={FOCS82},
	pages = {312--320}}

@Article{Karmarkar:LP,
  author =       "N. Karmarkar",
  title =        "{A New Polynomial-Time Algorithm for Linear
                 Programming}",
  journal =      "Combinatorica",
  volume =       "4",
  number =       "4",
  pages =        "373--395",
  year =         "1984",
}
@incollection{Karp:Parallel,
	author = {Richard M. Karp and Vijaya Ramachandran},
	title = {Parallel Algorithms for Shared Memory Machines},
        crossref = {HandbookTCS},
	pages = {869--932}}

@article{Karp:Matching,
	author = {Richard M. Karp and Eli Upfal and Avi Wigderson},
	title = {Constructing a Perfect Matching is in Random {$\NC$}},
	journal = COMB,
	volume = 6,
	number = 1,
	year = 1986,
	pages = {35--48}}

@inproceedings{Karp:Recurrence,
	author = {Richard M. Karp},
	title = {Probabilistic Recurrence Relations},
	pages = {190--197},
	crossref = {STOC91}}

@article{Karp:Reliability,
	author = {Richard M. Karp and Michael G. Luby},
	title = {Monte Carlo Algorithms for Planar Multiterminal
Network Reliability Problems},
	journal = {Journal of Complexity},
	volume = 1,
	year = 1985,
	pages = {45--64}}

@Article{Karp:DNF0,
  author = 	 "Richard M. Karp and Michael Luby",
  title = 	 "{M}onte {C}arlo Algorithms for Planar Multiterminal
		  Network Reliability Problems",
  journal =	 "Journal of Complexity",
  year =	 1985,
  volume =	 1,
  pages =	 "45--64"
}

@article{Dagum:BayesNets,
 author = {Paul Dagum and Michael Luby},
 title = {Approximating probabilistic inference in Bayesian belief networks is NP-hard},
 journal = {Artif. Intell.},
 volume = {60},
 number = {1},
 year = {1993},
 issn = {0004-3702},
 pages = {141--153},
 doi = {http://dx.doi.org/10.1016/0004-3702(93)90036-B},
 publisher = {Elsevier Science publishers Ltd.},
 address = {Essex, UK},
 }

@Article{Dyer:Gibbs,
  author = 	 {Martin Dyer and Alistair Sinclair and Eric Vigoda and Dror Weitz},
  title = 	 {Mixing in time and space for lattice spin systems: A combinatorial view},
  journal = 	 {Random Structures and Algorithms},
  year = 	 2004,
  volume =	 24,
  number =	 4,
  pages =	 {461--479}
}

@inproceedings{Tardos:HierarchicalFacilityLocation,
 author = {Zoya Svitkina and  and Eva Tardos},
 title = {Facility location with hierarchical facility costs},
 booktitle = {SODA '06: Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete algorithm},
 year = {2006},
 isbn = {0-89871-605-5},
 pages = {153--161},
 location = {Miami, Florida},
 doi = {http://doi.acm.org/10.1145/1109557.1109576},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }


@article{Karp:DNF,
	author = {Richard M. Karp and Michael Luby and N. Madras},
	title = {{M}onte {C}arlo Approximation Algorithms for Enumeration
Problems},
	journal = JALG,
	volume = 10,
	number = 3,
	year = 1989,
	month = sep,
	pages = {429--448}}

@article{Karzanov:cactus,
	author = {Alexander~V. Karzanov and E.~A. Timofeev},
	title = {Efficient Algorithm for Finding All Minimal Edge Cuts of a
  Non-Oriented Graph},
	journal = {Cybernetics},
	volume = 22,
	year = 1986,
	pages = {156--162}}

@INCOLLECTION{Karzanov:Flow,
author = "Alexander~V. Karzanov",
title = "O Nakhozhdenii Maksimal$'$nogo Potoka v Setyakh
Spetsial$'$nogo Vida i Nekotorykh Prilozheniyakh",
booktitle = "Matematicheskie Voprosy Upravleniya Proizvodstvom",
volume = 5,
publisher = "Moscow State University Press, Moscow",
note = "In Russian; title translation:
On Finding Maximum Flows in a Network with Special
Structure and Some Applications",
year = 1973}

@phdthesis{Kerr,
	author = {L. R. Kerr},
	title = {The Effect of Algebraic Structure on the Computational
		Complexity of Matrix Multiplications},
	school = {Cornell University},
	year = 1970
}

@inproceedings{sanjeev,
	author = {Sanjeev Khanna and Natan Linial and S. Safra},
	title = {On the Hardness of Approximating the Chromatic Number},
	booktitle = {Proceedings $2^{nd}$ Israeli Symposium on Theory
and Computing Systems},
	pages = {250--260},
	year =1992}

@InProceedings{Khanna:ApproxCSP,
  title =        "A Complete Classification of the Approximability of
                 Maximization Problems Derived from {Boolean} Constraint
                 Satisfaction",
  author =       "Sanjeev Khanna and Madhu Sudan and David P.
                 Williamson",
  pages =        "11--20",
  booktitle =    "Proceedings of the Twenty-Ninth Annual {ACM} Symposium
                 on Theory of Computing",
  month =        "4--6 " # may,
  year =         "1997",
  address =      "El Paso, Texas",
  references =   "\cite{FOCS::AroraLMSS1992} \cite{JCSS::Creignou1995}
                 \cite{STOC::FederV1993} \cite{JACM::GoemansW1995}
                 \cite{STOC::KhannaM1996} \cite{FOCS::KhannaMSV1994}
                 \cite{JACM::Ladner1975} \cite{JCSS::PapadimitriouY1991}
                 \cite{STOC::Schaefer1978} \cite{FOCS::TrevisanSSW1996}
                 \cite{JALGO::Yannakakis1994}",
}

@article{Khuller:Connectivity,
	author = {Samir Khuller and Baruch Schieber},
	title = {Efficient Parallel Algorithms for Testing
Connectivity and Finding Disjoint {$s$-$t$} Paths in Graphs},
	journal = sicomp,
	month = apr,
	year = 1991,
	volume = 20,
	number = 2,
	pages = {352--375}}

@article{Khuller:Steiner,
	author = {Samir Khuller and Uzi Vishkin},
	title = {Biconnectivity Approximations and Graph Carvings},
	journal = jacm,
	year = 1994,
	volume = 41,
	number = 2,
	month = mar,
	note = prelim # STOC92,
	pages = {214-235}}

@InProceedings{Khuller:UniformConnectivity,
  author = 	 {Samir Khuller and Balaji Raghavachari},
  title = 	 {Improved Approximation Algorithms for Uniform
                  Connectivity Problems},
  crossref =	 {STOC95},
  pages =	 {1--10}
}

@inproceedings{King:Flow-conf,
	author = {Valerie King and Satish Rao and Robert E. Tarjan},
	title = {A Faster Deterministic Maximum Flow Algorithm},
	crossref = {SODA92},
	pages = {157--164}}
@Article{King:Flow,
	author = {Valerie King and Satish Rao and Robert E. Tarjan},
       title =        "A Faster Deterministic Maximum Flow Algorithm",
       journal =      "Journal of Algorithms",
       volume =       "17", number = 3, pages = {447-474}, month = nov,
       year =         "1994",
       note = prelim # SODA92,
     }

@unpublished{King:MST,
	author = {Valerie King},
	title = {A Simpler Algorithm for Verifying Minimum
Spanning Trees},
	year = 1993}

@inproceedings{Klein:ExcludedMinors,
author =  "Philip Klein and Satish Rao and Serge Plotkin",
title = "Excluded Minors, Network Decomposition, and Multicommodity Flow",
crossref = {STOC93},
pages = {682--690},
annote={ Proves some results
regarding max-flow min-cut for multicommodity flow on minor-excluded
graphs...  This, in turn, gives some results on finding seps in such
graphs.} }

@inproceedings{Klein:Concurrent,
	author = {Philip N. Klein and Clifford Stein and {\'E}va Tardos},
	title = {{L}eighton-{R}ao Might be Practical: Faster
Approximation Algorithms for Concurrent Flow with Uniform Capacities},
	crossref = {STOC90},
	pages = {310-321}}

@article{Klein:Flow,
	author = {Philip Klein and Serge A. Plotkin and Clifford Stein
and {\'E}va Tardos},
	title = {Faster Approximation Algorithms for the Unit Capacity
Concurrent Flow Problem with Applications to Routing and Finding Sparse Cuts},
	journal = sicomp,
	volume = 23,
	number = 3,
	year = 1994,
	pages = {466--487},
	note = prelim # STOC90
	}

@inproceedings{Klein:MST,
	author = {Philip N. Klein and Robert E. Tarjan},
	title = {A Randomized Linear-time Algorithm for Finding
Minimum Spanning Trees},
	crossref = {STOC94},
	pages = {9--15}}

@InProceedings{Klein:PlanarShortestPaths,
  author = 	 {Philip N. Klein and Satish Rao and Monika H. Rauch and S.
     Subramanian},
  title = 	 {Faster shortest-path algorithms for planar graphs},
  crossref =	 {STOC94},
  pages =	 {27--37}
}

@article{kneser,
	author ={M. Kneser},
	title = {Aufgabe 300},
	journal = {Jber.~Deutsch.~Math.-Verein.},
	volume = 58,
	year = 1955}

@article{Komlos:MST,
	author = {J. Koml\'{o}s},
	title = {Linear Verification for Spanning Trees},
	journal = COMB,
	year = 1985,
	volume = 5,
	number = 1,
	pages = {57--65}}

@inproceedings{Kortsarz:DenseGraph,
        author = {Guy Kortsarz and David Peleg},
	title = {On Choosing a Dense Subgraph},
	crossref = {FOCS93},
	pages = {692--701}
        }

@techreport{Knuth:Matroid,
	author = {Donald E. Knuth},
	title = {Matroid Partitioning},
	institution = {Stanford University},
	year = 1973,
	number = {STAN-CS-73-342}}

@incollection{Knuth:NonuniformRandom,
	author = {Donald E. Knuth and Andrew C. Yao},
	title = {The Complexity of Nonuniform Random Number
Generation},
	pages  = {357--428},
	booktitle = {Algorithms and Complexity: New Directions and
Recent Results},
	editor = {Joseph F. Traub},
	publisher = {Academic Press},
	address = {New York},
	year = 1976}

@article{Knuth:Paths,
	author = {Donald E. Knuth},
	title = {A Generalization of {D}ijkstra's Algorithm},
	journal = {Information Processing Letters},
	year = 1977,
	volume = 6,
	pages = {1--5}}

@techreport{Knuth:RandomMatroid,
	author = {Donald E. Knuth},
	title = {Random Matroids},
	institution = {Stanford University},
	year = 1974,
	number = {STAN-CS-74-453}}

@book{Knuth:Book1,
	author = {Donald E. Knuth},
	series = {The Art of Computer Programming},
	title = {Fundamental Algorithms},
	volume = 1,
	edition = {2nd},
	year= 1973,
	publisher = {Addison-Wesley Publishing Company},
	address = {Reading, MA}}

@book{Knuth:Book2,
	author = {Donald E. Knuth},
	series = {The Art of Computer Programming},
	title = {Seminumerical Algorithms},
	volume = 2,
	edition = {2nd},
	year= 1981,
	publisher = {Addison-Wesley Publishing Company},
	address = {Reading, MA}}

@article{Knuth:Sandwich,
        author = {Donald E. Knuth},
	title = {The Sandwich Theorem},
	journal = {The Electronic Journal of Combinatorics},
	volume = 1,
	pages = {1--48},
	year = 1994}

@Article{Koller:SampleSpace,
  author = 	 "D. Koller and N. Megiddo",
  title = 	 "Constructing Small Sample Spaces Satisfying Given Constraints",
  journal =  sicomp,
  year =	 1994,
  volume =	 7,
  number =	 2,
  pages =	 "260--274",
  month =	 "may"
}

@Article{Koutsoupias:SAT,
  author = 	 {E. Koutsoupias and Christos H. Papadimitriou},
  title = 	 { On the greedy heuristic for satisfiability},
  journal =   IPL,
  year = 	 1992,
  volume =	 43,
	number = 1,
  pages =	 {53--55}
}

@book{Korte:Greedoid,
	author = {Bernhard H. Korte and } # lovasz # { and
Rainer Schrader},
	title = {Greedoids},
	publisher = sv,
	address = {Berlin},
	year = 1991}
@article{Kruskal:MST,
	author = {Kruskal, Jr., J. B.},
	title = {On the Shortest Spanning Subtree of a Graph and
the Traveling Salesman Problem},
	journal = proc # { American Mathematical Society},
	year = 1956,
	volume = 7,
	number = 1,
	pages = {48-50}}

@book{Lawler:TSP,
	editor = {Eugene L. Lawler and J.~K. Lenstra and A.~H.~G. Rinooy
		  Kan and David B. Shmoys},
	title = {The Traveling Salesman Problem},
	publisher = {John Wiley \& Sons},
	year = 1985}

@book{Lawler:Optimization,
	author = {Eugene L. Lawler},
	title = {Combinatorial Optimization: Networks and Matroids},
	publisher = {Holt, Reinhardt and Winston},
	address = {New York},
	year = 1976}

@article{Lee:Matroid,
	author = {Jon Lee and Jennifer Ryan},
	title = {Matroid Applications and Algorithms},
	journal = {ORSA Journal on Computing},
	volume = 4,
	number = 1,
	year = 1992,
	pages = {70--96}}

@inproceedings{Lengauer:Paths,
	author = {T. Lengauer and D. Theune},
	title = {Efficient Algorithms for Path Problems with General
		Cost Criteria},
	booktitle = icalp91,
	year = 1991,
	pages = {314--326}}

@unpublished{Leighton:Recurrence,
        author = {Tom Leighton},
        title = {notes on Better Master Theorems for
                  Divide-and-Conquer Recurrences},
        year = 1996,
        note = {\tt
                  ftp://theory.lcs.mit.edu/pub/classes/6.042/fall96/handouts/master\_thms.ps}
        }

@inproceedings{Leighton:Quotient,
	author = {Tom Leighton and Satish Rao},
	title = {An Approximate Max-flow Min-cut Theorem for
	Uniform Multicommodity Flow Problems with Applications to
	Approximation Algorithms},
	crossref = {FOCS88},
	pages = {422-431}}

@article{Linial:Embedding,
       author =       linial # " and E. London and Y. Rabinovich",
       title =        "The Geometry of Graphs and some of its Algorithmic
                      Applications",
journal = COMB,
volume = 15,
number = 2,
year = 1995,
pages = {215--246},
note = prelim # FOCS94,
     }

@Misc{Linial:Private,
  author =	 linial,
  note =	 "Personal Communication"
}

@article{Lomonosov:Mincut,
	author = {Micael V. Lomonosov},
	title = {On {M}onte {C}arlo Estimates in Network
Reliability},
	journal = {Probability in the Engineering and Informational
Sciences},
	year = 1994,
	volume = 8,
	pages = {245--264}}

@article{Lomonosov:Reliability,
	author = {Micael V. Lomonosov and V. P. Polesskii},
	title = {Lower Bound of Network Reliability},
	journal = {Problems of Information Transmission},
	volume = 7,
	year = 1971,
	pages = {118-123}}

@article{Lomonosov:MatroidSampling,
	author = {Micael V. Lomonosov},
	title = {Bernoulli Scheme with Closure},
	journal = {Problems of Information Transmission},
	year = 1974,
	volume = 10,
	pages = {73-81}}

@book{Lovasz:Exercises,
	author = lovasz,
	title = {Combinatorial Problems and
    Exercises},
	edition = {2nd},
	publisher = {North-Holland},
	address = {Amsterdam},
	year =1993
	}

@article{Lovasz:Shannon,
	author = lovasz,
	title = {On the Shannon capacity of a graph},
	journal = {IEEE Transactions on Information Theory},
	volume = {IT-25},
	pages ={1--7},
	year = 1979}

@misc{Lovasz:Personal,
	author = lovasz,
	note = {Personal Communication.},
	month = mar,
	year =  1994}

@article{Lovasz:SetCover,
	author = lovasz,
	title = {On the Ratio of Optimal Integral and Fractional
Covers},
	journal = DM,
	volume = 13,
	year = 1975,
	pages = {383-390}}

@article{Luby:pairwise,
        author = {Michael G. Luby},
        title = {A Simple Parallel Algorithm for the Maximal
Independent Set Problem},
        journal = sicomp,
	volume = 15,
	pages = {1036--1053},
        year = 1986}

@article{Luby:Paths,
	author = {Michael G. Luby and Prabakar Ragde},
	title = {A Bidirectional Shortest-path Algorithm with Good Average
                 Case Behavior},
	journal = ALGO,
	volume = 4,
	year = 1989,
	pages = {551--567}}

@techreport{Luby:Mincut,
	author = {Michael G. Luby and Joseph Naor and Moni Naor},
	title = {On Removing Randomness from a Parallel Algorithm
for Minimum Cuts},
	institution = {International Computer Science Institute},
	number = {TR-093-007},
	month = feb,
	year = 1993}

@Article{Luczak:PhaseTransition,
  author =       "Luczak and Boris Pittel and Wierman",
  title =        "The Structure of a Random Graph at the Point of the
                 Phase Transition",
  journal =      "TAMS: Transactions of the American Mathematical
                 Society",
  volume =       "341",
  year =         "1994",
}

@inproceedings{LuYa,
	author = {Carsten Lund and Mihalis Yannakakis},
	title = {On the Hardness of Approximating Minimization Problems},
	crossref = {STOC93},
	pages = {286--293}}

@inproceedings{LY,
	author = {Carsten Lund and Mihalis Yannakakis},
	title = {On the Hardness of Approximating Minimization Problems},
	crossref = {STOC93},
	pages = {286--293}}

@inproceedings{Lund:Coloring,
	author = {Carsten Lund and Mihalis Yannakakis},
	title = {On the Hardness of Approximating Minimization Problems},
	crossref = {STOC93},
	pages = {286--293}}

@article{Mader:Connectivity,
	author = {W. Mader},
	title = {A reduction method for edge-connectivity in
  graphs},
	journal ={Annales Discr. Math.},
	volume = {3},
	year ={1978},
	pages = {145--164}
	}

@Article{Mader:CliqueMinors,
  author = 	 "W. Mader",
  title = 	 "Homomorphies{\"a}tze f{\"u}r Graphen",
  journal =	 "Math. Ann.",
  year =	 1968,
  volume =	 "178",
  pages =	 "154--168"
}

@InProceedings{Mahajan:DerandomizeSemidefinite,
  author = 	 "Sanjeev Mahajan and H. Ramesh",
  title = 	 "Derandomizing Semidefinite Programming Based
		  Approximation Algorithms",
  crossref =	 "FOCS95",
  pages =	 "162--169"
}
@article{Margulis,
	author = {G. A. Margulis},
	title = {Probabilistic Characteristics of Graphs with
Large Connectivity (translated from Russian)},
	journal = {Problems in Information Transmission},
	volume = 9,
	year = 1975,
	pages = {325-332},
	publisher = {Plenum Press},
	address = {New York}}

@inproceedings{Matula:Connectivity,
	author = {D. W. Matula},
	title = {Determining Edge Connectivity in {$O(nm)$}},
	crossref = {FOCS87},
	pages = {249-251}}

@inproceedings{Matula:Approxcut,
	author = {D. W. Matula},
	title = {A Linear Time $2+\epsilon$ Approximation
Algorithm for Edge Connectivity},
	crossref = {SODA93},
	pages = {500--504}}

@techreport{Mcgeoch:Paths,
	author = {C.~C. McGeoch},
	title = {A New All-pairs Shortest-path Algorithm},
	institution = {DIMACS},
	year = 1991,
	number = {91-30},
	note = {to appear in Algorithmica.\typeout{MCGEOCH:PATHS APPEARED?}}
}

@article{Menger,
	author ={K. Menger},
	title= {Zur allgemeinem Kurventheorie},
	journal = {Fundam. Math.},
	vulome = 10,
	year = 1927,
	pages = {96--155}
	}

@article{milner,
	author = {E. C. Milner},
	title = {A Combinatorial Theorem on Systems of Sets},
	journal = {Journal of the London Mathematical Society},
	volume = 43,
	pages ={204--206},
	year =  1968}

@Article{Moore:1{.}Lmax,
  author = 	 {J. M. Moore},
  title = 	 {An {$n$}-Job, One Machine Sequencing Algorithm for
                  Minimizing the Number of Late Jobs},
  journal = 	 {Management Science},
  year = 	 1968,
  volume =	 15,
  pages =	 {102--109}
}

@unpublished{cutcover,
	author = {Rajeev Motwani and Joseph Naor},
	title = {On Exact and Approximate Cut Covers of Graphs},
	note ={Manuscript.},
	year =  1993}

@book{Motwani:RandomizedAlgorithms,
        author = {Rajeev Motwani and Prabhakar Raghavan},
	title = {Randomized Algorithms},
	publisher = {Cambridge University Press},
	address = {New York, NY},
	year = {1995}}

@Article{Motwani:DerandomizeLogWay,
  author = 	 {Rajeev Motwani and Joseph Naor and Moni Naor},
  title = 	 {The Probabilistic Method Yields Deterministic
		Parallel Algorithms},
  journal =   JCSS,
  year = 	 1994,
  volume =	 49
}

@book{Mulmuley,
	author = {Ketan Mulmuley},
	title = {Computational Geometry},
	publisher = {Prentice Hall},
	address = {Englewood Cliffs, New Jersey},
	year = 1994}

@article{Mulmuley:Matching,
	author ={Ketan Mulmuley and Umesh V. Vazirani and Vijay V.
Vazirani},
	title = {Matching is as Easy as Matrix Inversion},
	journal = COMB,
	volume = 7,
	number = 1,
	year = 1987,
	pages = {105-113}}

@techreport{Nagamochi:Approxcut,
        author = 	 nagamochi # and # nishimura # and # ibaraki,
	title = {A Tight Upper Bound on the Number of Small Cuts in a
Graph},
	number = {94007},
	place = {Kyoto University, Kyoto, Japan},
	year = 1994}

@TechReport{Nagamochi:CountCuts,
  author = 	 nagamochi # and # nishimura # and # ibaraki,
  title = 	 "Computing all Small Cuts in an Undirected Network",
  institution =  "Kyoto University",
  year = 	 1994,
  number =	 94007,
  address =	 "Kyoto, Japan"
}

@ARTICLE{Nagamochi:Implementation,
author = nagamochi # { and T. Ono and } # ibaraki,
title = "Implementing an Efficient Minimum Capacity Cut Algorithm",
JOURNAL = mp,
volume = 67,
year = 1994,
PAGES = "297--324"}

@article{Nagamochi:Connectivity,
	author =  nagamochi # and # ibaraki,
	title = {Linear Time Algorithms for Finding
		{$k$}-Edge Connected and {$k$}-Node Connected Spanning
		Subgraphs},
	journal = ALGO,
	volume = 7,
	year = 1992,
	pages = {583-596}}

@article{Nagamochi:Mincut,
	author =  nagamochi # and # ibaraki,
	title = {Computing Edge Connectivity in Multigraphs and
Capacitated Graphs},
	journal = siamdm,
	volume = 5,
	number = 1,
	pages = {54-66},
	month = feb,
	year = 1992}

@inproceedings{Nagamochi:Splitting,
	author = {Hiroshi Nagamochi  and T. Ibaraki},
	title = {Deterministic
  {$\Olog(nm)$}-time edge splitting in undirected graphs},
	crossref = {STOC96},
	pages = {64--73}}

@article{Nagamochi:MultiFlow,
	author = {Hiroshi Nagamochi and Toshihde Ibaraki},
        title = {On max-flow min-cut and integral flow properties for
                multicommodity flows in directed networks},
        journal= IPL,
        volume = 31,
        year = 1989,
        pages = {279--285}}

@inproceedings{Naor:Cactus,
	author={Dalit Naor and Vijay V. Vazirani},
	title = {Representing and Enumerating Edge Connectivity
Cuts in {$\RNC$}},
	pages = {273-285},
	series = LNCS,
	publisher = sv,
	volume = 519,
	year = 1991,
	booktitle = WADS91,
	editor = {F. Dehne and  J. R. Sack and N. Santoro},
	month = aug}

@inproceedings{Naor:Augmentation,
	author ={Dalit Naor and  Dan Gusfield and Charles Martel},
	title = {A fast algorithm
  for optimally increasing the edge connectivity},
	crossref = {FOCS90},
	pages = {698--707}
	}

@article{Nash:Trees,
	author = {C. St. J. A. Nash-Williams},
	title = {Edge Disjoint Spanning Trees of Finite Graphs},
	journal = {Journal of the London Mathematical Society},
	volume = 36,
	year = 1961,
	pages = {445-450}}

@incollection{Nash:Orientation,
	author = {C. St. J. A. Nash-Williams},
	title = {Well-balanced Orientations of Finite Graphs and
Unobtrusive Odd-vertex-pairings},
	booktitle = {Recent Progress in Combinatorics},
	editor = {W. T. Tutte},
	publisher = {Academic Press},
	address = {New York},
	year = 1969,
	pages = {133-149}}

@inproceedings{Nisan:Connectivity,
	author = {Noam Nisan and Endre Szemeredi and Avi Wigderson},
	title = {Undirected Connectivity in {$O(\log^{1.5} n)$}
Space},
	crossref = {FOCS92},
	pages = {24-29}}

@Article{Nisan92,
  author = 	 nisan,
  title = 	 "Pseudorandom Generators for Space-bounded Computation",
  journal =	 COMB,
  year =	 1992,
  volume =	 12,
		  number = 4,
		  pages = {449--461},
note = prelim # STOC90,
}

@article{Padberg:Mincut,
	author = {Manfred Padberg and Giovanni Rinaldi},
	title = {An Efficient Algorithm for the Minimum Capacity
Cut Problem},
	journal = mp,
	volume = 47,
	pages = {19--39},
	year = 1990}

@article{Picard:Mincut,
	author = {Jean-Claude Picard and Maurice Queyranne},
	title = {Selected Applications of Minimum Cuts in
Networks},
	journal = {I.N.F.O.R: Canadian Journal of Operations Research
and Information Processing},
	year=1982,
	month = nov,
	volume = 20,
	pages = {394--422}}

@Article{Picard:Stcut,
  author = 	 "Jean-Claude Picard and H.D. Ratliff",
  title = 	 "Minimum Cuts and Related Problems",
  journal =	 "Networks",
  year =	 1975,
  volume =	 5,
  pages =	 "357-370"
}

@inproceedings{Phillips:Flow,
	author = {Steven Phillips and Jeffrey Westbrook},
	title = {Online Load Balancing and Network Flow},
	crossref = {STOC92},
	pages = {402--411}}
@InProceedings{Plotkin:Packing,
       author =       "Serge Plotkin and David Shmoys" # and # tardos,
       title =        "Fast Approximation Algorithms for Fractional Packing
                      and Covering Problems",
crossref={FOCS91},
pages = {495--504}
		  }

@inproceedings{Plotkin:ExcludedMinors,
author="Serge Plotkin and Satish Rao and W. Smith",
title="Shallow excluded minors and improved decompositions",
pages="462--470",
crossref = {SODA94},
annote = {The paper by Alon Seymour and Thomas is beautiful stuff.  We use
essentially the same proof in Plotkin Rao Smith..with a (I think)
clearer explanation.}}

@inproceedings{Plaxton:Neighbor,
     title = {Accessing nearby copies of replicated objects in a distributed environment},
     author = {C. Plaxton and R. Rajaraman and A. Richa},
     booktitle = {Proceedings of the ACM SPAA},
     year = {1997},
     month = {June},
     address = {Newport, Rhode Island},
     pages = {311-320},
}

@article{Podderyugin:Connectivity,
	author = {V.~D. Podderyugin},
	title = {An Algorithm for finding the edge connectivity of
graphs},
	journal = {Vopr. Kibern.},
	year = 1973,
	volume = 2,
	pages = {136}}

@article{Polesskii:MatroidReliability,
	author = {V. P. Polesskii},
	title =  {Bounds on the Connectedness Probability of a
Random Graph},
	journal = {Problems of Information Transmition},
	volume = 27,
	no = 2,
	year = 1990,
	pages = {86--97}}

@Article{Polesski94,
         author =       "V.~P. Polesski",
         title =        "Lower Bounds on Full Rank Probability in Random
                        Matroids",
         journal =      "Problems of Information Transmission (translated from
                        Problemy Peredachi Informatsii (Russian))",
         volume =       "29",
         year =         "1994",
       }

@Article{Posa:Hamiltonian,
  author = 	 "L. P\`osa",
  title = 	 "Hamiltonian Circuits in Random Graphs",
  journal =	 "Discrete Mathematics",
  year =	 1976,
  volume =	 14,
  pages =	 "359--364"
}

@article{Prim:MST,
	author = {R. C. Prim},
	title = {Shortest Connection Networks and Some
Generalizations},
	journal = {Bell System Technical Journal},
	volume = 36,
	year = 1957,
	pages = {1389-1401}}

@article{Provan:Reliability,
	author = {J. Scott Provan and Michael O. Ball},
	title = {The Complexity of Counting Cuts and of Computing
the Probability that a Network Remains Connected},
	journal = sicomp,
	volume = 12,
	year = 1983,
	number = 4,
	pages = {777--788}}

@article{Pruhs:Selection,
	author = {Kirk Pruhs and Udi Manber},
	title = {The Complexity of Controlled Selection},
	journal = {Information and Computation},
	volume = 91,
	number= 1,
	pages  = {103--127},
	year = 1991}

@techreport{Raghavan:Randomization,
	author = {Prabhakar Raghavan},
	title = {Lecture notes on Randomized Algorithms},
	institution = {Computer Science/Mathematics IBM Research
Division},
	type = {Research Report},
	number = {RC 15340 (\ # 68237)},
	address = {T. J. Watson Research Center, Yorktown Heights, NY},
	year = 1990}

@article{Raghavan:DeterministicRounding,
	author = {Prabhakar Raghavan},
	title = {Probabilistic Construction of Deterministic
Algorithms: Approximate Packing Integer Programs},
	journal = JCSS,
	volume = 37,
	number = 2,
	pages = {130--43},
	year = 1988,
	month = oct}

@article{Raghavan:RandomizedRounding,
	author = {Prabhakar Raghavan and C. D. Thompson},
	title = {Randomized Rounding: a Technique for Provably Good
Algorithms and Algorithmic Proofs},
	journal = COMB,
	volume = {7},
	number = {4},
	year = 1987,
	pages = {365--374}}


@unpublished{Ramachandran:Flow,
	author = {Vijaya Ramachandran},
	title = {Flow Value, Minimum Cuts and Maximum Flows},
	year = 1987,
	note = {Manuscript.}}

@article{Ramanathan:EnumerateCuts,
	author = {A. Ramanathan and Charles Colbourn},
	title = {Counting Almost Minimum Cutsets with Reliability
Applications},
	journal = mp,
	year = 1987,
	month = dec,
	volume = 39,
	number = 3,
	pages = {253--61}}

@book{Recski:Matroid,
	author = {Andr{\'a}s Recski},
	title = {Matroid Theory and its Applications In Electric
Network Theory and in Statics},
	publisher = sv,
	address = {Berlin},
	series = {Algorithms and Combinatorics},
	number = {6},
	year = {1989}}

@inproceedings{Reif:Matroid,
	author = {John H. Reif and P. Spirakis},
	title = {Random Matroids},
	year = 1980,
	booktitle = STOC80,
	pages = {385-397}}


@article{Ravasio:Desktops,
 author = {Pamela Ravasio and Sissel Guttormsen Sch\"ar and Helmut Krueger},
 title = {In pursuit of desktop evolution: User problems and practices with modern desktop systems},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 volume = {11},
 number = {2},
 year = {2004},
 issn = {1073-0516},
 pages = {156--180},
 doi = {http://doi.acm.org/10.1145/1005361.1005363},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@InProceedings{Resnick:GroupLens,
  author = 	 {Paul Resnick and Neophytos Iacovou and Mitesh Suchak
                  andPeter Bergstrom and John Riedl},
  title = 	 {GroupLens: An Open Architecture for Collaborative
                  Filtering of Netnews},
  booktitle = 	 {ACM 1994 Conference on Computer Supported
                  Cooperative Work},
  year =	 1994,
  address =	 {Chapel Hill, NC},
  pages =	 {175--186},
  note =	 {server at {\tt http://www.cs.umn.edu/Research/GroupLens/}}
}

@book{renyi,
	author = renyi,
	title = {Probability Theory},
	publisher = {Elsevier},
	address = {New York},
	year =  {1970}}

@InProceedings{Rose:Piles,
  author = 	 {Daniel E. Rose and Richer Mander and Tim Oren and
                  Dulce B. Poncele\'on and Gitta Salomon and Yin Yin Wong},
  title = 	 {Content Awareness in a File System interface:
                  Implementing the 'Pile' Metaphor for Organizing Information},
  booktitle = 	 SIGIR93,
  year =	 1993,
  month =	 {June},
  pages =	 {260--269}
}

@Article{Salton:SMART-CACM,
  author = 	 {Gerard Salton and James Allan and Chris Buckley},
  title = 	 {Automatic Structuring and Retrieval of Large Text Files},
  journal = 	 cacm,
  year = 	 1994,
  volume =	 37,
  number =	 2,
  month =	 feb,
  pages =	 {97--108}
}

@InProceedings{Saran:Multicut,
  author =       "H. Saran and V. V. Vazirani",
  title =        "Finding $k$-Cuts Within Twice the Optimal",
  pages =        "743--751",
  ISBN =         "0-8186-2445-0",
  editor =       "IEEE",
  booktitle =    "Proceedings of the 32nd Annual Symposium on
                 Foundations of Computer Science",
  address =      "San Juan, Porto Rico",
  month =        oct,
  year =         "1991",
  publisher =    "IEEE Computer Society Press",
}
@article{Schieber:LCA,
	author = {Baruch Schieber and Uzi Vishkin},
	title = {On Finding Lowest Common Ancestors: Simplification
and Parallelization},
	journal = sicomp,
	year = 1988,
	month = dec,
	volume = 17,
	no = 6,
	pages = {1253-1262}}

@book{Schrijver:LP,
	author = {Alexander Schrijver},
	title = {Theory of Linear and Integer Programming},
	series = {Wiley-Interscience Series in Discrete Mathematics},
	publisher = {John Wiley \& Sons},
	cite = {New York},
	year = 1986}

@book{Schrijver:Packing,
	editor = {Alexander Schrijver},
	title = {Packing and Covering in Combinatorics},
	year = 1979,
	publisher = {Mathematical Centre},
	series = {Mathematical Centre Tracts},
	number = 106,
	address = {Amsterdam}}

@inproceedings{Seidel:Paths,
	author = {Raimund Seidel},
	title = {On the All-Pairs-Shortest-Path Problem},
	crossref = {STOC92},
	pages = {745--749}}

@article{Shiloach:Connectivity,
	author = {Y. Shiloach and Uzi Vishkin},
	title = {An {$O(\log n)$} Parallel Connectivity Algorithm},
	journal = JALG,
	volume = 3,
	pages = {57-67},
	year = 1982}

@article{Shiloach:Flow,
	author = {Y. Shiloach and Uzi Vishkin},
	title = {An ${O}(n^2 \log n)$ Parallel Max-Flow Algorithm},
	journal = JALG,
	volume = 3,
	year = 1982,
	pages = {128--146}}

@incollection{Shmoys:Approximation,
	author = {David Shmoys},
	title = {Combinatorial Optimization},
	booktitle = {Computing Near-Optimal Solutions to Combinatorial
		  Optimization Problems},
	year = 1995,
	pages = {355--397},
	series ={ DIMACS Series in Discrete Math and
		  Theoretical Computer Science},
	publisher = {AMS},
	editor = {William Cook and} # lovasz # {and Paul D. Seymour}}

@article{Sleator:DynamicTrees,
	author = {Daniel D. Sleator and Robert E. Tarjan},
	title = {A Data Structure for Dynamic Trees},
	journal = JCSS,
	volume= 26,
number = 3,
month = jun,
	year = 1983,
	pages = {362--391}}

@article{Spira:Paths,
	author = {P. M. Spira},
	title = {A New Algorithm for Finding All Shortest Paths in a Graph
		of Positive Arcs in Average Time {$O(n^2 \log^2 n)$}},
	journal = sicomp,
	year = 1973,
	volume = 2,
	pages = {28--32}}

@inproceedings{SpiraPan:Paths,
	author = {P. M. Spira and A. Pan},
	title = {On Finding and Updating Shortest Paths and
		Spanning Trees},
	booktitle = {Conference Record, IEEE 14th Annual Symposium on
		Switching and Automata Theory},
	year = 1973}

@Article{Stoer:Mincut,
  title =        "A Simple Min-Cut Algorithm",
  author =       "Mechthild Stoer and Frank Wagner",
  area =         "Data Structures and Algorithms",
  journal =      "Journal of the ACM",
  pages =        "585--591",
  month =        jul,
  year =         "1997",
  volume =       "44",
  number =       "4",
  general-terms = "Algorithms",
  cr-categories = "G.1.2[graph algorithms]",
  keywords =     "Min-Cut",
  references =   "\cite{SICOMP::AhujaOT1989} \cite{IPL::Alon1990}
                 \cite{ICALP::CheriyanHM1990} \cite{JACM::FredmanT1987}
                 \cite{JACM::GoldbergT1988} \cite{SODA::HaoO1992}
                 \cite{STOC::KargerS1993} \cite{SODA::Matula1993}
                 \cite{CACM::MehlhornN1995} \cite{ALGOR::NagamochiI1992}
                 \cite{SODA::Queyranne1995}",
}

@misc{Szegedy:Chromatic,
	author = {Mario Szegedy},
	note = {Personal Communication},
	month = mar,
	year = 1994,
	howpublished = {AT\&T Bell Laboratories}}

@inproceedings{Szegedy:Theta,
        author = {Mario Szegedy},
        title = {A note on the $\theta$ Number of Lov\'asz and the Generalized
Delsarte Bound},
        crossref={FOCS94},
        pages = {36--39}}

@misc{Ta-Shma:PComplete,
	author  = {Amnon Ta-Shma},
	note = {Personal Communication.},
	year = 1994,
	howpublished = {Hebrew University, Jerusalem, Israel}}

@inproceedings{Takaoka:Paths,
	author = {T. Takaoka},
	title = {A New Upper Bound on the Complexity of the All Pairs
		Shortest Path Problem},
	booktitle = proc # { 17th International Workshop on
		Graph-Theoretic Concepts in Computer Science},
	year = 1991,
	pages = {209--213}
}

@book{Tarjan:DataStructures,
	author = {Robert E. Tarjan},
	title = {Data Structures and Network Algorithms},
	publisher = {{SIAM}},
	year = 1983,
	series = {CBMS-NSF Regional Conference Series in Applied Mathematics},
	volume = 44}

@article{Tarjan:PathCompression,
	author = {Robert E. Tarjan},
	title = {Applications of Path Compression on Balanced
Trees},
	journal = JACM,
	volume = 26,
	number = 4,
	year = 1979,
	month = oct,
	pages = {690--715}}

@InProceedings{Thorup:DecrementalConnectivity,
  author = 	 {Mikkel Thorup},
  title = 	 {Dynamic Decremental Connectivity},
  crossref =	 {SODA95},
  pages =	 {305--313}
}

@InProceedings{Tenenbaum:Manifold,
  author = 	 {Joshua B. Tennebaum},
  title = 	 {Mapping a Manifold of Perceptual Observations},
  booktitle =	 {Advances in Neural Information Processing Systems},
  year =	 1998,
  volume =	 10,
  publisher =	 {The {MIT} Press}
}

@Article{Tenenbaum:Dimensionality,
  author = 	 {Joshua B. Tenenbaum and de Silva, Vin and John
                  C. Langford},
  title = 	 {A Global Geometric Framework for Nonlinear
                  Dimensionality Reduction},
  journal = 	 {Science},
  year = 	 2000,
  volume =	 290,
  number =	 5500,
  pages =	 {2319--2323},
  month =	 {dec},
  note = 	 {See also {\tt http://isomap.stanford.edu}},
}

@InProceedings{Thorup:DynamicConnectivity,
  author =       "Jacob Holm and Kristian de Lichtenberg and Mikkel
                 Thorup",
  title =        "Poly-logarithmic Deterministic Fully-dynamic
                 Algorithms for Connectivity, Minimum Spanning tree,
                 2-edge and Biconnectivity",
  pages =        "79--89",
  crossref = {STOC98},
}
@Proceedings{TREC4,
  title = 	 {The Fourth Text REtrieval Conference},
  year = 	 1995,
  editor =	 {Donna Harman},
  organization = {National Institute of Standards and Technology},
  note =	 {NIST SP 500-236.  Web access at {\tt http://www-nlpir.nist.gov/TREC/}}
}

@incollection{VEB:MachineModels,
        author = {Peter van Emde Boas},
        title = {Machine Models and Simulations},
        crossref={HandbookTCS},
        pages = {3-66},
        chapter = 2}

@book{Waerden:Matroid,
	author = {Van Der Waerden, B. L.},
	title = {Moderne Algebra},
	publisher = {Springer},
	address = {Berlin},
	year = 1937}

@article{Valiant:SharpP,
        author = {Leslie Valiant},
	title = {The Complexity of Enumeration and Reliability
		  Problems},
	journal= sicomp,
	volume = 8,
	year = 1979,
	pages= {410--421}}

@inproceedings{Vazirani:EnumerateCuts,
	author={Vijay V. Vazirani and Mihalis Yannakakis},
	title = {Suboptimal Cuts: Their Enumeration, Weight, and
Number},
        crossref = {icalp92},
	pages = {366-377}
	}

@article{Vega:Maxcut,
	author = {Fernandez de la Vega, W.},
	title = {{MAXCUT} has a Randomized Approximation Scheme in
		  Dense Graphs},
	journal = {Random Structures and Algorithms},
	volume = 8,
	number = 3,
	pages = {187--198},
	year = 1996,
	note = {A preliminary manuscript appeared in 1994}}

@Article{VonNeumann:Random,
  author =       {J. Von Neumann},
  title =        {Various Techniques Used in connection with random digits},
  journal =      {National Bureau of Standards, Applied Math Series},
  year =         1951,
  volume =       12,
  pages =        {36--38}
}

@article{Watanabe:Augmentation,
	author ={ Watanabe, T. and A. Nakamura},
	title = {Edge connectivity
  augmentation problems},
	journal = {Journal of Computer and System Sciences},
	volume = 53,
	year = 1987,
	pages = {96--144}
	}

@book{Welsh:Matroid,
	author = {D. J. A. Welsh},
	title = {Matroid Theory},
	publisher = {Academic Press},
	address = {London},
	year = 1976,
	series = {London Mathematical Society Monographs},
	editors = {P. M. Cohn and G. E. H. Reuter}}

@article{Whitney:Matroid,
	author = {Hassler Whitney},
	title = {On the Abstract Properties of Linear
Independence},
	journal = {American Journal of Mathematics},
	volume = 57,
	pages = {509--533},
	year = 1935}

@inproceedings{Williamson:Steiner1,
	author = {David Williamson and Michel X. Goemans and Milena
Mihail and Vijay V. Vazirani},
	title = {A Primal-Dual Approximation Algorithm for
Generalized {S}teiner Problems},
	crossref = {STOC93},
	pages = {708-717}}

@article{Williamson:CountCuts,
author  = "Monika Henzinger and David P. Williamson",
title   = "On the Number of Small Cuts in a Graph",
journal = IPL,
volume  = 59,
pages   = "41--44",
year    = 1996}

@article{wigderson,
	author = {Avi Wigderson},
	title = {Improving the Performance Guarantee for Approximate Graph Coloring},
	journal = jacm,
	volume = 30,
	pages = {729--735},
	year =  1983}

@inproceedings{Williamson:Steiner2,
	author = {Michel X. Goemans and Andrew Goldberg and Serge
Plotkin and David Shmoys and {\'E}va Tardos and David Williamson},
	title = {Improved Approximation Algorithms for Network
Design Problems},
	crossref = {SODA94},
	pages = {223-232}}

@phdthesis{Williamson:Thesis,
	author = {David P. Williamson},
	title = {On the Design of Approximation Algorithms for a
Class of Graph Problems},
	school = {MIT},
	year = 1993,
	note = {published as technical report MIT-LCS-TR-584.}}

@article{Winter:Steiner,
	author = {Pawel Winter},
	title = {Generalized {S}teiner Problem in Outerplanar
Networks},
	journal = {Networks},
        volume = {17},
	year = 1987,
	pages = {129-167}}

@article{wood,
	author  ={D. C. Wood},
	title = {A Technique for Coloring a Graph Applicable to
Large-Scale Optimization Problems},
	journal = {Computer Journal},
	volume = 12,
	pages = {317},
	year =1969}

@inproceedings{Yannakakis:3SAT,
	author = {Mihalis Yannakakis},
	title = {On the Approximation of Maximum Satisfiability},
	crossref = {SODA92},
	pages = {1--9}}

@book{Zimmerman,
	author = {U. Zimmerman},
	title = {Linear and Combinatorial Optimization in Ordered
		Algebraic Structures},
	publisher = {North-Holland Publishing Company},
	series = {Annals of Discrete Mathematics},
	volume = 10,
	chapter = 8,
	year = 1981
}

@inproceedings{BCLS,
  author = 	{T.~Bui and S.~Chaudhuri and Tom Leighton and Michael Sipser},
  title =  {Graph Bisection algorithms with good average case behavior},
crossref = {FOCS84},
  pages = 	 {181--192}
}

@article{JS:matching,
   author ={M.~Jerrum and A.~Sinclair},
  title = {Approximating the Permanent},
  year = 	{1989},
 volume = 	{18},
  number = 	{6},
pages = {1149--1178},
 journal = sicomp
}

@inproceedings{JS:annealing,
  author = 	 {M.~Jerrum and G.~B.~Sorkin},
  title = 	 {Simulated Annealing for Graph Bisection},
crossref = {FOCS93},
 pages = 	 {94--103},
}

@inproceedings{LR,
author = {Tom Leighton and Satish Rao},
title = {An approximate max-flow min-cut theorem for uniform multicommodity
		  flow problems with applications to approximation algorithms},
crossref={FOCS88},
pages = {422--431}}

@article{PY:maxsnp,
author = {Christos Papadimitriou and Mihalis Yannakakis},
title = {Optimization, approximation and complexity classes},
journal = {JCSS},
year = 1991,
volume = 43,
number = 3,
pages = {425--440},
note = prelim # STOC88
}

@Book{Papadimitriou:Complexity,
  author = 	 {Christos Papadimitriou},
  title = 	 {Computational Complexity},
  publisher = 	 {Addison-Wesley},
  year = 	 {1994},
  OPTkey = 	 {},
  OPTeditor = 	 {},
  OPTvolume = 	 {},
  OPTnumber = 	 {},
  OPTseries = 	 {},
  OPTaddress = 	 {},

  OPTedition = 	 {},
  OPTmonth = 	 {},
  OPTnote = 	 {},
  OPTannote = 	 {}
}

@inproceedings{GW,
author = {M.~Goemans and D.~Williamson},
title = {A 0.878 approximation algorithm for {MAX-2SAT} and {MAX-CUT}},
booktitle = {Proc.\ 26th STOC},
year = 1994,
pages = {422-431}}

@Article{Berners-Lee:SemanticWeb,
  author = 	 {Tim Berners-Lee and James Hendler and Ora Lasilla},
  title = 	 {The Semantic Web},
  journal = 	 {Scientific American},
  year = 	 2001,
  month =	 may
}

@InProceedings{Whittaker:Email,
  author = 	 {Steve Whittaker and C. Sidner},
  title = 	 {Email Overload: Exploring Personal Information
                  Management of Email},
  booktitle =	 {Proceedings of the ACM CHI Conference on Human Factors in Computing Systems},
  year =	 1996
}

@InProceedings{Storey:Shrimp,
  author = 	 {Storey, M. and Best, C. and Michaud, J. and Rayside,
                  D. and
                  Litoiu, M. and Musen, M.},
  title = 	 {{SHriMP} Views: An Interactive Environment for
                  Information Visualization and Navigation},
  booktitle =	 {Proceedings of the ACM CHI Conference on Human Factors in Computing Systems},
  year =	 2003
}


@InProceedings{Abrams:Bookmarks,
  author = 	 {Abrams, D. and Baecker, R. and Chignell, M.},
  title = 	 {Information
                  Archiving with Bookmarks: Personal Web Space
                  Construction and Organization},
  booktitle =	 {Proceedings of the ACM CHI Conference on Human Factors in Computing Systems},
  pages =	 {41-48},
  year =	 1998
}

@Article{Dourish:Presto,
  author = 	 {Paul Dourish and W. Keith Edwards and Anthony
                  LaMarca and John Lamping and Karin Petersen and Michael
                  Salisbury and Douglas B. Terry and James Thornton},
  title = 	 {Extending Document Management
                  Systems with User-Specific Active Properties},
  journal = 	 {ACM
                  Transactions on Information Systems},
  year = 	 2000,
  volume =	 18,
  number =	 2,
  pages =	 {140-170},
  month =	 apr
}

@Article{Lai:ObjectLens,
  author = 	 {Kum-Yew Lai and Thomas W. Malone},
  title = 	 {ObjectLens: a spreadsheet for cooperative work},
  journal = 	 {ACM Transactions on Office
Information Systems},
  year = 	 1988,
  volume =	 6,
  number =	 4
}

@Article{Malone:OVAL,
  author = 	 {Thomas W. Malone and Kum-Yew Lai and Christopher Fry},
  title = 	 {Experiments with OVAL: A Radically Tailorable Tool for Cooperative Work},
  journal = 	 {{ACM} Transactions on Information Systems},
  year = 	 1995,
  volume =	 13,
  number =	 2,
  pages =	 {177--205},
  month =	 apr
}

@Article{Freeman:LifeStreams,
  author = 	 {Freeman, E. and Gelernter, D.},
  title = 	 {Lifestreams: A Storage Model for Personal Data},
  journal = 	 {SIGMOD Record},
  year = 	 1996,
  volume =	 25,
  number =	 1,
  pages =	 {80-86}
}

@InProceedings{Kang:MediaFinder,
  author = 	 {Kang, H. and Ben Shneiderman},
  title = 	 {MediaFinder: An Interface for Dynamic Personal Media Management with Semantic Regions},
  booktitle =	 {Proceedings of the ACM CHI Conference on Human Factors in Computing Systems},
  year =	 2003
}

@inproceedings{Stojanovic:Seal,
 author = {Nenad Stojanovic and Alexander Maedche and Steffen Staab and Rudi Studer and York Sure},
 title = {{SEAL}: a framework for developing SEmantic PortALs},
 booktitle = {K-CAP '01: Proceedings of the 1st international conference on Knowledge capture},
 year = {2001},
 month = oct,
 isbn = {1-58113-380-4},
 pages = {155--162},
 location = {Victoria, British Columbia, Canada},
 doi = {http://doi.acm.org/10.1145/500737.500762},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@InProceedings{Guha:SemanticSearch,
  author = 	 {R. Guha and R. McCool and Eric Miller},
  title = 	 {Semantic Search},
  booktitle =	 {Proceedings of the World Wide Web Conference},
  year =	 2003
}

@Unpublished{Werner:LSID,
  author = 	 {P. Werner and T. Liefield and T. Gilman and S. Bacon
                  J. Apgar},
  title = 	 {URN Namespace for Life Science Identifiers},
  note =
                  {http://www.i3c.org/workgroups/technical\_architecture/resources/lsid/docs/LSIDSyntax9-20-02.htm},
  year =	 2002
}

@MastersThesis{Huynh:Thesis,
  author = 	 {David Huynh},
  title = 	 {A User Interface Framework for Supporting Information Management Tasks in Haystack},
  school = 	 {M.I.T.},
  year = 	 2003,
  month =	 may
}

@PhdThesis{Quan:Thesis,
  author = 	 {Dennis Quan},
  title = 	 {Designing End User Information Environments Built on Semistructured Data Models},
  school = 	 {M.I.T.},
  year = 	 2004,
  month =	 may
}

@Unpublished{McGuinness:OWL,
  author = 	 {     Deborah L. McGuinness and    Frank van Harmelen},
  title = 	 {OWL Web Ontology Language Overview},
  note =        {http://www.w3.org/TR/owl-features/},
  year =	 2003
}

@Unpublished{Manola:RDF,
  author = 	 {Frank Manola and Eric Miller},
  title = 	 {RDF Primer},
  note =        {http://www.w3.org/TR/rdf-primer/},
  year =	 2003
}

@Unpublished{Conolly:DAML,
  author = 	 {Dan Connolly and Frank van Harmelen and Ian Horrocks
                  and Deborah L. McGuinness and Peter
                  F. Patel-Schneider and Lynn Andrea Stein},
  title = 	 {DAML+OIL (March 2001) Reference Description},
  note =        {http://www.w3.org/TR/daml+oil-reference},
  year =	 2001
}

@inproceedings{Pietriga:IsaViz,
 author = {Pietriga, Emmanuel},
 title = {Semantic web data visualization with graph style sheets},
 booktitle = {Proceedings of the 2006 ACM symposium on Software visualization},
 series = {SoftVis '06},
 year = {2006},
 isbn = {1-59593-464-2},
 location = {Brighton, United Kingdom},
 pages = {177--178},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/1148493.1148532},
 doi = {10.1145/1148493.1148532},
 acmid = {1148532},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {graph drawing, semantic web, style sheets},
}

@InProceedings{Muslea:WrapperInduction,
  author = 	 {Ion Muslea and S. Minton and Craig Knoblock},
  title = 	 {A Hierarchical Approach to Wrapper Induction},
  booktitle =	 {Proceedings of the Third International Conference on
                  Autonomous Agents (Agents '99)},
  year =	 1999
}

@Article{Bosc:FuzzyQuery,
  author = 	 {P. Bosc and A. Motro and G. Pasi},
  title = 	 {Report on the Fourth International Conference on
                  Flexible Query Answering Systems},
  journal = 	 {SIGMOD Record},
  year = 	 2001,
  volume =	 30,
  number =	 1
}

@article{Codd:Relational,
   author    = {E. F. Codd},
   title     = {A Relational Model of Data for Large Shared Data Banks},
   journal   = {CACM},
   volume    = {13},
   number    = {6},
   year      = {1970},
   pages     = {377-387},
}

@inproceedings{Montage,
 author = {Corin R. Anderson and Eric Horvitz},
 title = {Web montage: a dynamic personalized start page},
 booktitle = {WWW '02: Proceedings of the 11th international conference on World Wide Web},
 year = {2002},
 isbn = {1-58113-449-5},
 pages = {704--712},
 location = {Honolulu, Hawaii, USA},
 doi = {http://doi.acm.org/10.1145/511446.511537},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@article{Rooms,
 author = {Henderson, Jr., D. Austin and Stuart Card},
 title = {Rooms: the use of multiple virtual workspaces to reduce space contention in a window-based graphical user interface},
 journal = {ACM Trans. Graph.},
 volume = {5},
 number = {3},
 year = {1986},
 issn = {0730-0301},
 pages = {211--243},
 doi = {http://doi.acm.org/10.1145/24054.24056},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@InProceedings{Eriksson:Protege,
  author = 	 {Eriksson, H. and Fergerson, R. and Shahar, Y. and
                  and Musen, M.},
  title = 	 {Automatic Generation of Ontology Editors},
  booktitle = 	 {Proceedings of the 12th Banff Knowledge Acquisition
                  Workshop },
  year =	 1999
}

@InProceedings{Yee:Faceted,
 author = {Yee, Ka-Ping and Swearingen, Kirsten and Li, Kevin and
                  Hearst, Marti},
 title = {Faceted metadata for image search and browsing},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in
                  Computing Systems},
 series = {CHI '03},
 year = {2003},
 isbn = {1-58113-630-7},
 location = {Ft. Lauderdale, Florida, USA},
 pages = {401--408},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/642611.642681},
 doi = {10.1145/642611.642681},
 acmid = {642681},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {faceted metadata, image search interfaces},
}

@Article{ zhang1989,
author = "K. Zhang and Dennis Shasha",
title = "Simple fast algorithms for the editing distance between trees and related problems",
journal = "SIAM J. Computing",
pages = "1245--1262",
volume = 18,
number = 6,
month = "December",
year = 1989,
}

@Article{ hoffmann1982,
author = "C. M. Hoffmann and M. J. O'Donnell",
title = "Pattern matching in trees",
journal = "J. Association of Computing Machinery",
pages = "68--95",
volume = 29,
number = 1,
month = "January",
year = 1982,
}

@Article{ tai1979,
author = "Kuo--Chung Tai",
title = "The tree--to--tree correction problem",
journal = "J. Association of Computing Machinery",
pages = "422--433",
volume = 26,
number = 3,
month = "July",
year = 1979,
}

@article { bernerslee2001,
author = "T. Berners--Lee and J. Hendler and O. Lassila",
title = "The Semantic Web",
journal = "Scientific American",
volume = 284,
number = 5,
pages = "35",
month = "May",
year =  2001
}

@inproceedings{ reis04,
author = "D. C. Reis and P. B. Golgher and A. S. Silva and A. F. Laender",
title = "Automatic Web News Extraction Using Tree Edit Distance",
booktitle = "Proceedings of the 13th International Conference on the World Wide Web",
address = "New York, NY",
pages = "502--511",
year = 2004
}

@inproceedings{ golbeck02,
author = "J. Golbeck and M. Grove and Bijan Parsia and A. Kalyanpur and J. Hendler",
title = "New tools for the semantic web",
booktitle = "Proceedings of 13th International Conference on Knowledge Engineering and Knowledge Management",
month = "Oct",
year = 2002
}

@inproceedings{ handschuh02,
author = "S. Handschuh and S. Staab",
booktitle = "Proceedings of the 11th International World Wide Web Conference",
year = 2003,
title = "authoring and Annotation of Web Pages in CREAM",
}

@inproceedings{ kahan01annotea,
    author = "Jose Kahan and Marja-Ritta Koivunen",
    title = "Annotea: an open {RDF} infrastructure for shared Web annotations",
    booktitle = "World Wide Web",
    pages = "623-632",
    year = "2001",
    url = "citeseer.ist.psu.edu/kahan01annotea.html" }

@inproceedings{ cole1999,
    author = "Cole and Hariharan and Indyk",
    title = "Tree Pattern Matching and Subset Matching in Deterministic ${O}(n \log^3 n)$-Time",
    booktitle = "{SODA}: {ACM}-{SIAM} Symposium on Discrete Algorithms (A Conference on Theoretical and Experimental Analysis of Discrete Algorithms)",
    year = 1999,
    url = "citeseer.nj.nec.com/cole00tree.html"
}

@Article{ dubiner1994,
author = "Moshe Dubiner and Zvi Galil and Edith Magen",
title = "Faster Tree Pattern Matching",
journal = "J. Association of Computing Machinery",
pages = "205--213",
volume = 41,
number = 2,
month = "March",
year = 1994,
}

@inproceedings{ shasha2002,
author = "Dennis Shasha and Jason Tsong-Li Wang and Rosalba Giugno",
title = "Algorithmics and applications of tree and graph searching",
booktitle = "Symposium on Principles of Database Systems",
pages = "39--52",
year = 2002,
}

@inproceedings{ muslea1999,
author = "Ion Muslea and Steven Minton and Craig Knoblock",
title = "A hierarchical approach to wrapper induction",
booktitle = "Proc. of the Third International Conference on Autonomous Agents",
publisher = "ACM Press",
address = "Seattle, WA, USA",
editor = "Oren Etzioni and J{\"o}rg P. M{\"u}ller and Jeffrey M. Bradshaw",
pages = "190--197",
year = 1999,
}

@inproceedings{ miller1999,
author = "Robert C. Miller and Brad A. Meyers",
title = "Lightweight Structured Text Processing",
booktitle = "Proc. of USENIX 1999 Annual Technical Conference",
address = "Monterey, CA, USA",
month = "June",
year = 1999,
pages = "131--144"
}

@incollection { domingue2003,
author = "John Domingue and Martin Dzbor and Enrico Motta",
title = "Semantic Layering with Magpie",
editor = "S. Staab and R. Studer",
booktitle = "Handbook on Ontologies in Information Systems",
publisher = "Springer Verlag",
year = 2003
}


@misc { dublin1997,
title = "Dublin Core Metadata Initiative",
howpublished = "http://purl.org/metadata/dublin\_core",
year = 1997
}

@misc { simile2004,
title = "Simile: {S}emantic {I}nteroperability of {M}etadata and {I}nformation in un{L}ike {E}nvironments",
howpublished = "http://simile.mit.edu",
year = 2004
}

@misc { rdf1999,
title = "Resource {D}escription {F}ramework ({RDF}) Specification",
howpublished = "http://www.w3.org/RDF",
year = 1999
}

@misc { cgi,
title = "The {CGI} Specification, {V}ersion 1.1",
howpublished = "http://hoohoo.ncsa.uiuc.edu/cgi/interface.html",
}

@inproceedings{ freitag1998,
    author = "Dayne Freitag",
    title = "Information Extraction from {HTML}: Application of a General Machine Learning Approach",
    booktitle = "{AAAI}/{IAAI}",
    pages = "517-523",
    year = "1998",
    url = "citeseer.nj.nec.com/freitag98information.html"
}

@inproceedings{ kushmerick1997,
    author = "Nicholas Kushmerick and Daniel S. Weld and Robert B. Doorenbos",
    title = "Wrapper Induction for Information Extraction",
    booktitle = "Intl. Joint Conference on Artificial Intelligence ({IJCAI})",
    pages = "729--737",
    year = "1997",
    url = "citeseer.nj.nec.com/kushmerick97wrapper.html"
}


@inproceedings{ crescenzi2001,
    author = "Valter Crescenzi and Giansalvatore Mecca and Paolo Merialdo",
    title = "RoadRunner: Towards Automatic Data Extraction from Large Web Sites",
    booktitle = "Proceedings of 27th International Conference on Very Large Data Bases",
    pages = "109-118",
    year = "2001",
    url = "citeseer.nj.nec.com/crescenzi01roadrunner.html"
}

@article{ soderland1999,
    author = "Stephen Soderland",
    title = "Learning Information Extraction Rules for Semi-Structured and Free Text",
    journal = "Machine Learning",
    volume = "34",
    number = "1-3",
    pages = "233-272",
    year = "1999",
    url = "citeseer.nj.nec.com/soderland99learning.html"
}

@inproceedings{ collins1997,
  author = "Michael Collins and Scott Miller",
  title = "Semantic tagging using a probabilistic context free grammar",
  booktitle = "Proceedings of 6th Workshop on Very Large Corpora",
  address = "Montreal, Canada",
  year = 1997,
  url = "citeseer.nj.nec.com/article/collins97semantic.html"
}

@inproceedings{ freund1993,
    author = "Yoav Freund and Michael Kearns and Dana Ron and Ronitt Rubinfeld and Robert E. Schapire and Linda Sellie",
    title = "Efficient learning of typical finite automata from random walks",
    pages = "315--324",
    year = "1993",
    url = "citeseer.nj.nec.com/freund93efficient.html"
}
@inproceedings{ seymore1999,
    author = "Kristie Seymore and Andrew McCallum and Roni Rosenfeld",
    title = "Learning Hidden {Markov} Model Structure for Information Extraction",
    booktitle = "{AAAI} 99 Workshop on Machine Learning for Information Extraction",
    year = "1999",
    url = "citeseer.nj.nec.com/seymore99learning.html"
}
@inproceedings{ freitag2000,
    author = "Dayne Freitag and Andrew McCallum",
    title = "Information Extraction with {HMM} Structures Learned by Stochastic Optimization",
    booktitle = "{AAAI}/{IAAI}",
    pages = "584-589",
    year = "2000",
    url = "citeseer.nj.nec.com/freitag00information.html"
}

@Book{ gusfield97,
author = "D. Gusfield",
title = "Algorithms on Strings, Trees, and Sequences",
year = 1997,
publisher = "Cambridge University Press",
address = "New York",
}

@inproceedings{ ukkonen93,
author = "Esko Ukkonen",
title = "Approximate String--Matching over Suffix Trees",
booktitle = "Proc. 4th Annual Symposium on Combinatorial Pattern Matching",
pages = "229--242",
year = 1993,
}

@inbook {hopcroft72,
author = "J. E. HopCroft and R. E. Tarjan",
title = "Isomorphism of Planar Graphs",
editor = "Raymond E. Miller and James W. Thatcher",
booktitle = "Complexity of Computer Computations",
publisher = "Plenum Press",
pages = "131--152",
year = 1972
}

@article { matula68,
author = "D. W. Matula",
title = "An Algorithm for Subtree Identification",
journal = "SIAM Rev.",
volume = 10,
pages = "273--274",
year = 1968
}

@book { clr,
author = "Tom H. Cormen and Charles E. Leiserson and Ron L. Rivest and Cliff Stein",
title = "Introduction to Algorithms",
publisher = "MIT Press",
edition = "Second",
year = 2001,
pages = "350--356"
}

@inproceedings{ wu1992,
    author = "S. Wu and Udi Manber",
    title = "Agrep -- a fast approximate pattern-matching tool",
    booktitle = "Proceedings {USENIX} Winter 1992 Technical Conference",
    address = "San Francisco, CA",
    pages = "153--162",
    year = "1992",
    url = "citeseer.nj.nec.com/wu92agrep.html"
}

@inproceedings{ kosaraju1989,
author = "S. R. Kosaraju",
title = "Efficient Tree Pattern Matching",
booktitle = "Proceedings of the 30th annual {IEEE} Symposium on Foundations of Computer Science",
address = "New York",
pages = "178--183",
year = 1989,
publisher = "IEEE"
}



@misc { xpath1999,
author = {James Clark and Steve DeRose},
title = "{XML} {P}ath Language ({XP}ath) Specification",
howpublished = "http://www.w3.org/TR/xpath",
year = 1999
}

@misc{ nottingham03,
author = "Mark Nottingham",
title = "xpath2rss {HTML} to {RSS} Scraper",
howpublished = "http://www.mnot.net/xpath2rss/",
year = 2003
}

@misc{iana-uri,
title={The Official {IANA} Registry of {URI} Schemes},
author={{Internet Assigned Numbers authority}},
year=2002,
howpublished={http://www.iana.org/assignments/uri-schemes}
}

@misc{iana-urn,
  title  = {The Official {IANA} Registry of {URN} Namespaces},
  author = {{Internet Assigned Numbers authority}},
  year   = 2002,
  howpublished = {\url{http://www.iana.org/assignments/urn-namespaces}}
}

@misc{owl,
  title  = {{OWL} Web Ontology Language},
  author = {Smith, Michael K. and Welty, Chris and McGuinness, Deborah L.},
  year = 2004,
  month = nov,
  howpublished = {\url{http://www.w3.org/TR/owl-guide/}}
}

@misc{id3,
  title={ID3v2},
  author={Martin Nilsson},
  year = 2004,
  month = nov,
  howpublished = {\url{http://www.id3.org}}
}


@misc{cddb,
  title={Gracenote {CDDB}},
  author={Gracenote},
  year = 2004,
  month = nov,
  howpublished = {\url{http://www.gracenote.com/gn_products/cddb.html}}
}

@misc{freedb,
  title={FreeDB Database},
  author={freedb.org},
  year = 2004,
  month = nov,
  howpublished = {\url{http://www.freedb.org}}
}

@Book{Jensen96,
  author         = {Jensen, F.},
  title          = {An Introduction to Bayesian Networks},
  publisher      = {Springer Verlag},
  keywords       = {knowledge representation bayesian networks da99},
  year           = 1996,
}

@article{Lee01,
 author = "Tim Berners-Lee, James Hendler and Ora Lassila",
 title = "The Semantic Web",
 journal = "Scientific American",
 year = 2001,
 month = may
}

@inproceedings{ goldman97,
    author    = {Roy Goldman and Jennifer Widom},
    title     = {DataGuides: Enabling Query Formulation and Optimization in Semistructured Databases},
    booktitle = {Proceedings of 23rd International Conference on Very Large Data Bases},
    publisher = {Morgan Kaufmann},
    editor    = {Matthias Jarke and Michael J. Carey and Klaus R. Dittrich and Frederick H. Lochovsky and Pericles Loucopoulos and Manfred A. Jeusfeld},
    pages     = {436--445},
    year      = {1997},
    url = {citeseer.ist.psu.edu/article/goldman97dataguide.html}
}

@InProceedings{jensen-neville-NAS02,
  author         = {Jensen, D. and Neville, J.},
  title          = {Data mining in social networks},
  booktitle      = {Invited presentation to the National Academy of Sciences Workshop on Dynamic Social Network Modeling and Analysis},
  city           = {Washington, DC},
  month          = nov,
  year           = 2002
}

@InProceedings{cohn95active,
  author         = {David A. Cohn and Zoubin Ghahramani and Michael I.
                   Jordan},
  title          = {Active Learning with Statistical Models},
  booktitle      = {Advances in Neural Information Processing Systems},
  Editor         = {G. Tesauro and D. Touretzky and T. Leen},
  volume         = {7},
  Pages          = {705--712},
  publisher      = {The {MIT} Press},
  url            = {citeseer.nj.nec.com/cohn96active.html},
  year           = 1995,
}

@inproceedings{lore,
    author = {Roy Goldman and Jennifer Widom},
    title = {DataGuides: Enabling Query Formulation and Optimization in Semistructured Databases},
    booktitle = {{VLDB}'97, Proceedings of 23rd International Conference on Very Large Data Bases},
    publisher = {Morgan Kaufmann},
    editor = {Matthias Jarke and Michael J. Carey and Klaus R. Dittrich and Frederick H. Lochovsky and Pericles Loucopoulos and Manfred A. Jeusfeld},
    pages = {436--445},
    year = {1997},
    url = {citeseer.ist.psu.edu/126680.html}
}

@book{watanabe85,
  author={S. Watanabe},
  year = {1985},
  title={Pattern Recognition: Human and Mechanical},
  publisher={Willey},
  address={New York},
  pages = {198}
}

@book{newcombe88,
  author="H.B. Newcombe",
  year = 1988,
  title="Handbook of Record Linkage: Methods for Health and Statistical Studies, Administration, and Business",
  publisher="Oxford University Press",
  note="Classic book reference. Covers some of the theory and much of the heuristics needed for good record linkage practice.  Now out of print."
}

@article{newcombe59,
	author = {H. B. Newcombe and J. M. Kennedy and S. J. Axford and A. P. James},
	title = {Automatic Linkage for Vital Records},
	journal = {Science},
	year = {1959},
	volume = {130},
	pages = {954--959},
}

@article{fellegi-sunter,
	author = {Fellegi, I. P. and Sunter, A. B.},
	title = {A Theory for Record Linkage},
	journal = {Journal of the American Statistical Association},
	year = {1969},
	volume = {64},
	pages = {1183--1210},
}

@inproceedings{french97,
	title={Automating the Construction of authority Files in Digital Libraries: A Case Study},
	author={James C. French and Allison L. Powell and Eric Schulman and John L. Pfaltz},
 	booktitle = {European Conference on Digital Libraries},
    pages = {55--71},
    year = {1997}
}

@article{hernandez98,
    author = {Mauricio A. Hernandez and Salvatore J. Stolfo},
    title = {Real-world Data is Dirty: Data Cleansing and The Merge/Purge Problem},
    journal = {Data Mining and Knowledge Discovery},
    address = {Boston},
    volume = 2,
    number = 1,
    pages = {9--37},
    year = {1998}
}

@inproceedings{lin98,
    author = {Dekang Lin},
    title = {An information-theoretic definition of similarity},
    booktitle = {Proc. 15th International Conf. on Machine Learning},
    publisher = {Morgan Kaufmann, San Francisco, CA},
    pages = {296--304},
    year = {1998},
    url = {citeseer.ist.psu.edu/95071.html}
}

@inproceedings{pasula02,
	author = {Hanna Pasula and Bhaskara Marthi and Brian Milch and
			Stuart Russell and Ilya Shpitser},
	title = {Identity Uncertainty and Citation Matching},
	booktitle = {Neural Information Processing Systems},
	year = {2002}
}

@inproceedings{bilenko03,
	author = {Mikhail Bilenko and Raymond J. Mooney},
	title = {Adaptive Duplicate Detection Using Learnable String Similarity Measures},
	booktitle = {Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	month = aug,
	year = {2003},
	pages = {39--48}
}

@article{lee01,
 author = "Tim Berners-Lee, James Hendler and Ora Lassila",
 title = "The Semantic Web",
 journal = "Scientific American",
 year = 2001,
 month = may}

@misc{iana-uri,
title={The Official {IANA} Registry of {URI} Schemes},
author={{Internet Assigned Numbers authority}},
year=2002,
note={http://www.iana.org/assignments/uri-schemes}
}

@misc{iana-urn,
title={The Official {IANA} Registry of {URN} Namespaces},
author={{Internet Assigned Numbers authority}},
year=2002,
note={http://www.iana.org/assignments/urn-namespaces}
}

@InProceedings{cohen00,
  author         = {William W. Cohen and Henry Kautz and David McAllester},
  title          = {Hardening Soft Information Sources},
  booktitle      = {Proceedings of the Sixth International Conference on
                   Knowledge Discovery and Data Mining},
  Pages          = {255--259},
  Address        = {Boston, MA},
  key            = {Hardening, Information integration},
  year           = 2000,
  month          = aug
}

@InProceedings{mccallum00,
  author         = {Andrew K. McCallum and Kamal Nigam and Lyle Ungar},
  title          = {Efficient Clustering of High-Dimensional Data Sets
                   with Application to Reference Matching},
  booktitle      = {Proceedings of the Sixth International Conference on
                   Knowledge Discovery and Data Mining},
  Pages          = {169--178},
  Address        = {Boston, MA},
  year           = 2000,
  month          = aug
}

@InProceedings{lawrence99,
  author        = {Steve Lawrence and Kurt Bollacker and C. Lee Giles},
  title         = {Autonomous Citation Matching},
  booktitle     = {Proceedings of the Third International Conference on Autonomous Agents},
 editor        = {Oren Etzioni},
  publisher     = {ACM Press},
  address       = {New York},
  year          = {1999},
  note = {Error metric is percentage of true blocks with incorrect entries}
}

@InProceedings{lafferty01conditional,
  author         = {John Lafferty and Andrew McCallum and Fernando Pereira},
  title          = {Conditional Random Fields: {P}robabilistic Models for
                   Segmenting and Labeling Sequence Data},
  booktitle      = {Proc. 18th International Conf. on Machine Learning},
  Pages          = {282--289},
  publisher      = {Morgan Kaufmann, San Francisco, CA},
  year           = 2001
}

@phdthesis{pfeffer00,
	author = {Avi Pfeffer},
	title = {Probabilistic Reasoning for Complex Systems},
	school = {Stanford},
	year = {2000}
}

@InProceedings{mccallum03,
  author        = "Andrew McCallum and Ben Wellner",
  title         = "Toward Conditional Models of Identity Uncertainty with Application to Proper Noun Coreference",
  booktitle     = "Proceedings of the 18th International Joint Conference on Artificial Intelligence",
  year          = "2003"
}


@InProceedings{Tan:WinCuts,
  author = 	 {D. S. Tan and B. Meyers and Mary Czerwinski},
  title = 	 {{WinCuts}: Manipulating arbitrary window regions for more effective use of screen space},
  booktitle =	 {Extended Abstracts of Proceedings of ACM Human Factors in Computing Systems CHI 2004},
  pages =	 {1525-1528},
  year =	 2004
}

@inproceedings{Dumais01,
 author = {Susan Dumais and Edward Cutrell and Hao Chen},
 title = {Optimizing search by showing results in context},
 booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
 year = {2001},
 isbn = {1-58113-327-8},
 pages = {277--284},
 location = {Seattle, Washington, United States},
 doi = {http://doi.acm.org/10.1145/365024.365116},
 publisher = {ACM Press},
 }

@inproceedings{Engl,
author="Jennifer English and Marti Hearst and Rashmi Sinha and Kristen Searingen and Ka-Ping Yee",
title="Hierarchical Faceted Metadata in Site Search Interfaces",
year="2002",
booktitle="CHI 2002, Minneapolis, Minnesota, USA"
}

@article{Hearst02,
 author = {Marti Hearst and Ame Elliott and Jennifer English and Rashmi Sinha and Kirsten Swearingen and Ka-Ping Yee},
 title = {Finding the flow in web site search},
 journal = {Communications of the ACM},
 volume = {45},
 number = {9},
 year = {2002},
 issn = {0001-0782},
 pages = {42--49},
 doi = {http://doi.acm.org/10.1145/567498.567525},
 publisher = {ACM Press},
 }

@inproceedings{Hearst03,
 author = {Ka-Ping Yee and Kirsten Swearingen and Kevin Li and Marti Hearst},
 title = {Faceted metadata for image search and browsing},
 booktitle = {CHI '03: Proceedings of the SIGCHI conference on Human factors in computing systems},
 year = {2003},
 isbn = {1-58113-630-7},
 pages = {401--408},
 location = {Ft. Lauderdale, Florida, USA},
 doi = {http://doi.acm.org/10.1145/642611.642681},
 publisher = {ACM Press},
 }


@inproceedings{Egnor,
 author="Daniel Egnor and Robert Lord",
 title= {Structured Information Retrieval using {XML}},
 booktitle= {Working notes of the ACM SIGIR Workshop on XML and Information Retrieval},
 year="2000",
 location = {Athens, Greece},
}

@article{Lee01,
 author = "Tim Berners-Lee and James Hendler and Ora Lassila",
 title = "{The Semantic Web}",
 journal = "Scientific American",
 year = 2001,
 month = may}


@Misc{ XML,
  author = "Franois Yergeau and Tim Bray and Jean Paoli and C. M. Sperberg-McQueen and Eve Maler",
  title		= {Extensible Markup Language ({XML})},
  howpublished	= {\url{http://www.w3.org/TR/2004/REC-xml-20040204/}},
  month		= feb,
  year		= {2004},
  note		= {W3C Recommendation},
  postscript	= {},
  pdf		= {},
  url		= {http://www.w3.org/TR/2004/REC-xml-20040204/},
  keywords	= {XML}
}

@proceedings{INEX,
  title={{INitiative for the Evaluation of XML} Retrieval ({INEX}). Proceedings of the Second {INEX} Workshop},
  location = {Dagstuhl, Germany},
  editor={Norbert Fuhr and Mounia Lalmas and Saadia Malik},
  howpublished={\url{http://inex.is.informatik.uni-duisburg.de:2003/proceedings.pdf}},
  month = {December},
  year = 2003,
}

@Misc{ RDFPrimer,
  author = "Frank Manola and Eric Miller",
  title		= {RDF Primer},
  howpublished	= {\url{http://www.w3.org/TR/rdf-primer/}},
}

@Misc{ MozRDF,
  author = "The Mozilla Organization",
  title		= {mozilla.org: Resource Description Framework (RDF)},
  howpublished	= {\url{http://www.mozilla.org/rdf/doc/}},
}

@Misc{ AdobeXMP,
  author 	= "Adobe Systems Inc.",
  title		= {Adobe Extensible Metadata Platform (XMP)},
  howpublished	= {\url{http://www.adobe.com/products/xmp/}},
}

@Misc{ RSS10Spec,
  author	= "Gabe Beged-Dov and Dan Brickley and Rael Dornfest and Ian Davis and Leigh Dodds and Jonathan Eisenzopf and David Galbraith and R.V. Guha and Ken MacLeod and Eric Miller and Aaron Swartz and Eric van der Vlist",
  title		= {{RDF Site Summary (RSS) 1.0 Specifcation}},
  howpublished	= {\url{http://purl.org/rss/1.0/spec}},
}

@Misc{ Lucene,
  author = "Jakatra Project, The Apache Software Foundation",
  title		= {The {L}ucene Search Engine},
  howpublished	= {\url{http://www.lucene.com/}}
}

@Misc{ LongwellWeb,
  author = "The Simile Project",
  title		= {Longwell suit of web-based {RDF} browsers},
  howpublished	= {\url{http://simile.mit.edu/longwell/}}
}

@Misc{ Hayweb,
  author	= {Haystack},
  title		= {The Universal Information Client},
  howpublished	= {\url{http://haystack.lcs.mit.edu/}},
}

@Misc{ MicrodocSurvey,
  author	= "Microdoc News",
  title		= {Expert Users Move Away from Google},
  howpublished	= {\url{http://www.microdoc-news.info/home/2003/04/26.html}}
}

@Misc{ MicrodocPsych,
  author	= "Microdoc News",
  title		= {Google: How the Competition Stacks Up},
  howpublished	= {\url{http://microdoc-} \url{news.info/home/2003/04/15.html}}
}

@Misc{ UIEDecideFirst,
  author	= "Erik Ojakaar",
  title		= {Users Decide First; Move Second},
  howpublished	= {\url{http://www.uie.com/Articles/whatTheyWantArticle.htm}}
}

@Misc{ UIEZeroResults,
  author	= "User Interface Engineering",
  title		= {Users Don't Learn to Search Better},
  howpublished	= {\url{http://www.uie.com/Articles/not_learn_search.htm}}
}

@inproceedings{Velez97,
 author = {Bienvenido Vlez and Ron Weiss and Mark A. Sheldon and David K. Gifford},
 title = {Fast and effective query refinement},
 booktitle = {SIGIR '97: Proceedings of the 20th annual international ACM SIGIR conference on Research and development in information retrieval},
 month = {July},
 year = {1997},
 isbn = {0-89791-836-3},
 pages = {6--15},
 location = {Philadelphia, Pennsylvania, United States},
 doi = {http://doi.acm.org/10.1145/258525.258528},
 publisher = {ACM Press},
 }

@article{Bush45,
   author = {Vannevar Bush},
   title = {Artificial Intelligence},
   journal = {Atlantic Monthly},
   volume = {176},
   number = {1},
   pages = {641--649},
   month = {January},
   year = {1945}
}

@article{Bates89,
   author = {Marcia J. Bates},
   title = {The design of browsing and berrypicking techniques for the online search interface},
   journal = {Online Review},
   volume = {13},
   number = {5},
   pages = {407--424},
   month = {October},
   year = {1989}
}

@article{Bates90,
   author = {Marcia J. Bates},
   title = {Where Should the Person Stop and the Information Search Interface Start?},
   journal = {Information Processing and Management},
   volume = {26},
   number = {5},
   year = {1990},
   issn = {0306-4573},
   pages = {575--591},
   publisher = {Pergamon Press, Inc.},
}

@article{NavCHI97,
   author = {Susanne Jul and George W. Furnas},
   title = {Navigation in Electronic Worlds: Workshop Report},
   journal = {SIGCHI Bulletin},
   volume = {29},
   number = {4},
   pages = {44--49},
   month = {October},
   year = {1997},
   ee = {http://www.acm.org/sigchi/bulletin/1997.4/jul.html}
}

@inproceedings{BrowSEarch95,
 author = {Jock D. Mackinlay and Polle T. Zellweger},
 title = {Browsing vs. search: can we find a synergy? (panel session)},
 booktitle = {Conference companion on Human factors in computing systems},
 year = {1995},
 isbn = {0-89791-755-3},
 pages = {179--180},
 location = {Denver, Colorado, United States},
 doi = {http://doi.acm.org/10.1145/223355.223490},
 publisher = {ACM Press},
 }

@incollection{HearstBook,
   author = {Marti A. Hearst},
   title = {User interfaces and visualization},
   editor = {Ricardo Baeza-Yates and Berthier Ribeiro-Neto},
   booktitle = {Modern Information Retrieval},
   publisher = {ACM Press},
   chapter = {10},
   pages = {257--323},
   year = {1999}
}

@incollection{LostInSpace,
   author = {Joel Spolsky},
   title = {User Interface Design for Programmers},
   booktitle = {User Interface Design for Programmers},
   publisher = {APress},
   month = {June},
   year = {2001}
}

@incollection{IRBook92,
 author = {Donna Harman},
 title = {Relevance feedback and other query modification techniques},
 pages = {241--263},
 chapter = {11},
 editor = {William B. Frakes and Ricardo Baeza-Yates},
 booktitle = {Information retrieval: data structures and algorithms},
 year = {1992},
 isbn = {0-13-463837-9},
 publisher = {Prentice-Hall, Inc.}
 }

@incollection{VSMIRBook92,
 author = {Donna Harman},
 title = {Ranking Algorithms},
 pages = {363--392},
 chapter = {14},
 editor = {William B. Frakes and Ricardo Baeza-Yates},
 booktitle = {Information retrieval: data structures and algorithms},
 year = {1992},
 isbn = {0-13-463837-9},
 publisher = {Prentice-Hall, Inc.}
 }

@book{InfoSeekingBook,
 author = {Gary Marchionini},
 title = {Information seeking in electronic environments},
 year = {1995},
 isbn = {0-521-44372-5},
 publisher = {Cambridge University Press},
 }

@book{PatternClassBook,
 author = {Richard O. Duda and Peter E. Hart and David G. Stork},
 title = {Pattern Classification},
 year = {2000},
 isbn = {0-471-05669-3},
 edition = {2nd},
 address = {New York},
 publisher = {Wiley},
 }

@techreport{Eng62,
   author = {Douglas C. Engelbart},
   title = {Augmenting Human Intellect: A Conceptual Framework},
   institution = {Stanford Research Institute},
   address = {Menlo Park, CA},
   month = {October},
   year = {1962}
}

@inproceedings{Fre95,
 author = "Eric T. Freeman and Scott J. Fertig",
 title = "Lifestreams: Organizing your electronic life",
 booktitle = "AAAI Fall Symposium: AI Applications in Knowledge Navigation and Retrieval",
 address = "Cambridge, MA",
 month = "November",
 year = 1995
}

@inproceedings{ Furnas98,
    author = "George W. Furnas and Samuel J. Rauch",
    title = "Considerations for Information Environments and the {NaviQue} Workspace",
    year = "1998",
    url = "citeseer.nj.nec.com/376128.html",
    booktitle = {Proceedings of the third ACM conference on Digital libraries},
    isbn = {0-89791-965-3},
    pages = {79--88},
    location = {Pittsburgh, Pennsylvania, United States},
    doi = {http://doi.acm.org/10.1145/276675.276684},
    publisher = {ACM Press},
 }

@inproceedings{ Pirolli95,
 author = {Peter Pirolli and Stuart Card},
 title = {Information foraging in information access environments},
 booktitle = {Conference proceedings on Human factors in computing systems},
 year = {1995},
 isbn = {0-201-84705-1},
 pages = {51--58},
 location = {Denver, Colorado, United States},
 publisher = {ACM Press/Addison-Wesley Publishing Co.},
 }

@article{Previews99,
 author = {Catherine Plaisant and Ben Shneiderman and Khoa Doan and Tom Bruns},
 title = {Interface and data architecture for query preview in networked information systems},
 journal = {ACM Transactions on Information Systems (TOIS)},
 volume = {17},
 number = {3},
 year = {1999},
 issn = {1046-8188},
 pages = {320--341},
 doi = {http://doi.acm.org/10.1145/314516.314522},
 publisher = {ACM Press},
 }

@inproceedings{Pesto96,
  author    = {Michael J. Carey and
               Laura M. Haas and
               Vivekananda Maganty and
               John H. Williams},
  editor    = {T. M. Vijayaraman and
               Alejandro P. Buchmann and
               C. Mohan and
               Nandlal L. Sarda},
  title     = {{PESTO}: An Integrated Query/Browser for Object Databases},
  booktitle = {VLDB'96, Proceedings of 22th International Conference on Very
               Large Data Bases, September 3-6, 1996, Mumbai (Bombay), India},
  publisher = {Morgan Kaufmann},
  year      = {1996},
  isbn      = {1-55860-382-4},
  pages     = {203-214},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{DataGuides97,
  author    = {Roy Goldman and
               Jennifer Widom},
  editor    = {Matthias Jarke and
               Michael J. Carey and
               Klaus R. Dittrich and
               Frederick H. Lochovsky and
               Pericles Loucopoulos and
               Manfred A. Jeusfeld},
  title     = {DataGuides: Enabling Query Formulation and Optimization in Semistructured
               Databases},
  booktitle = {VLDB'97, Proceedings of 23rd International Conference on Very
               Large Data Bases, August 25-29, 1997, Athens, Greece},
  publisher = {Morgan Kaufmann},
  year      = {1997},
  isbn      = {1-55860-470-7},
  pages     = {436-445},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{QBE77,
 author = {Mosh{\'e} M. Zloof},
 title = {Query-by-{E}xample: a data base language},
 journal = {IBM Systems Journal},
 volume = {16},
 number = {4},
 year = {1977},
 pages = {342--342},
 }

@article{Greene90,
 author = {Sharon L. Greene and Susan J. Devlin and Philip E. Cannata and Louis M. Gomez},
 title = "{No IFs, ANDs, or ORs: A study of databases querying}",
 journal = {International Journal of Man-Machine Studies},
 volume = {32},
 number = {3},
 year = {1990},
 issn = {0020-7373},
 pages = {303--326},
 publisher = {Academic Press Ltd.},
 }

@inproceedings{Wong82,
  author    = {Harry K. T. Wong and Ivy Kuo},
  title     = {GUIDE: Graphical User Interface for Database Exploration},
  booktitle = {Eigth International Conference on Very Large Data Bases, September 8-10, 1982, Mexico City, Mexico, Proceedings},
  publisher = {Morgan Kaufmann},
  year      = {1982},
  isbn      = {0-934613-14-1},
  pages     = {22-32},
  ee        = {db/conf/vldb/WongK82.html},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{ catarci97,
    author = "Tiziana Catarci and Maria Francesca Costabile and Stefano Levialdi and Carlo Batini",
    title = "Visual Query Systems for Databases: A Survey",
    journal = "Journal of Visual Languages and Computing",
    volume = "8",
    number = "2",
    pages = "215-260",
    year = "1997",
    url = "citeseer.nj.nec.com/catarci95visual.html" }

@article{ Riloff96,
    author = "Ellen Riloff and Lee Hollaar",
    title = "Text Databases and Information Retrieval",
    journal = "ACM Computing Surveys",
    volume = "28",
    number = "1",
    pages = "133--135",
    month = "March",
    year = "1996"
}

@MastersThesis{WChienMEngThesis,
  author	= "Wendy S. Chien",
  title		= {Learning Query Behavior in the {Haystack} System},
  month		= jun,
  year		= {2000},
  school    = "Massachusetts Institute of Technology",
  type      = "Master of {Eng}ineering Thesis",
  address   = "Department of Electrical Engineering and Computer Science",
}

@MastersThesis{MSThesis,
  author	= "Vineet Sinha",
  title		= {Dynamically Exploiting Available Metadata For Browsing And Information Retrieval},
  month		= sep,
  year		= {2003},
  school    = "M.I.T.",
  type      = "{M.S. Thesis}",
  address   = "Department of Electrical Engineering and Computer Science",
}

@MastersThesis{ MAsdoorianMEngThesis,
  author	= "Mark Asdoorian",
  title		= {Data Manipulation Services in the Haystack IR System},
  month		= may,
  year		= {1998},
  school    = "Massachusetts Institute of Technology",
  type      = "Master of {Eng}ineering Thesis",
  address   = "Department of Electrical Engineering and Computer Science",
}

@MastersThesis{ ALowMEngThesis,
  author	= "Aidan Low",
  title		= {A Folder-Based Graphical Interface for an Information Retrieval System},
  month		= may,
  year		= {1999},
  school    = "Massachusetts Institute of Technology",
  type      = "Master of {Eng}ineering Thesis",
  address   = "Department of Electrical Engineering and Computer Science",
}

@MastersThesis{ ILisanskiyMEngThesis,
  author	= "Ilya Lisanskiy",
  title		= {Something About {Haystack}},
  month		= feb,
  year		= {1999},
  school    = "Massachusetts Institute of Technology",
  type      = "Master of {Eng}ineering Thesis",
  address   = "Department of Electrical Engineering and Computer Science",
}

@MastersThesis{ EAdarMEngThesis,
  author	= "Eytan Adar",
  title		= {Hybrid-Search and Storage of Semi--structured Information},
  month		= may,
  year		= {1998},
  school    = "Massachusetts Institute of Technology",
  type      = "Master of {Eng}ineering Thesis",
  address   = "Department of Electrical Engineering and Computer Science",
}

@MastersThesis{ SShnitserMEngThesis,
  author	= "Svetlana Shnitser",
  title		= {Integrating Structural Search Capabilites Into Project{Haystack}},
  month		= jun,
  year		= {2000},
  school    = "Massachusetts Institute of Technology",
  type      = "Master of {Eng}ineering Thesis",
  address   = "Department of Electrical Engineering and Computer Science",
}

@MastersThesis{ MRosenMEngThesis,
  author	= "Mark Rosen",
  title		= {E-mail Classification in the {Haystack} Framework},
  month		= feb,
  year		= {2003},
  school    = "Massachusetts Institute of Technology",
  type      = "Master of {Eng}ineering Thesis",
  address   = "Department of Electrical Engineering and Computer Science",
}

@inproceedings{Whittaker96,
 author = {Steve Whittaker and Candace Sidner},
 title = {Email overload: exploring personal information management of email},
 booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
 year = {1996},
 isbn = {0-89791-777-4},
 pages = {276--283},
 location = {Vancouver, British Columbia, Canada},
 doi = {http://doi.acm.org/10.1145/238386.238530},
 publisher = {ACM Press},
}

@inproceedings{ buneman97semi,
 author = {Peter Buneman},
 title = {Semistructured data},
 booktitle = {Proceedings of the sixteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems},
 year = {1997},
 isbn = {0-89791-910-6},
 pages = {117--121},
 location = {Tucson, Arizona, United States},
 doi = {http://doi.acm.org/10.1145/263661.263675},
 publisher = {ACM Press},
 abstract  = "{http://db.cis.upenn.edu/DL/97/Tutorial-Peter/abstract}",
 ps        = "{http://db.cis.upenn.edu/DL/97/Tutorial-Peter/tutorial-semi-pods.ps.gz}",
 sli_ps    = "{http://db.cis.upenn.edu/DL/97/Tutorial-Peter/slides.ps.gz}",
}

@article{Shneiderman98,
 author = {Ben Shneiderman and Donald Byrd and W. Bruce Croft},
 title = {Sorting out searching: a user-interface framework for text searches},
 journal = {Communications of the ACM},
 volume = {41},
 number = {4},
 year = {1998},
 issn = {0001-0782},
 pages = {95--98},
 doi = {http://doi.acm.org/10.1145/273035.273069},
 publisher = {ACM Press},
 }

@article{ suciu98overview,
  author = {Dan Suciu},
  title = {An overview of semistructured data},
  journal = {ACM SIGACT News},
  volume = {29},
  number = {4},
  year = {1998},
  issn = {0163-5700},
  pages = {28--38},
  doi = {http://doi.acm.org/10.1145/306198.306204},
  publisher = {ACM Press},
}

@article{ lore97,
    author = "Jason McHugh and Serge Abiteboul and Roy Goldman and Dallan Quass and Jennifer Widom",
    title = "Lore: A Database Management System for Semistructured Data",
    journal = "SIGMOD Record",
    volume = "26",
    number = "3",
    pages = "54-66",
    year = "1997",
    url = "citeseer.nj.nec.com/mchugh97lore.html" }


@article{ batesSearchTactics,
    author = "Marcia J. Bates",
    title = "Information Search Tactics",
    journal = "Journal of the American Society for Information Science",
    volume = "30",
    number = "4",
    pages = "205--214",
    year = "1979"
	}

@article{ batesIdeaTactics,
    author = "Marcia J. Bates",
    title = "Idea Tactics",
    journal = "Journal of the American Society for Information Science",
    volume = "30",
    number = "5",
    pages = "280--289",
    year = "1979"
	}

@article{ OnlineInfoRetrievalHeuristics,
    author = "Stephen P. Harter and Anne Rogers Peters",
    title = "Heuristics for online information retrieval: a typology and preliminary listing",
    journal = "Online Review",
    volume = "9",
    number = "5",
    pages = "407--424",
    year = "1985"
	}

@inproceedings{Furnas97EVN,
 author = {George W. Furnas},
 title = {Effective view navigation},
 booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
 year = {1997},
 isbn = {0-89791-802-9},
 pages = {367--374},
 location = {Atlanta, Georgia, United States},
 doi = {http://doi.acm.org/10.1145/258549.258800},
 publisher = {ACM Press},
 }

@inproceedings{Pirolli97,
 author = {Peter Pirolli},
 title = {Computational models of information scent-following in a very large browsable text collection},
 booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
 year = {1997},
 isbn = {0-89791-802-9},
 pages = {3--10},
 location = {Atlanta, Georgia, United States},
 doi = {http://doi.acm.org/10.1145/258549.258558},
 publisher = {ACM Press},
 }


@inproceedings{Pirolli96,
 author = {Peter Pirolli and James Pitkow and Ramana Rao},
 title = {Silk from a sow's ear: extracting usable structures from the Web},
 booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems},
 year = {1996},
 isbn = {0-89791-777-4},
 pages = {118--125},
 location = {Vancouver, British Columbia, Canada},
 doi = {http://doi.acm.org/10.1145/238386.238450},
 publisher = {ACM Press},
 }

@article{Nii1,
 author = {H. Penny Nii},
 title = {The Blackboard Model of Problem Solving and the Evolution of Blackboard Architectures},
 journal = {AI Magazine},
 volume = {7},
 number = {2},
 month = {Summer},
 year = {1986},
 issn = {0738-4602},
 pages = {38--53},
 publisher = {American Association for Artificial Intelligence},
}

@article{Nii2,
 author = {H. Penny Nii},
 title = {Blackboard Application Systems, Blackboard Systems and a Knowledge Engineering Perspective},
 journal = {AI Magazine},
 volume = {7},
 number = {3},
 month = {August},
 year = {1986},
 pages = {82--106},
 publisher = {American Association for Artificial Intelligence},
}

@article{Corkill91,
 author = {Daniel D. Corkill},
 title = {Blackboard Systems},
 journal = {AI Expert},
 volume = {6},
 number = {9},
 month = {September},
 year = {1991},
 pages = {40--47},
}

@incollection{Rocchio71
,author = "J. J. Rocchio"
,title = "Relevance feedback in information retrieval"
,year = 1971
,booktitle = "The {SMART} Retrieval System: Experiments in Automatic Document Processing"
,publisher = "Prentice-Hall"
,editor = "G. Salton"
,pages = "313--323"
,keywords = "rocchio"
}

@inproceedings{ Tsimmis,
    author = "Joachim Hammer and Jason McHugh and Hector Garcia-Molina",
    title = "Semistructured Data: The Tsimmis Experience",
    booktitle = "Advances in Databases and Information Systems",
    pages = "1-8",
    year = "1997",
    url = "citeseer.nj.nec.com/hammer97semistructured.html" }

@article{DonNormanHumanError,
 author = {Donald A. Norman},
 title = {Design rules based on analyses of human error},
 journal = {Communications of the ACM},
 volume = {26},
 number = {4},
 year = {1983},
 issn = {0001-0782},
 pages = {254--258},
 doi = {http://doi.acm.org/10.1145/2163.358092},
 publisher = {ACM Press},
 }

@inproceedings{XMLFrag,
 author = {David Carmel and Yoelle S. Maarek and Matan Mandelbrod and Yosi Mass and Aya Soffer},
 title = {Searching {XML} documents via {XML} fragments},
 booktitle = {Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval},
 year = {2003},
 isbn = {1-58113-646-3},
 pages = {151--158},
 location = {Toronto, Canada},
 doi = {http://doi.acm.org/10.1145/860435.860464},
 publisher = {ACM Press},
 }

@inproceedings{XMLWhatToRetrieve,
 author = {Jaap Kamps and Maarten Marx and Maarten {de Rijke} and B\"{o}rkur Sigurbj\"{o}rnsson},
 title = {{XML} retrieval: {W}hat to retrieve?},
 booktitle = {Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval},
 year = {2003},
 isbn = {1-58113-646-3},
 pages = {409--410},
 location = {Toronto, Canada},
 doi = {http://doi.acm.org/10.1145/860435.860525},
 publisher = {ACM Press},
 }

@inproceedings{DataGuidesSearch,
 author = {Roy Goldman and Jennifer Widom},
 title = {Interactive Query and Search in Semistructured Databases},
 booktitle = {Proceedings of the First International Workshop on the Web and Databases (WebDB '98), Lecture notes in Computer Science 1590},
 year = {1998},
 month = {March},
 pages = {52--62},
 location = {Berlin},
 publisher = {Springer-Verlag},
 }

@inproceedings{Trigoni02,
 author = {Agathoniki Trigoni},
 title = {Interactive Query Formulation in Semistructured Databases},
 booktitle = {Proceedings of the Fifth International Conference on Flexible Query Answering Systems (FQAS 2002), Lecture notes in Computer Science 2522},
 year = {2002},
 month = {October},
 pages = {356--369},
 location = {Copenhagen, Denmark},
 publisher = {Springer-Verlag Heidelberg},
 }

@InProceedings{Halevy:StructureChasm,
  author = 	 {Alon Halevy and Oren Etzioni and AnHai Doan and Zachary Ives and Jayant Madhavan and Luke McDowell and Igor Tatarinov},
  title = 	 {Crossing the Structure Chasm},
  booktitle =	 {Proceedings of the First Biennial Conference on Innovative Data Systems Research (CIDR)},
  year =	 2003,
  month =	 jan
}


@InProceedings{McDowell:Mangrove,
  author = 	 {Luke McDowell and Oren Etzioni and Alon Halevy and Henry Levy and Steven Gribble and William Pentney and Deepak Verma and Stani Vlasseva},
  title = 	 {Mangrove: Enticing Ordinary People onto the Semantic Web via Instant Gratification},
  booktitle =	 {Second International Semantic Web Conference (ISWC)},
  year =	 2003
}

@InCollection{Woods:SemanticNetwork,
  author = 	 {William A. Woods},
  title = 	 {What's in a Link: Foundations for Semantic Networks},
  booktitle = 	 {Representation and Understanding},
  pages =	 {35-82},
  publisher =	 {Academic Press},
  year =	 1975,
  editor =	 {D. G. Bobrow and A. Collins},
  address =	 {New York}
}

@inproceedings{Bolin05,
 author = {Michael Bolin and Matthew Webber and Philip Rha and Tom Wilson and Robert C. Miller},
 title = {Automation and customization of rendered web pages},
 booktitle = {UIST '05: Proceedings of the 18th annual ACM symposium on User interface software and technology},
 year = {2005},
 isbn = {1-59593-271-2},
 pages = {163--172},
 location = {Seattle, WA, USA},
 doi = {http://doi.acm.org/10.1145/1095034.1095062},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@inproceedings{Kistler98,
  author  = {Thomas Kistler and Hannes Marais},
  title  = {{WebL} -- a programming language for the {Web}},
  year   = {1998},
 booktitle   = {Proceedings of the 7th International World Wide Web Conference (WWW7)},

}

@article{Krulwich97,
  author  = {Bruce Krulwich},
  title  = {Automating the {Internet}: Agents as User Surrogates},
  year   = {1997},
 journal = {IEEE Internet Computing},
 volume    = {1},
  number    = {4},
  pages    = {34--38},

}

@inproceedings{Miller00,
  author  = {Robert C. Miller and Brad A. Myers},
  title  = {Integrating a Command Shell into a Web Browser},
  year   = {2000},
 booktitle    = {{USENIX} 2000 Annual Technical Conference},
  pages    = {171--182},
  month    = {June},

}

@inproceedings{Sugiura98,
  author  = {Atsushi Sugiura and Yoshiyuki Koseki},
  title  = {{Internet Scrapbook}: Automating Web Browsing Tasks by Demonstration},
  year   = {1998},
 booktitle    = {Proceedings of User Interface Software and Technology (UIST 98)},
  pages    = {9--18},
}

@article{ anupam00automating,
    author = "Vinod Anupam and Juliana Freire and Bharat Kumar and Daniel Lieuwen",
    title = "Automating {Web} navigation with the {WebVCR}",
    journal = "Computer Networks (Amsterdam, Netherlands: 1999)",
    volume = "33",
    number = "1--6",
    pages = "503--517",
    year = "2000",
    url = "citeseer.ist.psu.edu/anupam00automating.html" }

@inproceedings{Fujima04,
 author = {Jun Fujima and Aran Lunzer and Kasper Hornb\&\#230;k and Yuzuru Tanaka},
 title = {Clip, connect, clone: combining application elements to build custom interfaces for information access},
 booktitle = {UIST '04: Proceedings of the 17th annual ACM symposium on User interface software and technology},
 year = {2004},
 isbn = {1-58113-957-8},
 pages = {175--184},
 location = {Santa Fe, NM, USA},
 doi = {http://doi.acm.org/10.1145/1029632.1029664},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@misc{screenscraper,
  organization = {{Ekiwi, LLC}},
  title  = {{screen-scraper}: solutions for web data extraction},
  year   = {2004},
  howpublished    = {http://www.screen-scraper.com/},
}

@article{Kushmerick00,
  author  = {Nicholas Kushmerick},
  title  = {Wrapper verification},
  year   = {2000},
 journal = {World Wide Web},
 volume    = {3},
  number    = {2},
  pages    = {79--94},
  note    = {http://citeseer.nj.nec.com/article/kushmerick00wrapper.html", },

}

@inproceedings{Kushmerick97,
  author  = {Nicholas Kushmerick and Daniel S. Weld and Robert Doorenbos},
  title  = {Wrapper Induction for Information Extraction},
  year   = {1997},
 booktitle   = {Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)},
  pages    = {729--737},

}

@inproceedings{Muslea99,
 author = {Ion Muslea and Steven Minton and Craig Knoblock},
 title = {A hierarchical approach to wrapper induction},
 booktitle = {Proceedings of the third annual conference on Autonomous Agents},
 year = {1999},
 isbn = {1-58113-066-X},
 pages = {190--197},
 location = {Seattle, Washington, United States},
 doi = {http://doi.acm.org/10.1145/301136.301191},
 publisher = {ACM Press},
 }

@inproceedings{Chidlovskii01,
 author = {Boris Chidlovskii},
 title = {Automatic repairing of web wrappers},
 booktitle = {Proceeding of the third international workshop on Web information and data management},
 year = {2001},
 isbn = {1-58113-444-4},
 pages = {24--30},
 location = {Atlanta, Georgia, USA},
 doi = {http://doi.acm.org/10.1145/502932.502938},
 publisher = {ACM Press},
 }

@article{Knoblock03,
 author = {Craig A. Knoblock and Kristina Lerman and Steven Minton and Ion Muslea},
 title = {Accurately and reliably extracting data from the Web: a machine learning approach},
 journal = {Intelligent exploration of the web},
 year = {2003},
 isbn = {3-7908-1529-2},
 pages = {275--287},
 publisher = {Physica-Verlag GmbH},
 }

@article{Lerman03,
 author = {Kristina Lerman and Steven N. Minton and Craig A. Knoblock},
 title = {Wrapper maintenance: a machine learning approach},
 journal = {Journal of Artificial Intelligence Research},
 year = {2003},
 volume    = {18},
 pages = {149--181},
 }

@inproceedings{Lerman04,
 author = {Kristina Lerman and Lise Getoor and Steven Minton and Craig Knoblock},
 title = {Using the structure of Web sites for automatic segmentation of tables},
 booktitle = {Proceedings of the 2004 ACM SIGMOD international conference on Management of data},
 year = {2004},
 isbn = {1-58113-859-8},
 pages = {119--130},
 location = {Paris, France},
 doi = {http://doi.acm.org/10.1145/1007568.1007584},
 publisher = {ACM Press},
 }

@inproceedings{ ciravegna03integrating,
  author = "F. Ciravegna and A. Dingli and D. Guthrie and Y. Wilks",
  title = "Integrating Information to Bootstrap Information Extraction from Web Sites",
  booktitle = "Proc. IJCAI 2003",
  year = "2003",
  url = "citeseer.ist.psu.edu/ciravegna03integrating.html" }
@misc{LAPIS,
  author = {Robert C. Miller and others},
  title  = {{LAPIS} 1.2},
  year   = {2003},
 howpublished    = {http://graphics.lcs.mit.edu/lapis/},

}

@incollection{Witten93,
  author  = {Ian H. Witten and Dan Mo},
  title  = {{TELS}: Learning Text Editing Tasks From Examples},
  year   = {1993},
 booktitle    = {Watch What I Do: Programming by Demonstration},
  editor    = {Allen Cypher},
  publisher    = {MIT Press},
  pages    = {183--204},

}

@inproceedings{Landauer95,
  author  = {Jurgen Landauer and Masahito Hirakawa},
  title  = {Visual {AWK}: a model for text processing by demonstration},
  year   = {1995},
 booktitle   = {Proceedings of the 11th International IEEE Symposium on Visual Languages '95},
  pages    = {267--274},
  note    = {http://www.computer.org/conferen/vl95/talks/T32.html},

}

@inproceedings{Fujishima98,
  author  = {Yuzo Fujishima},
  title  = {Demonstrational Automation of Text

 Editing Tasks Involving Multiple Focus Points and Conversions},
  year   = {1998},
 booktitle   = {Proceedings of the International Conference on Intelligent User Interfaces (IUI '98)},
  pages    = {101--108},
  note    = {http://doi.acm.org/10.1145/268389.268408},

}

@inproceedings{Lau00,
  author  = {Tessa Lau and Pedro Domingos and Daniel S. Weld},
  title  = {Version Space Algebra and its Application to Programming by Demonstration},
  year   = {2000},
 booktitle    = {Proceedings of ICML 2000},
  pages    = {527--534},
  note    = {http://www.ofb.net/~tlau/research/papers/icml2000.ps},
  month    = {June},

}

@incollection{Lau01,
  author  = {Tessa Lau and Steven Wolfman and Pedro Domingos and Daniel S. Weld},
  title  = {Learning Repetitive Text-Editing Procedures with {SMARTedit}},
  year   = {2001},
 booktitle   = {Your Wish Is My Command: Giving Users the Power to Instruct Their Software},
  editor    = {Henry Lieberman},
  publisher    = {Morgan Kaufmann},
  pages    = {209--226},
  note    = {http://www.ofb.net/~tlau/research/yourwish/smartedit.html},

}

@inproceedings{Miller01b,
  author  = {Robert C. Miller and Brad A. Myers},
  title  = {Interactive Simultaneous Editing of Multiple Text Regions},
  year   = {2001},
 booktitle    = {Proceedings of the 2001 {USENIX} Annual Technical Conference},
  pages    = {161--174},
  month    = {June},

}

@book{Nardi93,
  author = {Bonnie A. Nardi},
  title = {A Small Matter of Programming: Perspectives on End User Computing},
  year = {1993},
  publisher = {{MIT} Press},
}

@InProceedings{Gajos:Supple,
  author = 	 {Krzysztof Gajos and Daniel S. Weld},
  title = 	 {{SUPPLE:} Automatically Generating User Interfaces},
  booktitle =	 {Proceedings of Intelligent User Interfaces (IUI '04)},
  year =	 2004
}

@book{Cypher93,
 crossref={Witten93}
}

@book{Lieberman01,
  title  = {Your Wish Is My Command: Giving Users the Power to Instruct Their Software},
  year   = {2001},
 editor    = {Henry Lieberman},
  publisher    = {Morgan Kaufmann},

}

@inproceedings{Somberg87,
 author = {Benjamin L. Somberg},
 title = {A comparison of rule-based and positionally constant arrangements of computer menu items},
 booktitle = {CHI '87: Proceedings of the SIGCHI/GI conference on Human factors in computing systems and graphics interface},
 year = {1987},
 isbn = {0-89791-213-6},
 pages = {255--260},
 location = {Toronto, Ontario, Canada},
 doi = {http://doi.acm.org/10.1145/29933.275639},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@inproceedings{Liu05,
 author = {Hugo Liu and Henry Lieberman},
 title = {Metafor: visualizing stories as code},
 booktitle = {IUI '05: Proceedings of the 10th international conference on Intelligent user interfaces},
 year = {2005},
 isbn = {1-58113-894-6},
 pages = {305--307},
 location = {San Diego, California, USA},
 doi = {http://doi.acm.org/10.1145/1040830.1040908},
 publisher = {ACM Press},
 address = {New York, NY, USA},
}

@article{Sears94,
 author = {Andrew Sears and Ben Shneiderman},
 title = {Split menus: effectively using selection frequency to organize menus},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 volume = {1},
 number = {1},
 year = {1994},
 issn = {1073-0516},
 pages = {27--51},
 doi = {http://doi.acm.org/10.1145/174630.174632},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@article{Mitchell89,
 author = {J. Mitchell and Ben Shneiderman},
 title = {Dynamic versus static menus: an exploratory comparison},
 journal = {SIGCHI Bull.},
 volume = {20},
 number = {4},
 year = {1989},
 issn = {0736-6906},
 pages = {33--37},
 doi = {http://doi.acm.org/10.1145/67243.67247},
 publisher = {ACM Press},
 address =
 {New York, NY, USA},
 }
@article{ pane01studying,
    author = "John F. Pane and Chotirat (Ann) Ratanamahatana and Brad A. Myers",
    title = "Studying the language and structure in non-programmers' solutions to programming problems",
    journal = "International Journal of Human Computer Studies",
    volume = "54",
    number = "2",
    pages = "237-264",
    year = "2001",
    url = "citeseer.ist.psu.edu/pane00studying.html" }

@Article{Guy:Folksonomy,
  author = 	 {Marieke Guy and Emma Tonkin},
  title = 	 {Folksonomies: Tidying up Tags?},
  journal = 	 {Dlib},
  year = 	 2006,
  month =        jan,
  volume =	 12,
  number =	 1,
  note =	 {Digital publication, available at http://www.dlib.org/dlib/january06/guy/01guy.html}
}

@inbook{Frasincar:RDFViz,
  author =	 {Flavius Frasincar and Alexandru Telea and Geert-Jan Houben},
  ALTeditor =	 {Vladimir Geroimenko and Chaomei Chen},
  title = 	 {Adapting graph visualization techniques for the
                  visualization of RDF data},
  chapter = 	 9,
  booktitle =    {Visualizing the Semantic Web},
  publisher = 	 {Springer},
  year = 	 2005,
  edition =	 2,
  pages =	 {154-171}
}


@inproceedings{Rutledge:Finding,
  author = "Lloyd Rutledge and M. Alberink and R. Brussee and S. Pokraev and W. van Dieten
    and M. Veenstra",
  booktitle = {Proceedings of the 14th ACM conference on
    Hypertext and Hypermedia},
  title = "Finding the Story --- Broader Applicability of Semantics and Discourse
    for Hypermedia Generation",
  text = "L. Rutledge, M. Alberink, R. Brussee, S. Pokraev, W. van Dieten, and M.
    Veenstra. Finding the Story --- Broader Applicability of Semantics and Discourse
    for Hypermedia Generation. In, Nottingham, UK, August 26-30, 2003. http: //www.ht03.org/.",
  year = 2003,
  pages={67-76},
  url = "citeseer.ist.psu.edu/article/rutledge03finding.html" }

@InProceedings{Kleinberg:WebAsGraph,
  author = 	 {Jon Kleinberg and S. R. Kumar and Prabhakar Raghavan and
                  Sridhar Rajagopalan and Andrew Tomkins},
  title = 	 {The Web as a graph: Measurements, models and methods},
  booktitle =	 {International Conference on Combinatorics and Computing},
  year =	 1999,
  note =	 {Invited Survey}
}

@inproceedings{Broder:Bowtie,
 author = {Andrei Broder and Ravi Kumar and Farzin Maghoul and Prabhakar Raghavan and Sridhar Rajagopalan and Raymie Stata and Andrew Tomkins and Janet Wiener},
 title = {Graph structure in the Web},
 booktitle = {Proceedings of the 9th international World Wide Web conference on Computer networks : the international journal of computer and telecommunications netowrking},
 year = 2000,
 pages = {309--320},
 location = {Amsterdam, The Netherlands},
 doi = {http://dx.doi.org/10.1016/S1389-1286(00)00083-9},
 publisher = {North-Holland Publishing Co.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 }

@article{Hearst:Clustering,
 author = {Marti A. Hearst},
 title = {Clustering versus faceted categories for information exploration},
 journal = {Communications of the ACM},
 volume = 49,
 number = 4,
 year = 2006,
 issn = {0001-0782},
 pages = {59--61},
 doi = {http://doi.acm.org/10.1145/1121949.1121983},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@Article{Kalyanpur:Swoop,
  author = 	 {Aditya Kalyanpur and Bijan Parsia and Evren Sirin and Bernardo Cuenca-Grau and James Hendler},
  title = 	 {Swoop: A 'Web' Ontology Editing Browser},
  journal = 	 {Journal of Web Semantics},
  year = 	 2005,
  volume =	 4,
  number =	 2
}

@Article{Seo:HierarchicalCluster,
  author = 	 {Jinwook Seo and Ben Shneiderman},
  title = 	 {Interactively Exploring Hierarchical Clustering Results},
  journal = 	 {IEEE Computer},
  year = 	 2002,
  volume =	 35,
  number =	 7,
  pages =	 {80-86},
  month =	 jul
}

@InProceedings{Schraefel:Mspace,
  author = 	 {schraefel, m. c. and Smith, D. A. and Russel, A. and Owens, A. and Harris, C. and Wilson, M. L.},
  title = 	 {The mSpace Classical Music Explorer: Improving Access to Classical Music for Real People},
  booktitle =	 {Proceedings of V MUSICNETWORK OPEN WORKSHOP: Integration of Music in Multimedia Applications},
  year =	 2005
}

@Article{Robertson:Pivot,
  author = 	 {Robertson, G. G. and Cameron, K. and Czerwinski, M. and Robbins, D.},
  title = 	 {Polyarchy Visualization: Visualizing multiple intersecting hierarchies},
  journal = 	 {Information Visualization},
  year = 	 2002,
  volume =	 1,
  number =	 1,
  pages =	 {50-65}
}

@inproceedings{Bellotti:Taskmaster,
 author = {Victoria Bellotti and Nicolas Ducheneaut and Mark Howard and Ian Smith},
 title = {Taking email to task: the design and evaluation of a task management centered email tool},
 booktitle = {CHI '03: Proceedings of the SIGCHI conference on Human factors in computing systems},
 year = 2003,
 isbn = {1-58113-630-7},
 pages = {345--352},
 location = {Ft. Lauderdale, Florida, USA},
 doi = {http://doi.acm.org/10.1145/642611.642672},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 }

@InProceedings{Hildebrand:Slashfacet,
  author = 	 {Michiel Hildebrand and van Ossenbruggen, Jacco  and Lynda Hardman},
  title = 	 {/facet: A Browser for Heterogeneous Semantic Web Repositories},
  booktitle =	 {$5^{th}$ International Semantic Web Conference (ISWC)},
  year =	 2006,
  note =	 {To appear}
}

@article{Schraefel:Hypertext,
author = {schraefel, m. c. and Leslie Carr and David De Roure and Wendy
                  Hall},
title = {You've Got Hypertext},
journal = {Journal of Digital Information},
volume = 5,
number = 1,
year= 2004
}

@proceedings{esa94,
        title = esa94,
        booktitle = esa94,
		  month = sep,
		  editor = leeuwen,
		  publisher = sv,
  venue = {ESA},
        year = 1994}

@proceedings{STOC84,
	title = STOC84,
	booktitle = STOC84,
	year = 1984,
	organization = {ACM},
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC85,
	title = STOC85,
	booktitle = STOC85,
	year = 1985,
	organization = {ACM},
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC86,
	title = STOC86,
	booktitle = STOC86,
	year = 1986,
	organization = {ACM},
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC87,
	title = STOC87,
	booktitle = STOC87,
	year = 1987,
	organization = {ACM},
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC88,
	title = STOC88,
	booktitle = STOC88,
	year = 1988,
	organization = {ACM},
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC89,
	title = STOC89,
	booktitle = STOC89,
	year = 1989,
	organization = {ACM},
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC90,
	title = STOC90,
	booktitle = STOC90,
	year = 1990,
	organization = {ACM},
	month = may,
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC91,
	title = STOC91,
	booktitle = STOC91,
	year = 1991,
	organization = {ACM},
	month = may,
  venue = {STOC},
	publisher = acmp}

@proceedings{STOC92,
	title = STOC92,
	booktitle = STOC92,
	year = 1992,
	organization = {ACM},
	month = may,
	publisher = acmp,
  venue = {STOC},
        place = {Victora, BC, Canada}}

@proceedings{STOC93,
	title = STOC93,
	booktitle = STOC93,
editor = {Alok Aggarwal},
	year = 1993,
	organization = {ACM},
	month = may,
	publisher = acmp,
  venue = {STOC},
        place = {San Diego, CA}}

@proceedings{STOC94,
	title = STOC94,
	booktitle = STOC94,
	year = 1994,
	organization = {ACM},
	month = may,
	publisher = acmp,
  venue = {STOC},
        place = {Montreal, Quebec, Canada}}

@proceedings{STOC95,
	title = STOC95,
	booktitle = STOC95,
	year = 1995,
	organization = {ACM},
	month = may,
	publisher = acmp,
  venue = {STOC},
        place ={Las Vegas, NV}
        }

@proceedings{STOC96,
	title = STOC96,
	booktitle = STOC96,
	year = 1996,
	organization = {ACM},
	month = may,
	publisher = acmp,
        editor = {Gary Miller},
  venue = {STOC},
        place ={Philadelphia, PA}
        }

@proceedings{STOC97,
	title = STOC97,
	booktitle = STOC97,
	year = 1997,
	organization = {ACM},
	month = may,
	publisher = acmp,
  venue = {STOC},
        place ={El Paso, TX}
        }

@proceedings{STOC98,
	title = STOC98,
	booktitle = STOC98,
	year = 1998,
	organization = {ACM},
	publisher = acmp,
        place ={Dallas, TX},
  ISBN =         "0-89791-962-9",
  month =        may # "~23--26",
  venue = {STOC},
  address =      "New York",
        }

@proceedings{STOC99,
  title =	 STOC99,
  booktitle =	 STOC99,
  year =	 1999,
  organization = {ACM},
  month =	 may,
  publisher =	 acmp,
  venue = {STOC},
  place =	 {Philadelphia, PA}
}

@proceedings{STOC02,
  title =	 STOC02,
  booktitle =	 STOC02,
  year =	 2002,
  organization = {ACM},
  month =	 may,
  publisher =	 acmp,
  venue = {STOC},
  place =	 {Montreal, Canada}
}

@Proceedings{focs79,
  title =	 focs79,
  year =	 1979,
  booktitle =	 focs79,
  publisher =	 ieeep,
  organization = "{IEEE}",
  month =	 oct,
  venue = {FOCS},
  place =	 {San Juan, Puerto Rico}
}

@proceedings{FOCS82,
  title =	 FOCS82,
  booktitle =	 FOCS82,
  year =	 1982,
  organization = {IEEE},
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{FOCS84,
  title =	 FOCS84,
  booktitle =	 FOCS84,
  year =	 1984,
  organization = {IEEE},
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{FOCS86,
  title =	 FOCS86,
  booktitle =	 FOCS86,
  year =	 1986,
  organization = {IEEE},
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{FOCS87,
  title =	 FOCS87,
  booktitle =	 FOCS87,
  year =	 1987,
  organization = {IEEE},
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{FOCS88,
  title =	 FOCS88,
  booktitle =	 FOCS88,
  year =	 1988,
  month =	 oct,
  organization = {IEEE},
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{FOCS89,
  title =	 FOCS89,
  booktitle =	 FOCS89,
  year =	 1989,
  organization = {IEEE},
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{FOCS90,
  title =	 FOCS90,
  booktitle =	 FOCS90,
  year =	 1990,
  month =	 oct,
  organization = {IEEE},
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{FOCS91,
  title =	 FOCS91,
  booktitle =	 FOCS91,
  year =	 1991,
  organization = {IEEE},
  month =	 oct,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {San Juan, Puerto Rico}
}

@proceedings{FOCS92,
  title =	 FOCS92,
  booktitle =	 FOCS92,
  year =	 1992,
  organization = {IEEE},
  month =	 oct,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Pittsburgh, PA}
}

@proceedings{FOCS93,
  title =	 FOCS93,
  booktitle =	 FOCS93,
  editor =	 {Leonidas Guibas},
  year =	 1993,
  organization = {IEEE},
  month =	 nov,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Palo Alto, CA}
}

@proceedings{FOCS94,
  title =	 FOCS94,
  booktitle =	 FOCS94,
  year =	 1994,
  editor =	 {Shafi Goldwasser},
  organization = {IEEE},
  month =	 nov,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Santa Fe, NM}
}

@proceedings{FOCS95,
  title =	 FOCS95,
  booktitle =	 FOCS95,
  year =	 1995,
  organization = {IEEE},
  month =	 oct,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Milwaukie, WI}
}

@proceedings{FOCS96,
  title =	 FOCS96,
  booktitle =	 FOCS96,
  year =	 1996,
  organization = {IEEE},
  month =	 oct,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Burlington, VT}
}

@proceedings{FOCS97,
  title =	 FOCS97,
  booktitle =	 FOCS97,
  year =	 1997,
  organization = {IEEE},
  month =	 oct,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Miami, FL}
}

@proceedings{FOCS99,
  title =	 FOCS99,
  booktitle =	 FOCS99,
  year =	 1999,
  organization = {IEEE},
  month =	 oct,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {New York, NY}
}

@proceedings{FOCS00,
  title =	 FOCS00,
  booktitle =	 FOCS00,
  year =	 2000,
  organization = {IEEE},
  month =	 nov,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Rodondo Beach, CA}
}
@proceedings{FOCS02,
  title =	 FOCS02,
  booktitle =	 FOCS02,
  year =	 2002,
  organization = {IEEE},
  month =	 nov,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Vancouver, Canada}
}
@proceedings{FOCS03,
  title =	 FOCS03,
  booktitle =	 FOCS03,
  year =	 2003,
  organization = {IEEE},
  month =	 oct,
  publisher =	 ieeep,
  venue = {FOCS},
  place =	 {Cambridge, MA}
}
@proceedings{FOCS04,
  title =	 FOCS04,
  booktitle =	 FOCS04,
  year =	 2004,
  organization = {IEEE},
  month =	 oct,
  venue = {FOCS},
  publisher =	 ieeep
}
@proceedings{FOCS09,
  title =	 FOCS09,
  booktitle =	 FOCS09,
  year =	 2009,
  organization = {IEEE},
  month =	 oct,
  venue = {FOCS},
  publisher =	 ieeep
}

@proceedings{SODA92,
  title =	 SODA92,
  booktitle =	 SODA92,
  organization = {ACM-SIAM},
  year =	 1992,
  venue = {SODA},
  month =	 jan
}

@proceedings{SODA93,
  title =	 SODA93,
  booktitle =	 SODA93,
  organization = {ACM-SIAM},
  year =	 1993,
  month =	 jan,
  venue = {SODA},
  place =	 {Austin, TX}
}

@proceedings{SODA94,
  title =	 SODA94,
  booktitle =	 SODA94,
  editor =	 {Daniel D. Sleator},
  organization = {ACM-SIAM},
  year =	 1994,
  month =	 jan,
  venue = {SODA},
  place =	 {Arlington, VA}
}

@proceedings{SODA95,
  title =	 SODA95,
  booktitle =	 SODA95,
  organization = {ACM-SIAM},
  year =	 1995,
  month =	 jan,
  venue = {SODA},
  place =	 {San Fransisco, CA}
}

@proceedings{SODA96,
  title =	 SODA96,
  booktitle =	 SODA96,
  organization = {ACM-SIAM},
  year =	 1996,
  month =	 jan,
  venue = {SODA},
  place =	 {Atlanta, GA}
}

@proceedings{SODA97,
  title =	 SODA97,
  booktitle =	 SODA97,
  editor =	 {Michael Saks},
  organization = {ACM-SIAM},
  year =	 1997,
  month =	 jan,
  venue = {SODA},
  place =	 {New Orleans, LA}
}

@proceedings{SODA98,
  title =	 SODA98,
  booktitle =	 SODA98,
  editor =	 {Howard Karloff},
  organization = {ACM-SIAM},
  year =	 1998,
  month =	 jan,
  venue = {SODA},
  place =	 {San Fransisco, CA}
}

@proceedings{SODA01,
  title =	 SODA01,
  booktitle =	 SODA01,
  editor =	 {S. Rao Kosaraju},
  organization = {ACM-SIAM},
  year =	 2001,
  month =	 jan,
  place =	 {Washington, DC},
  venue = {SODA},
  confurl = {http://portal.acm.org/toc.cfm?id=365411&dl=GUIDE&dl=ACM&type=proceeding&idx=SERIES422&part=Proceedings&WantType=Proceedings}
}

@proceedings{SODA04,
 title=SODA04,
 booktitle=SODA04,
venue = {SODA},
 year = {2004},
 month = jan,
 isbn = {0-89871-558-X},
 location = {New Orleans, Louisiana},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
}

@proceedings{SODA05,
  title =	 SODA05,
  booktitle =	 SODA05,
  organization = {ACM-SIAM},
  year =	 2005,
  month =	 jan,
  venue = {SODA},
  place =	 {Vancouver, BC},
}
@proceedings{SODA06,
 isbn = {0-89871-605-5},
 location = {Miami, Florida},
 publisher = {ACM Press},
 address = {New York, NY, USA},

  title =	 SODA06,
  booktitle =	 SODA06,
  organization = {ACM-SIAM},
  year =	 2006,
  month =	 jan,
  venue = {SODA},
  place =	 {Miami, FL},
}

@proceedings{SODA07,
  editor    = {Nikhil Bansal and
               Kirk Pruhs and
               Clifford Stein},
  title     = SODA07,
  booktitle = SODA07,
  venue = {SODA},
  organization = {ACM-SIAM},
  publisher = {SIAM},
  year      = {2007},
  month = jan,
  isbn      = {978-0-898716-24-5}
}

@proceedings{SODA08,
 publisher = {ACM Press},
 address = {New York, NY, USA},

  title =	 SODA08,
  booktitle =	 SODA08,
  organization = {ACM-SIAM},
  year =	 2008,
  month =	 jan,
  venue = {SODA},
  place =	 {San Francisco, CA},
}

@proceedings{SODA10,
 publisher = {ACM Press},
  title =	 SODA10,
  booktitle =	 SODA10,
  organization = {ACM-SIAM},
  year =	 2010,
  month =	 jan,
  venue = {SODA}
}

@proceedings{SPAA92,
  title =	 SPAA92,
  booktitle =	 SPAA92,
  year =	 1992,
  organization = {ACM},
  place =	 {San Diega, CA},
venue = {SPAA},
  month =	 jun
}

@proceedings{SPAA93,
  title =	 SPAA93,
  booktitle =	 SPAA93,
  organization = {ACM},
  year =	 1993,
venue = {SPAA},
  month =	 jun
}

@proceedings{SPAA94,
  title =	 SPAA94,
  booktitle =	 SPAA94,
  organization = {ACM},
  year =	 1994,
venue = {SPAA},
  month =	 jun
}

@proceedings{SWAT90,
  title =	 SWAT90,
  booktitle =	 SWAT90,
  editor =	 {John R. Gilbert and Rolf Karlsson},
  publisher =	 sv,
  address =	 {New York},
  series =	 LNCS,
  number =	 447,
  venue = {SWAT},
  year =	 1990
}

@proceedings{icalp90,
  booktitle =	 icalp90,
  editor =	 {Michael S. Patterson},
  series =	 LNCS,
  publisher =	 sv,
  volume =	 443,
  year =	 1992,
  venue = {ICALP},
  month =	 jul
}

@proceedings{icalp91,
  booktitle =	 icalp91,
  editor =	 {Leach Albert, Javier and Burkhard Monien and
                  Artalejo Rodru{'i}gez, Mario},
  series =	 LNCS,
  publisher =	 sv,
  volume =	 510,
  year =	 1992,
  venue = {ICALP},
  month =	 jul
}

@proceedings{icalp92,
  booktitle =	 icalp92,
  series =	 LNCS,
  publisher =	 sv,
  volume =	 623,
  year =	 1992,
  venue = {ICALP},
  month =	 jul
}

@proceedings{icalp95,
  booktitle =	 icalp95,
  series =	 LNCS,
  publisher =	 sv,
  volume =	 944,
  year =	 1995,
  month =	 jul,
  venue = {ICALP}
}

@Proceedings{icml03,
  title = 	 {The Twentieth International Conference on Machine
                  Learning},
  year = 	 2003,
  url = {http://www.hpl.hp.com/conferences/icml03/},
  booktitle =	 {The Twentieth International Conference on Machine
                  Learning},
  address =	 {Washington, DC},
  month =	 aug,
  venue = {ICML}
}

@book{HandbookTCS,
	booktitle = {Handbook of Theoretical Computer Science},
        title = {Handbook of Theoretical Computer Science},
	volume = {A},
	editor = leeuwen,
	publisher = {MIT Press},
	address = {Cambridge, MA},
	year = {1990}}

@proceedings{iptps02,
  title =	 proc # { First } # iptps,
  booktitle =	 proc # { First } # iptps,
  year =	 2002,
  address =	 {Cambridge, MA},
  month =	 mar,
  venue={IPTPS}
}

@Proceedings{iptps03,
  editor =       {M. Frans Kaashoek and Ion Stoica},
  title = 	 {2nd International Workshop on Peer to Peer Systems},
  year = 	 2003,
  booktitle =	 {2nd International Workshop on Peer to Peer Systems},
  series =	 {LNCS Hot Topics},
  address =	 {Berkeley, CA},
  month =	 jan,
  venue = {IPTPS},
  publisher =	 {Springer},
  confurl = {http://iptps03.cs.berkeley.edu/}
}

@Proceedings{iptps04,
  title = 	 {IPTPS: 3rd International Workshop on Peer to Peer Systems},
  year = 	 2004,
  booktitle =	 {IPTPS: 3rd International Workshop on Peer to Peer Systems},
  series =	 {LNCS Hot Topics},
  month =	 feb,
  venue = {IPTPS},
  publisher =	 {Springer},
}

@Proceedings{iptps05,
  editor =       {M. Frans Kaashoek and Ion Stoica},
  title = 	 {4th International Workshop on Peer to Peer Systems},
  year = 	 2005,
  booktitle =	 {4th International Workshop on Peer to Peer Systems},
  series =	 {LNCS Hot Topics},
  address =	 {Ithaca, NY},
  month =	 feb,
  publisher =	 {Springer},
  venue = {IPTPS},
  confurl = {http://iptps05.cs.cornell.edu/}
}

@Proceedings{interact03,
  title = 	 {INTERACT: $9^{th}$ IFIP International Conference on Human
                  Computer Interaction},
  year = 	 2003,
  confurl = {http://www.interact2003.org/},
  booktitle =	 {INTERACT: $9^{th}$ IFIP International Conference on Human
                  Computer Interaction},
  address =	 {Zurich},
  month =	 sep,
  venue = {INTERACT},
  organization = {International Federation for Information Processing}
}

@Proceedings{sigir03,
  title = 	 {$26^{th}$ Internationl ACM SIGIR Conference},
  year = 	 2003,
  month = jul,
  booktitle =	 {$26^{th}$ Internationl ACM SIGIR Conference},
  address =	 {Toronto},
  organization = {ACM SIGIR},
  publisher =	 {ACM},
  venue = {SIGIR},
  confurl= {http://www.sigir2003.org}
}

@Proceedings{sigir06,
  title = 	 {$29^{th}$ Internationl ACM SIGIR Conference},
  year = 	 2006,
  month = jul,
  booktitle =	 {$29^{th}$ Internationl ACM SIGIR Conference},
  organization = {ACM SIGIR},
  publisher =	 {ACM},
venue = {SIGIR},
  confurl= {http://www.sigir2006.org}
}

@proceedings{iui03,
  title     = {Proceedings of the 2003 International Conference on Intelligent
               User Interfaces},
  booktitle = {Intelligent User Interfaces},
  publisher = {ACM},
  year      = {2003},
  month =   jan,
  confurl = {http://www.iuiconf.org/03program.html},
  address = {Miami, FL},
  isbn      = {1-58113-586-6},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  venue = {IUI}
}

@Proceedings{semweb02,
  title = 	 {Semantic Web Workshop at WWW2002},
  year = 	 2002,
  booktitle =	 {Semantic Web Workshop at WWW2002},
  address =	 {Honolulu, Hawaii},
  month =	 may,
  confurl = {http://www.www2002.org/},
  venue = {WWW}
}


@Proceedings{iswc03,
  title = 	 {$2^{nd}$ International Semantic Web Conference},
  booktitle = 	 {$2^{nd}$ International Semantic Web Conference},
  year = 	 2003,
  key =		 {$2^{nd}$ International Semantic Web Conference},
  address =	 {Sanibel Island, FL},
  month =	 oct,
  venue = {ISWC}
}

@proceedings{iswc06,
  title =	 {$5^{th}$ International Semantic Web Conference (ISWC)},
  booktitle =	 {$5^{th}$ International Semantic Web Conference (ISWC)},
  year =	 2006,
  month =	 nov,
  venue={ISWC}
}

@proceedings{iswc07,
  title =	 {$6^{th}$ International Semantic Web Conference (ISWC)},
  booktitle =	 {$6^{th}$ International Semantic Web Conference (ISWC)},
  year =	 2007,
  month =	 nov,
  venue={ISWC}
}

@Proceedings{isit03,
  title = 	 {IEEE International Symposium on Information Theory},
  booktitle = 	 {IEEE International Symposium on Information Theory},
  year = 	 2003,
  address =	 {Yokohama, Japan},
  month =	 jun,
  organization = {IEEE},
venue = {ISIT},
  confurl = {http://www.isit2003.org/}
}
@Proceedings{uist03,
  title = 	 {The $16^{th}$ Annual Symposium on User Interface
                  Software and Technology},
  booktitle = 	 {The $16^{th}$ Annual Symposium on User Interface
                  Software and Technology},
  venue = {UIST},
  year = 	 2003,
  month = nov,
  address =	 {Vancouver, BC},
  organization = {ACM}
}

@proceedings{www03,
  title =	 {Proceedings of the $12^{th}$ International World
                  Wide Web Conference},
  booktitle =	 {Proceedings of the $12^{th}$ International World
                  Wide Web Conference},
  venue={WWW},
  year =	 2003,
  month = may
}

@proceedings{www04,
  title =	 {Proceedings of the $13^{th}$ International World
                  Wide Web Conference},
  booktitle =	 {Proceedings of the $13^{th}$ International World
                  Wide Web Conference},
  year =	 2004,
  month = may,
  venue = {WWW}
}

@proceedings{www05,
  title =	 {Proceedings of the $14^{th}$ International World
                  Wide Web Conference (WWW)},
  booktitle =	 {Proceedings of the $14^{th}$ International World
                  Wide Web Conference (WWW)},
  year =	 2005,
venue={WWW}
}


@proceedings{www07,
  title = {16th International World Wide Web Conference (WWW2007)},
  booktitle = {16th International World Wide Web Conference (WWW2007)},
  venue = {WWW},
  year = {2007},
  month = may,
  location = {Banff, Canada}}


@proceedings{oopsla05companion,
 title = {OOPSLA '05: Companion to the 20th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
 booktitle = {OOPSLA '05: Companion to the 20th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
 year = {2005},
 month = oct,
 isbn = {1-59593-193-7},
 location = {San Diego, CA, USA},
 publisher = {ACM Press},
 address = {New York, NY, USA},
 venue = {OOPSLA}
 }

@proceedings{hotnets05,
   title =    {4th ACM  Workshop on Hot Topics in Networks (HotNets)},
   booktitle =    {4th ACM  Workshop on Hot Topics in Networks (HotNets)},
   year =         {2005},
   month =        nov,
   address =      {College Park, MD},
   venue   =      {HotNets}
}

@proceedings{STOC07,
 booktitle = {STOC '07: Proceedings of the thirty-ninth annual ACM
                  symposium on Theory of computing},
 year = {2007},
 isbn = {978-1-59593-631-8},
 location = {San Diego, California, USA},
 doi = {http://doi.acm.org/10.1145/1250790.1250879},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@proceedings{STOC08,
 booktitle = {STOC '08: Proceedings of the 40th annual ACM symposium
                  on Theory of computing},
 year = {2008},
 isbn = {978-1-60558-047-0},
 location = {Victoria, British Columbia, Canada},
 doi = {http://doi.acm.org/10.1145/1374376.1374456},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@proceedings{STOC09,
  editor    = {Michael Mitzenmacher},
  title     = {STOC 2009: Proceedings of the 41st Annual ACM Symposium on Theory of Computing},
  booktitle     = {STOC 2009: Proceedings of the 41st Annual ACM Symposium on Theory of Computing},
  publisher = {ACM},
  year      = {2009},
  month=may,
  isbn      = {978-1-60558-506-2},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@proceedings{stoc11,
 acmid = {1993674},
 editor={Salil Vadhan},
 booktitle = {Proceedings of the 43rd annual ACM symposium on Theory
                  of computing},
 title = {Proceedings of the 43rd annual ACM symposium on Theory
                  of computing},
 series = {STOC '11},
 year = {2011},
 isbn = {978-1-4503-0691-1},
 location = {San Jose, California, USA},
 publisher = {ACM},
 address = {New York, NY, USA},
  month=may
}

@misc{RDFDraft,
  author = "Ora Lassila and Ralph Swick",
  title		= {Resource Description Framework ({RDF}): Model and Syntax
		  Specification},
  howpublished	= {{\tt http://www.w3.org/TR/1999/REC-rdf-syntax-19990222}},
  month		= feb,
  year		= {1999},
  note		= {W3C Recommendation},
  postscript	= {},
  pdf		= {},
  url		= {http://www.w3.org/TR/1999/REC-rdf-syntax-19990222},
  keywords	= {XML}
}

@misc{RDF,
  title  = {{Resource Description Framework}},
  author = {The World Wide Web Consortium},
  year = 2004,
  month = nov,
  howpublished = {{\tt http://www.w3.org/RDF/}}
}
